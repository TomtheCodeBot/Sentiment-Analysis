{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"7I-xZzsveUMA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1654621050656,"user_tz":-420,"elapsed":29806,"user":{"displayName":"Duy Hoang","userId":"17457647490907439684"}},"outputId":"69154ea0-0be9-4923-e4cd-e3d9c9837572"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"S9qzfxSwkTtx","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1654621066694,"user_tz":-420,"elapsed":16047,"user":{"displayName":"Duy Hoang","userId":"17457647490907439684"}},"outputId":"7251b0d3-fb22-4496-d508-afd4926b88be"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting fastNLP\n","  Downloading FastNLP-0.7.0.tar.gz (295 kB)\n","\u001b[?25l\r\u001b[K     |█                               | 10 kB 31.1 MB/s eta 0:00:01\r\u001b[K     |██▏                             | 20 kB 36.2 MB/s eta 0:00:01\r\u001b[K     |███▎                            | 30 kB 41.5 MB/s eta 0:00:01\r\u001b[K     |████▍                           | 40 kB 34.9 MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 51 kB 25.1 MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 61 kB 28.2 MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 71 kB 29.1 MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 81 kB 30.4 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 92 kB 32.6 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 102 kB 34.7 MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 112 kB 34.7 MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 122 kB 34.7 MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 133 kB 34.7 MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 143 kB 34.7 MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 153 kB 34.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 163 kB 34.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 174 kB 34.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 184 kB 34.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 194 kB 34.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 204 kB 34.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 215 kB 34.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 225 kB 34.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 235 kB 34.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 245 kB 34.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 256 kB 34.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 266 kB 34.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 276 kB 34.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 286 kB 34.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 295 kB 34.7 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.14.2 in /usr/local/lib/python3.7/dist-packages (from fastNLP) (1.21.6)\n","Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from fastNLP) (1.11.0+cu113)\n","Requirement already satisfied: tqdm>=4.28.1 in /usr/local/lib/python3.7/dist-packages (from fastNLP) (4.64.0)\n","Requirement already satisfied: prettytable>=0.7.2 in /usr/local/lib/python3.7/dist-packages (from fastNLP) (3.3.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from fastNLP) (2.23.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from fastNLP) (2019.12.20)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prettytable>=0.7.2->fastNLP) (0.2.5)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from prettytable>=0.7.2->fastNLP) (4.11.4)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.0.0->fastNLP) (4.2.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->prettytable>=0.7.2->fastNLP) (3.8.0)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->fastNLP) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->fastNLP) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->fastNLP) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->fastNLP) (2022.5.18.1)\n","Building wheels for collected packages: fastNLP\n","  Building wheel for fastNLP (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for fastNLP: filename=FastNLP-0.7.0-py3-none-any.whl size=364746 sha256=3642cf9d85b1ac518981a5249c234f5aa9915119d86ba33ce7d28cce54d8d40b\n","  Stored in directory: /root/.cache/pip/wheels/eb/80/db/f206d6f4481007868937e789999822fc879aad6e44ddcbcafa\n","Successfully built fastNLP\n","Installing collected packages: fastNLP\n","Successfully installed fastNLP-0.7.0\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers==3.4.0\n","  Downloading transformers-3.4.0-py3-none-any.whl (1.3 MB)\n","\u001b[K     |████████████████████████████████| 1.3 MB 32.7 MB/s \n","\u001b[?25hCollecting sacremoses\n","  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n","\u001b[K     |████████████████████████████████| 880 kB 57.5 MB/s \n","\u001b[?25hCollecting tokenizers==0.9.2\n","  Downloading tokenizers-0.9.2-cp37-cp37m-manylinux1_x86_64.whl (2.9 MB)\n","\u001b[K     |████████████████████████████████| 2.9 MB 57.9 MB/s \n","\u001b[?25hCollecting sentencepiece!=0.1.92\n","  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n","\u001b[K     |████████████████████████████████| 1.2 MB 59.4 MB/s \n","\u001b[?25hRequirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from transformers==3.4.0) (3.17.3)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==3.4.0) (2019.12.20)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==3.4.0) (2.23.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers==3.4.0) (1.21.6)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==3.4.0) (21.3)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==3.4.0) (4.64.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==3.4.0) (3.7.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==3.4.0) (3.0.9)\n","Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf->transformers==3.4.0) (1.15.0)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.4.0) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.4.0) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.4.0) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.4.0) (2022.5.18.1)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.4.0) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.4.0) (1.1.0)\n","Building wheels for collected packages: sacremoses\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895260 sha256=e30f2b9f70a97ac5cfb3fd9a147d347f6da78cf1f907f29a76139a804bab368f\n","  Stored in directory: /root/.cache/pip/wheels/87/39/dd/a83eeef36d0bf98e7a4d1933a4ad2d660295a40613079bafc9\n","Successfully built sacremoses\n","Installing collected packages: tokenizers, sentencepiece, sacremoses, transformers\n","Successfully installed sacremoses-0.0.53 sentencepiece-0.1.96 tokenizers-0.9.2 transformers-3.4.0\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","\u001b[31mERROR: Could not find a version that satisfies the requirement pytorch==1.7.1 (from versions: 0.1.2, 1.0.2)\u001b[0m\n","\u001b[31mERROR: No matching distribution found for pytorch==1.7.1\u001b[0m\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting fitlog\n","  Downloading fitlog-0.9.13.tar.gz (925 kB)\n","\u001b[K     |████████████████████████████████| 925 kB 26.6 MB/s \n","\u001b[?25hRequirement already satisfied: docopt>=0.6.2 in /usr/local/lib/python3.7/dist-packages (from fitlog) (0.6.2)\n","Requirement already satisfied: flask>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from fitlog) (1.1.4)\n","Requirement already satisfied: numpy>=1.16.4 in /usr/local/lib/python3.7/dist-packages (from fitlog) (1.21.6)\n","Collecting gitpython>=3.1.2\n","  Downloading GitPython-3.1.27-py3-none-any.whl (181 kB)\n","\u001b[K     |████████████████████████████████| 181 kB 46.6 MB/s \n","\u001b[?25hRequirement already satisfied: itsdangerous<2.0,>=0.24 in /usr/local/lib/python3.7/dist-packages (from flask>=1.0.2->fitlog) (1.1.0)\n","Requirement already satisfied: Werkzeug<2.0,>=0.15 in /usr/local/lib/python3.7/dist-packages (from flask>=1.0.2->fitlog) (1.0.1)\n","Requirement already satisfied: Jinja2<3.0,>=2.10.1 in /usr/local/lib/python3.7/dist-packages (from flask>=1.0.2->fitlog) (2.11.3)\n","Requirement already satisfied: click<8.0,>=5.1 in /usr/local/lib/python3.7/dist-packages (from flask>=1.0.2->fitlog) (7.1.2)\n","Collecting gitdb<5,>=4.0.1\n","  Downloading gitdb-4.0.9-py3-none-any.whl (63 kB)\n","\u001b[K     |████████████████████████████████| 63 kB 2.0 MB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from gitpython>=3.1.2->fitlog) (4.2.0)\n","Collecting smmap<6,>=3.0.1\n","  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2<3.0,>=2.10.1->flask>=1.0.2->fitlog) (2.0.1)\n","Building wheels for collected packages: fitlog\n","  Building wheel for fitlog (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for fitlog: filename=fitlog-0.9.13-py3-none-any.whl size=967495 sha256=c1415d48ff7e498318115fe4c2f3a24c47095996c1698db1cfb277402c4dc80b\n","  Stored in directory: /root/.cache/pip/wheels/7d/95/d4/a1a752c27fad922c452674b431fb58417ac6de1a530c8a6d05\n","Successfully built fitlog\n","Installing collected packages: smmap, gitdb, gitpython, fitlog\n","Successfully installed fitlog-0.9.13 gitdb-4.0.9 gitpython-3.1.27 smmap-5.0.0\n"]}],"source":["!pip install fastNLP\n","!pip install transformers==3.4.0\n","!pip install pytorch==1.7.1\n","!pip install fitlog"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"G7gO_HpreZuq"},"outputs":[],"source":["import pandas as pd\n","import glob\n","from tqdm import tqdm\n","import re\n","import itertools\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import f1_score\n","from sklearn.metrics import confusion_matrix\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from sklearn.metrics import recall_score,f1_score,precision_score,accuracy_score\n","import torch\n","from torch import nn"]},{"cell_type":"markdown","metadata":{"id":"im-ufjT0g6_L"},"source":["#Laptop-ACOS"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oolcZUHk1ClI"},"outputs":[],"source":["def adJusttab(input_file, output_file):\n","    lines_seen = set()  ### holds lines already seen\n","    outfile = open(output_file, \"w\", encoding='latin-1')\n","    for line in open(input_file, \"r\", encoding='latin-1'):\n","        arr = line.split(\"\\t\")\n","        arr[0 : 2] = ['\\t'.join(arr[0 : 2])]\n","        newline =' '.join(arr)\n","        outfile.write(newline)\n","    outfile.close()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gtiXrx492CDt"},"outputs":[],"source":["adJusttab(\"/content/drive/MyDrive/Sentiment Analysis/data/Laptop-ACOS/laptop_quad_dev.tsv\", \"/content/drive/MyDrive/Sentiment Analysis/data/Laptop-ACOS/laptop_quad_dev_adjusted.tsv\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3s5pVxss2eq0"},"outputs":[],"source":["adJusttab(\"/content/drive/MyDrive/Sentiment Analysis/data/Laptop-ACOS/laptop_quad_train.tsv\", \"/content/drive/MyDrive/Sentiment Analysis/data/Laptop-ACOS/laptop_quad_train_adjusted.tsv\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AS9XYEsfDhxi"},"outputs":[],"source":["adJusttab(\"/content/drive/MyDrive/Sentiment Analysis/data/Laptop-ACOS/laptop_quad_test.tsv\", \"/content/drive/MyDrive/Sentiment Analysis/data/Laptop-ACOS/laptop_quad_test_adjusted.tsv\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tqZ_evhKg1cu"},"outputs":[],"source":["dev_dataframe = pd.read_csv(\"/content/drive/MyDrive/Sentiment Analysis/data/Laptop-ACOS/laptop_quad_dev_adjusted.tsv\", sep='\\t',on_bad_lines='skip',names=[\"text\",\"label\"])\n","test_dataframe = pd.read_csv(\"/content/drive/MyDrive/Sentiment Analysis/data/Laptop-ACOS/laptop_quad_test_adjusted.tsv\", sep='\\t',on_bad_lines='skip',names=[\"text\",\"label\"])\n","train_dataframe = pd.read_csv(\"/content/drive/MyDrive/Sentiment Analysis/data/Laptop-ACOS/laptop_quad_train_adjusted.tsv\", sep='\\t',on_bad_lines='skip',names=[\"text\",\"label\"])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"58eOCiIWhNFf"},"outputs":[],"source":["print(train_dataframe)"]},{"cell_type":"markdown","metadata":{"id":"MQwocvOY5EEi"},"source":["#Restaurant-ACOS"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"p_aHU5ae5J_f"},"outputs":[],"source":["adJusttab(\"/content/drive/MyDrive/Sentiment Analysis/data/Restaurant-ACOS/rest16_quad_dev.tsv\", \"/content/drive/MyDrive/Sentiment Analysis/data/Restaurant-ACOS/rest16_quad_dev_adjusted.tsv\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ygAW5Zyb5J_g"},"outputs":[],"source":["adJusttab(\"/content/drive/MyDrive/Sentiment Analysis/data/Restaurant-ACOS/rest16_quad_test.tsv\", \"/content/drive/MyDrive/Sentiment Analysis/data/Restaurant-ACOS/rest16_quad_test_adjusted.tsv\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6t1c8mPI5J_g"},"outputs":[],"source":["adJusttab(\"/content/drive/MyDrive/Sentiment Analysis/data/Restaurant-ACOS/rest16_quad_train.tsv\", \"/content/drive/MyDrive/Sentiment Analysis/data/Restaurant-ACOS/rest16_quad_train_adjusted.tsv\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FUvv-oG15J_g"},"outputs":[],"source":["dev_dataframe = pd.read_csv(\"/content/drive/MyDrive/Sentiment Analysis/data/Restaurant-ACOS/rest16_quad_dev_adjusted.tsv\", sep='\\t',names=[\"text\",\"label\"])\n","test_dataframe = pd.read_csv(\"/content/drive/MyDrive/Sentiment Analysis/data/Restaurant-ACOS/rest16_quad_test_adjusted.tsv\", sep='\\t',names=[\"text\",\"label\"])\n","train_dataframe = pd.read_csv(\"/content/drive/MyDrive/Sentiment Analysis/data/Restaurant-ACOS/rest16_quad_train_adjusted.tsv\", sep='\\t',names=[\"text\",\"label\"])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":271,"status":"ok","timestamp":1649953802816,"user":{"displayName":"Duy Hoang","userId":"17457647490907439684"},"user_tz":-420},"id":"p07kqShB5J_h","outputId":"bb99f458-5297-483f-b826-a5525db1df28"},"outputs":[{"name":"stdout","output_type":"stream","text":["                                                   text  \\\n","0     judging from previous posts this used to be a ...   \n","1     we , there were four of us , arrived at noon -...   \n","2     they never brought us complimentary noodles , ...   \n","3     the food was lousy - too sweet or too salty an...   \n","4     after all that , they complained to me about t...   \n","...                                                 ...   \n","1525  i ca n ' t believe that it was , but please pu...   \n","1526  the waitress came to check in on us every few ...   \n","1527  i could n ' t ignore the fact that she reach o...   \n","1528  she then put the check down without asking if ...   \n","1529  i wish i could like this place more , and i wi...   \n","\n","                                                  label  \n","0                      10,11 RESTAURANT#GENERAL 0 13,16  \n","1                         19,20 SERVICE#GENERAL 0 31,32  \n","2                         -1,-1 SERVICE#GENERAL 0 -1,-1  \n","3     1,2 FOOD#QUALITY 0 3,4 1,2 FOOD#QUALITY 0 5,7 ...  \n","4                           -1,-1 SERVICE#GENERAL 0 5,6  \n","...                                                 ...  \n","1525                      -1,-1 SERVICE#GENERAL 0 -1,-1  \n","1526                        1,2 SERVICE#GENERAL 0 -1,-1  \n","1527                      -1,-1 SERVICE#GENERAL 0 -1,-1  \n","1528                      -1,-1 SERVICE#GENERAL 0 -1,-1  \n","1529  6,7 RESTAURANT#GENERAL 0 -1,-1 16,17 SERVICE#G...  \n","\n","[1530 rows x 2 columns]\n"]}],"source":["print(train_dataframe)"]},{"cell_type":"markdown","metadata":{"id":"5aRhKFHQ9yXY"},"source":["#Convert ACOS data to JSON"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FK-XtR_rMsKQ"},"outputs":[],"source":["def labelConversion(label):\n","    ret = []\n","    lstlabel = label.split(\" \")\n","    for i in range(0,len(lstlabel)):\n","        if i%4==0 or i%4==3:\n","            ret.extend(lstlabel[i].split(\",\"))\n","        else:\n","            ret.append(lstlabel[i])\n","    return ret"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DrVgonN493EM"},"outputs":[],"source":["\"\"\"words: List[str]\n","        aspects: [{\n","            'index': int\n","            'from': int\n","            'to': int\n","            'polarity': str\n","            'cat_obj':str\n","            'category':str\n","            'term': List[str]\n","        }],\n","        opinions: [{\n","            'index': int\n","            'from': int\n","            'to': int\n","            'term': List[str]\n","        }]\"\"\"\n","import json\n","def fromACOSToJSON(path):\n","    lst = []\n","    lst_aspect = []\n","    lst_opinion = []\n","    dict_templat = {}\n","    dict_template_aspect = {}\n","    dict_template_opinion = {}\n","    polarity = [\"NEG\",\"NEU\",\"POS\"]\n","    dev_dataframe = pd.read_csv(path, sep='\\t',on_bad_lines='skip',names=[\"text\",\"label\"])\n","    for i in range(0,len(dev_dataframe)):\n","        word = \"<<null>> \"+dev_dataframe.iloc[i][\"text\"]\n","        word.translate({\"/' \":\"'\"})\n","        dict_templat[\"raw_words\"] = word\n","        dict_templat[\"words\"] = word.split(\" \")\n","        labels = labelConversion(dev_dataframe.iloc[i][\"label\"])\n","        amount = int(len(labels)/6)\n","        for i in range(amount):\n","            dict_template_aspect[\"index\"] = i\n","            dict_template_opinion[\"index\"] = i\n","            pos = i*6\n","            if int(labels[pos])<0:\n","                dict_template_aspect[\"from\"] = 0\n","                dict_template_aspect[\"to\"] = 1\n","            else:\n","                dict_template_aspect[\"from\"] = int(labels[pos])+1\n","                dict_template_aspect[\"to\"] = int(labels[pos+1])+1\n","            cat1,cat2 =  labels[pos+2].split(\"#\")\n","            dict_template_aspect[\"cat_obj\"] = cat1\n","            dict_template_aspect[\"category\"] = cat2\n","            dict_template_aspect[\"term\"] = dict_templat[\"words\"][dict_template_aspect[\"from\"]:dict_template_aspect[\"to\"]] \n","            dict_template_aspect[\"polarity\"] = polarity[int(labels[pos+3])]\n","            if int(labels[pos+4])<0:\n","                dict_template_opinion[\"from\"] = 0\n","                dict_template_opinion[\"to\"] = 1\n","            else:\n","                dict_template_opinion[\"from\"] = int(labels[pos+4])+1\n","                dict_template_opinion[\"to\"] = int(labels[pos+5])+1\n","            dict_template_opinion[\"term\"] = dict_templat[\"words\"][dict_template_opinion[\"from\"]:dict_template_opinion[\"to\"]]\n","            lst_aspect.append(dict_template_aspect.copy())\n","            lst_opinion.append(dict_template_opinion.copy())\n","            dict_template_aspect={}\n","            dict_template_opinion={}\n","        dict_templat[\"aspects\"]=lst_aspect.copy()\n","        dict_templat[\"opinions\"]=lst_opinion.copy()\n","        lst_aspect = []\n","        lst_opinion = []\n","        lst.append(dict_templat.copy())\n","        dict_templat={}\n","    return json.dumps(lst)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HFYiPtnTZ9Lj"},"outputs":[],"source":["json_object = fromACOSToJSON(\"/content/drive/MyDrive/Sentiment Analysis/data/Restaurant-ACOS/rest16_quad_dev_adjusted.tsv\")\n","with open(\"/content/drive/MyDrive/Sentiment Analysis/data/Restaurant-ACOS/json/dev_convert.json\", \"w\") as outfile:\n","    outfile.write(json_object)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EPU_Cj_Fuji8"},"outputs":[],"source":["json_object =fromACOSToJSON(\"/content/drive/MyDrive/Sentiment Analysis/data/Restaurant-ACOS/rest16_quad_test_adjusted.tsv\")\n","with open(\"/content/drive/MyDrive/Sentiment Analysis/data/Restaurant-ACOS/json/test_convert.json\", \"w\") as outfile:\n","    outfile.write(json_object)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8FIKkqWquj7N"},"outputs":[],"source":["json_object =fromACOSToJSON(\"/content/drive/MyDrive/Sentiment Analysis/data/Restaurant-ACOS/rest16_quad_train_adjusted.tsv\")\n","with open(\"/content/drive/MyDrive/Sentiment Analysis/data/Restaurant-ACOS/json/train_convert.json\", \"w\") as outfile:\n","    outfile.write(json_object)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"auaXEPadCkzQ"},"outputs":[],"source":["l = ['MULTIMEDIA_DEVICES#PRICE', 'OS#QUALITY', 'SHIPPING#QUALITY', 'GRAPHICS#OPERATION_PERFORMANCE', 'CPU#OPERATION_PERFORMANCE', \n","        'COMPANY#DESIGN_FEATURES', 'MEMORY#OPERATION_PERFORMANCE', 'SHIPPING#PRICE', 'POWER_SUPPLY#CONNECTIVITY', 'SOFTWARE#USABILITY', \n","        'FANS&COOLING#GENERAL', 'GRAPHICS#DESIGN_FEATURES', 'BATTERY#GENERAL', 'HARD_DISC#USABILITY', 'FANS&COOLING#DESIGN_FEATURES', \n","        'MEMORY#DESIGN_FEATURES', 'MOUSE#USABILITY', 'CPU#GENERAL', 'LAPTOP#QUALITY', 'POWER_SUPPLY#GENERAL', 'PORTS#QUALITY', \n","        'KEYBOARD#PORTABILITY', 'SUPPORT#DESIGN_FEATURES', 'MULTIMEDIA_DEVICES#USABILITY', 'MOUSE#GENERAL', 'KEYBOARD#MISCELLANEOUS', \n","        'MULTIMEDIA_DEVICES#DESIGN_FEATURES', 'OS#MISCELLANEOUS', 'LAPTOP#MISCELLANEOUS', 'SOFTWARE#PRICE', 'FANS&COOLING#OPERATION_PERFORMANCE', \n","        'MEMORY#QUALITY', 'OPTICAL_DRIVES#OPERATION_PERFORMANCE', 'HARD_DISC#GENERAL', 'MEMORY#GENERAL', 'DISPLAY#OPERATION_PERFORMANCE', \n","        'MULTIMEDIA_DEVICES#GENERAL', 'LAPTOP#GENERAL', 'MOTHERBOARD#QUALITY', 'LAPTOP#PORTABILITY', 'KEYBOARD#PRICE', 'SUPPORT#OPERATION_PERFORMANCE', \n","        'GRAPHICS#GENERAL', 'MOTHERBOARD#OPERATION_PERFORMANCE', 'DISPLAY#GENERAL', 'BATTERY#QUALITY', 'LAPTOP#USABILITY', 'LAPTOP#DESIGN_FEATURES', \n","        'PORTS#CONNECTIVITY', 'HARDWARE#QUALITY', 'SUPPORT#GENERAL', 'MOTHERBOARD#GENERAL', 'PORTS#USABILITY', 'KEYBOARD#QUALITY', 'GRAPHICS#USABILITY', \n","        'HARD_DISC#PRICE', 'OPTICAL_DRIVES#USABILITY', 'MULTIMEDIA_DEVICES#CONNECTIVITY', 'HARDWARE#DESIGN_FEATURES', 'MEMORY#USABILITY', \n","        'SHIPPING#GENERAL', 'CPU#PRICE', 'Out_Of_Scope#DESIGN_FEATURES', 'MULTIMEDIA_DEVICES#QUALITY', 'OS#PRICE', 'SUPPORT#QUALITY', \n","        'OPTICAL_DRIVES#GENERAL', 'HARDWARE#USABILITY', 'DISPLAY#DESIGN_FEATURES', 'PORTS#GENERAL', 'COMPANY#OPERATION_PERFORMANCE', \n","        'COMPANY#GENERAL', 'Out_Of_Scope#GENERAL', 'KEYBOARD#DESIGN_FEATURES', 'Out_Of_Scope#OPERATION_PERFORMANCE', \n","        'OPTICAL_DRIVES#DESIGN_FEATURES', 'LAPTOP#OPERATION_PERFORMANCE', 'KEYBOARD#USABILITY', 'DISPLAY#USABILITY', 'POWER_SUPPLY#QUALITY', \n","        'HARD_DISC#DESIGN_FEATURES', 'DISPLAY#QUALITY', 'MOUSE#DESIGN_FEATURES', 'COMPANY#QUALITY', 'HARDWARE#GENERAL', 'COMPANY#PRICE', \n","        'MULTIMEDIA_DEVICES#OPERATION_PERFORMANCE', 'KEYBOARD#OPERATION_PERFORMANCE', 'SOFTWARE#PORTABILITY', 'HARD_DISC#OPERATION_PERFORMANCE', \n","        'BATTERY#DESIGN_FEATURES', 'CPU#QUALITY', 'WARRANTY#GENERAL', 'OS#DESIGN_FEATURES', 'OS#OPERATION_PERFORMANCE', 'OS#USABILITY', \n","        'SOFTWARE#GENERAL', 'SUPPORT#PRICE', 'SHIPPING#OPERATION_PERFORMANCE', 'DISPLAY#PRICE', 'LAPTOP#PRICE', 'OS#GENERAL', 'HARDWARE#PRICE', \n","        'SOFTWARE#DESIGN_FEATURES', 'HARD_DISC#MISCELLANEOUS', 'PORTS#PORTABILITY', 'FANS&COOLING#QUALITY', 'BATTERY#OPERATION_PERFORMANCE', \n","        'CPU#DESIGN_FEATURES', 'PORTS#OPERATION_PERFORMANCE', 'SOFTWARE#OPERATION_PERFORMANCE', 'KEYBOARD#GENERAL', 'SOFTWARE#QUALITY', \n","        'LAPTOP#CONNECTIVITY', 'POWER_SUPPLY#DESIGN_FEATURES', 'HARDWARE#OPERATION_PERFORMANCE', 'WARRANTY#QUALITY', 'HARD_DISC#QUALITY', \n","        'POWER_SUPPLY#OPERATION_PERFORMANCE', 'PORTS#DESIGN_FEATURES', 'Out_Of_Scope#USABILITY']"]},{"cell_type":"code","source":["laptop_obj =['<<MULTIMEDIA_DEVICES>>', '<<OS>>', '<<SHIPPING>>', '<<GRAPHICS>>', '<<CPU>>', '<<COMPANY>>', '<<MEMORY>>', '<<POWER_SUPPLY>>', \n","             '<<SOFTWARE>>', '<<FANS&COOLING>>', '<<BATTERY>>', '<<HARD_DISC>>', '<<MOUSE>>', '<<LAPTOP>>', '<<PORTS>>', '<<KEYBOARD>>', \n","             '<<SUPPORT>>', '<<OPTICAL_DRIVES>>', '<<DISPLAY>>', '<<MOTHERBOARD>>', '<<HARDWARE>>', '<<Out_Of_Scope>>', '<<WARRANTY>>']\n","laptop_catergory =['<<PRICE>>', '<<QUALITY>>', '<<OPERATION_PERFORMANCE>>', '<<DESIGN_FEATURES>>', '<<CONNECTIVITY>>', '<<USABILITY>>', \n","                   '<<GENERAL>>', '<<PORTABILITY>>', '<<MISCELLANEOUS>>']\n","                   \n","restaurant_obj =['<<RESTAURANT>>', '<<SERVICE>>', '<<FOOD>>', '<<DRINKS>>', '<<AMBIENCE>>', '<<LOCATION>>']\n","restaurant_catergory =['<<GENERAL>>', '<<QUALITY>>', '<<STYLE_OPTIONS>>', '<<PRICES>>', '<<MISCELLANEOUS>>']"],"metadata":{"id":"LZMP-zDdMxwZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ur1HXPDMclxI"},"outputs":[],"source":["laptop_obj =['<<MULTIMEDIA_DEVICES>>', '<<OS>>', '<<SHIPPING>>', '<<GRAPHICS>>', '<<CPU>>', '<<COMPANY>>', '<<MEMORY>>', '<<POWER_SUPPLY>>', \n","             '<<SOFTWARE>>', '<<FANS&COOLING>>', '<<BATTERY>>', '<<HARD_DISC>>', '<<MOUSE>>', '<<LAPTOP>>', '<<PORTS>>', '<<KEYBOARD>>', \n","             '<<SUPPORT>>', '<<OPTICAL_DRIVES>>', '<<DISPLAY>>', '<<MOTHERBOARD>>', '<<HARDWARE>>', '<<Out_Of_Scope>>', '<<WARRANTY>>']\n","laptop_catergory =['<<PRICE>>', '<<QUALITY>>', '<<OPERATION_PERFORMANCE>>', '<<DESIGN_FEATURES>>', '<<CONNECTIVITY>>', '<<USABILITY>>', \n","                   '<<GENERAL>>', '<<PORTABILITY>>', '<<MISCELLANEOUS>>']\n","laptop_obj_key = ['MULTIMEDIA_DEVICES', 'OS', 'SHIPPING', 'GRAPHICS', 'CPU', 'COMPANY', 'MEMORY', 'POWER_SUPPLY', 'SOFTWARE', 'FANS&COOLING', 'BATTERY', 'HARD_DISC', 'MOUSE', 'LAPTOP', 'PORTS', 'KEYBOARD', 'SUPPORT', 'OPTICAL_DRIVES', 'DISPLAY', 'MOTHERBOARD', 'HARDWARE', 'Out_Of_Scope', 'WARRANTY']\n","laptop_catergory_key = ['PRICE', 'QUALITY', 'OPERATION_PERFORMANCE', 'DESIGN_FEATURES', 'CONNECTIVITY', 'USABILITY', 'GENERAL', 'PORTABILITY', 'MISCELLANEOUS']\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jwhxyH02Du6E"},"outputs":[],"source":["l = ['RESTAURANT#GENERAL', 'SERVICE#GENERAL', 'FOOD#GENERAL', 'FOOD#QUALITY', 'FOOD#STYLE_OPTIONS', 'DRINKS#STYLE_OPTIONS', 'DRINKS#PRICES', \n","        'AMBIENCE#GENERAL', 'RESTAURANT#PRICES', 'FOOD#PRICES', 'RESTAURANT#MISCELLANEOUS', 'DRINKS#QUALITY', 'LOCATION#GENERAL']"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bBpp0tCii4N0"},"outputs":[],"source":["restaurant_obj =['<<RESTAURANT>>', '<<SERVICE>>', '<<FOOD>>', '<<DRINKS>>', '<<AMBIENCE>>', '<<LOCATION>>']\n","restaurant_catergory =['<<GENERAL>>', '<<QUALITY>>', '<<STYLE_OPTIONS>>', '<<PRICES>>', '<<MISCELLANEOUS>>']\n","restaurant_obj_key =['RESTAURANT', 'SERVICE', 'FOOD', 'DRINKS', 'AMBIENCE', 'LOCATION']\n","restaurant_catergory_key =['GENERAL', 'QUALITY', 'STYLE_OPTIONS', 'PRICES', 'MISCELLANEOUS']\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0lmWnXtFtYud"},"outputs":[],"source":["restaurant_obj_dict = dict(zip(restaurant_obj_key, restaurant_obj))\n","restaurant_catergory_dict = dict(zip(restaurant_catergory_key, restaurant_catergory))\n","laptop_obj_dict = dict(zip(laptop_obj_key, laptop_obj))\n","laptop_catergory_dict = dict(zip(laptop_catergory_key, laptop_catergory))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qjggXwnfK7nj"},"outputs":[],"source":["obj =[]\n","aspect= []\n","for i in l:\n","    check = i.split(\"#\")\n","    if check[0] not in obj:\n","        obj.append(check[0]) \n","    if check[1] not in aspect:\n","        aspect.append(check[1]) "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17,"status":"ok","timestamp":1649580246804,"user":{"displayName":"Duy Hoang","userId":"17457647490907439684"},"user_tz":-420},"id":"xmvfAlf-Dl47","outputId":"8f8999d3-a830-4f33-9741-c678419b9786"},"outputs":[{"name":"stdout","output_type":"stream","text":["['MULTIMEDIA_DEVICES', 'OS', 'SHIPPING', 'GRAPHICS', 'CPU', 'COMPANY', 'MEMORY', 'POWER_SUPPLY', 'SOFTWARE', 'FANS&COOLING', 'BATTERY', 'HARD_DISC', 'MOUSE', 'LAPTOP', 'PORTS', 'KEYBOARD', 'SUPPORT', 'OPTICAL_DRIVES', 'DISPLAY', 'MOTHERBOARD', 'HARDWARE', 'Out_Of_Scope', 'WARRANTY']\n","['PRICE', 'QUALITY', 'OPERATION_PERFORMANCE', 'DESIGN_FEATURES', 'CONNECTIVITY', 'USABILITY', 'GENERAL', 'PORTABILITY', 'MISCELLANEOUS']\n"]}],"source":["print(obj)\n","print(aspect)"]},{"cell_type":"markdown","metadata":{"id":"BWeNjY13jF5C"},"source":["#Implicit/Explicit Test set"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nbIobibajFQF"},"outputs":[],"source":["import json\n","def IEPartitioner(path):\n","    base = json.loads(open(path, \"r\").read())\n","    IAIO = []\n","    IAEO = []\n","    EAIO = []\n","    EAEO = []\n","    IAIO_template = {}\n","    IAEO_template = {}\n","    EAIO_template = {}\n","    EAEO_template = {}\n","    for i in base:\n","        IAIO_template = i.copy()\n","        IAEO_template = i.copy()\n","        EAIO_template = i.copy()\n","        EAEO_template = i.copy()\n","        IAIO_template[\"aspects\"],IAIO_template[\"opinions\"] = [],[]\n","        IAEO_template[\"aspects\"],IAEO_template[\"opinions\"] = [],[]\n","        EAIO_template[\"aspects\"],EAIO_template[\"opinions\"] = [],[]\n","        EAEO_template[\"aspects\"],EAEO_template[\"opinions\"] = [],[]\n","        for k in range(0,len(i[\"aspects\"])):\n","            if i[\"aspects\"][k][\"from\"]==0:\n","                if i[\"opinions\"][k][\"from\"]==0:\n","                    IAIO_template[\"aspects\"].append(i[\"aspects\"][k])\n","                    IAIO_template[\"opinions\"].append(i[\"opinions\"][k])\n","                else:\n","                    IAEO_template[\"aspects\"].append(i[\"aspects\"][k])\n","                    IAEO_template[\"opinions\"].append(i[\"opinions\"][k])\n","            else:\n","                if i[\"opinions\"][k][\"from\"]==0:\n","                    EAIO_template[\"aspects\"].append(i[\"aspects\"][k])\n","                    EAIO_template[\"opinions\"].append(i[\"opinions\"][k])\n","                else:\n","                    EAEO_template[\"aspects\"].append(i[\"aspects\"][k])\n","                    EAEO_template[\"opinions\"].append(i[\"opinions\"][k])\n","        if(len(IAIO_template[\"aspects\"])>0):\n","            IAIO.append(IAIO_template.copy())\n","        if(len(IAEO_template[\"aspects\"])>0):\n","            IAEO.append(IAEO_template.copy())\n","        if(len(EAIO_template[\"aspects\"])>0):\n","            EAIO.append(EAIO_template.copy())\n","        if(len(EAEO_template[\"aspects\"])>0):\n","            EAEO.append(EAEO_template.copy())  \n","        IAIO_template = {}\n","        IAEO_template = {}\n","        EAIO_template = {}\n","        EAEO_template = {}\n","    return json.dumps(IAIO),json.dumps(IAEO),json.dumps(EAIO),json.dumps(EAEO)\n","IAIO,IAEO,EAIO,EAEO = IEPartitioner(\"/content/drive/MyDrive/Sentiment Analysis/data/Laptop-ACOS/json/test_convert.json\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TnA5KZ7asLxD"},"outputs":[],"source":["with open(\"/content/drive/MyDrive/Sentiment Analysis/data/Laptop-ACOS/json/Implicit Explicit/IAIO.json\", \"w\") as outfile:\n","    outfile.write(IAIO)\n","with open(\"/content/drive/MyDrive/Sentiment Analysis/data/Laptop-ACOS/json/Implicit Explicit/IAEO.json\", \"w\") as outfile:\n","    outfile.write(IAEO)\n","with open(\"/content/drive/MyDrive/Sentiment Analysis/data/Laptop-ACOS/json/Implicit Explicit/EAIO.json\", \"w\") as outfile:\n","    outfile.write(EAIO)\n","with open(\"/content/drive/MyDrive/Sentiment Analysis/data/Laptop-ACOS/json/Implicit Explicit/EAEO.json\", \"w\") as outfile:\n","    outfile.write(EAEO)"]},{"cell_type":"markdown","metadata":{"id":"dCtAWimziVXR"},"source":["# Data pipeline"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Z3rcZPOhhJKB"},"outputs":[],"source":["from fastNLP.io import Pipe, DataBundle, Loader\n","import os\n","import json\n","from fastNLP import DataSet, Instance\n","from transformers import AutoTokenizer\n","import numpy as np\n","from itertools import chain\n","from functools import cmp_to_key\n","\n","\n","def cmp_aspect(v1, v2):\n","    if v1[0]['from']==v2[0]['from']:\n","        return v1[1]['from'] - v2[1]['from']\n","    return v1[0]['from'] - v2[0]['from']\n","\n","def cmp_opinion(v1, v2):\n","    if v1[1]['from']==v2[1]['from']:\n","        return v1[0]['from'] - v2[0]['from']\n","    return v1[1]['from'] - v2[1]['from']\n","\n","\n","class BartBPEABSAPipe(Pipe):\n","    def __init__(self, tokenizer='facebook/bart-base', opinion_first=False):\n","        super(BartBPEABSAPipe, self).__init__()\n","        self.tokenizer = AutoTokenizer.from_pretrained(tokenizer)\n","        self.tokenizer.add_tokens(\"<<null>>\")\n","        self.mapping = laptop_obj_dict\n","        self.mapping.update(laptop_catergory_dict)\n","        self.mapping.update({  # so that the label word can be initialized in a better embedding.\n","            'POS': '<<positive>>',\n","            'NEG': '<<negative>>',\n","            'NEU': '<<neutral>>'\n","        })\n","        self.opinion_first = opinion_first  # 是否先生成opinion\n","        cur_num_tokens = self.tokenizer.vocab_size\n","        self.cur_num_token = cur_num_tokens\n","  \n","        tokens_to_add = sorted(list(self.mapping.values()), key=lambda x:len(x), reverse=True)\n","        unique_no_split_tokens = self.tokenizer.unique_no_split_tokens\n","        sorted_add_tokens = sorted(list(tokens_to_add), key=lambda x:len(x), reverse=True)\n","        for tok in sorted_add_tokens:\n","            assert self.tokenizer.convert_tokens_to_ids([tok])[0]==self.tokenizer.unk_token_id\n","        self.tokenizer.unique_no_split_tokens = unique_no_split_tokens + sorted_add_tokens\n","        self.tokenizer.add_tokens(sorted_add_tokens)\n","        \n","        self.mapping2id = {}\n","        self.mapping2targetid = {}\n","\n","        for key, value in self.mapping.items():\n","            key_id = self.tokenizer.convert_tokens_to_ids(self.tokenizer.tokenize(value))\n","            assert len(key_id) == 1, value\n","            assert key_id[0] >= cur_num_tokens\n","            self.mapping2id[key] = key_id[0]\n","            self.mapping2targetid[key] = len(self.mapping2targetid)\n","\n","    def process(self, data_bundle: DataBundle) -> DataBundle:\n","        \"\"\"\n","        words: List[str]\n","        aspects: [{\n","            'index': int\n","            'from': int\n","            'to': int\n","            'polarity': str\n","            'cat_obj':str\n","            'category':str\n","            'term': List[str]\n","        }],\n","        opinions: [{\n","            'index': int\n","            'from': int\n","            'to': int\n","            'term': List[str]\n","        }]\n","        输出为[o_s, o_e, a_s, a_e, c]或者[a_s, a_e, o_s, o_e, c]\n","        :param data_bundle:\n","        :return:\n","        \"\"\"\n","        target_shift = len(self.mapping) + 2  # 是由于第一位是sos，紧接着是eos, 然后是\n","\n","        def prepare_target(ins):\n","            raw_words = ins['raw_words']\n","            word_bpes = [[self.tokenizer.bos_token_id]]\n","            for word in raw_words:\n","                bpes = self.tokenizer.tokenize(word, add_prefix_space=True)\n","                bpes = self.tokenizer.convert_tokens_to_ids(bpes)\n","                word_bpes.append(bpes)\n","            word_bpes.append([self.tokenizer.eos_token_id])\n","\n","            lens = list(map(len, word_bpes))\n","            cum_lens = np.cumsum(list(lens)).tolist()\n","            target = [0]  # 特殊的开始\n","            target_spans = []\n","            _word_bpes = list(chain(*word_bpes))\n","            aspects_opinions = [(a, o) for a, o in zip(ins['aspects'], ins['opinions'])]\n","            if self.opinion_first:\n","                aspects_opinions = sorted(aspects_opinions, key=cmp_to_key(cmp_opinion))\n","            else:\n","                aspects_opinions = sorted(aspects_opinions, key=cmp_to_key(cmp_aspect))\n","\n","            for aspects, opinions in aspects_opinions:  # 预测bpe的start\n","                assert aspects['index'] == opinions['index']\n","                a_start_bpe = cum_lens[aspects['from']]  # 因为有一个sos shift\n","                a_end_bpe = cum_lens[aspects['to']-1]  # 这里由于之前是开区间，刚好取到最后一个word的开头\n","                o_start_bpe = cum_lens[opinions['from']]  # 因为有一个sos shift\n","                o_end_bpe = cum_lens[opinions['to']-1]  # 因为有一个sos shift\n","                # 这里需要evaluate是否是对齐的\n","                for idx, word in zip((o_start_bpe, o_end_bpe, a_start_bpe, a_end_bpe),\n","                                     (opinions['term'][0], opinions['term'][-1], aspects['term'][0], aspects['term'][-1])):\n","                    assert _word_bpes[idx] == self.tokenizer.convert_tokens_to_ids(self.tokenizer.tokenize(word, add_prefix_space=True)[:1])[0] or \\\n","                           _word_bpes[idx] == self.tokenizer.convert_tokens_to_ids(self.tokenizer.tokenize(word, add_prefix_space=True)[-1:])[0]\n","\n","                if self.opinion_first:\n","                    target_spans.append([o_start_bpe+target_shift, o_end_bpe+target_shift,\n","                                         a_start_bpe+target_shift, a_end_bpe+target_shift,\n","                                         self.mapping2targetid[aspects['cat_obj']]+2,\n","                                         self.mapping2targetid[aspects['category']]+2])\n","                else:\n","                    target_spans.append([a_start_bpe+target_shift, a_end_bpe+target_shift,\n","                                         self.mapping2targetid[aspects['cat_obj']]+2,\n","                                         self.mapping2targetid[aspects['category']]+2,\n","                                         o_start_bpe+target_shift, o_end_bpe+target_shift])\n","                target_spans[-1].append(self.mapping2targetid[aspects['polarity']]+2)   # 前面有sos和eos\n","                target_spans[-1] = tuple(target_spans[-1])\n","            target.extend(list(chain(*target_spans)))\n","            target.append(1)  # append 1是由于特殊的eos\n","            return {'tgt_tokens': target, 'target_span': target_spans, 'src_tokens': list(chain(*word_bpes))}\n","\n","        data_bundle.apply_more(prepare_target, use_tqdm=True, tqdm_desc='Pre. tgt.')\n","\n","        data_bundle.set_ignore_type('target_span')\n","        data_bundle.set_pad_val('tgt_tokens', 1)  # 设置为eos所在的id\n","        data_bundle.set_pad_val('src_tokens', self.tokenizer.pad_token_id)\n","\n","        data_bundle.apply_field(lambda x: len(x), field_name='src_tokens', new_field_name='src_seq_len')\n","        data_bundle.apply_field(lambda x: len(x), field_name='tgt_tokens', new_field_name='tgt_seq_len')\n","        data_bundle.set_input('tgt_tokens', 'src_tokens', 'src_seq_len', 'tgt_seq_len')\n","        data_bundle.set_target('tgt_tokens', 'tgt_seq_len', 'target_span')\n","\n","        return data_bundle\n","\n","    def process_from_file(self, paths, demo=False) -> DataBundle:\n","        \"\"\"\n","        :param paths: 支持路径类型参见 :class:`fastNLP.io.loader.ConllLoader` 的load函数。\n","        :return: DataBundle\n","        \"\"\"\n","        # 读取数据\n","        data_bundle = ABSALoader(demo=demo).load(paths)\n","        data_bundle = self.process(data_bundle)\n","\n","        return data_bundle\n","\n","\n","class ABSALoader(Loader):\n","    def __init__(self, demo=False):\n","        super().__init__()\n","        self.demo = demo\n","\n","    def _load(self, path):\n","        with open(path, 'r', encoding='utf-8') as f:\n","            data = json.load(f)\n","        ds = DataSet()\n","        for ins in data:\n","            tokens = ins['words']\n","            aspects = ins['aspects']\n","            opinions = ins['opinions']\n","            assert len(aspects)==len(opinions)\n","            ins = Instance(raw_words=tokens, aspects=aspects, opinions=opinions)\n","            ds.append(ins)\n","            if self.demo and len(ds)>30:\n","                break\n","        return ds\n","\n"]},{"cell_type":"markdown","metadata":{"id":"HcuQh7sVUPq5"},"source":["# BART code"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZijvJnk-XLE5"},"outputs":[],"source":["# Copyright 2020 The Facebook AI Research Team Authors and The HuggingFace Inc. team.\n","#\n","# Licensed under the Apache License, Version 2.0 (the \"License\");\n","# you may not use this file except in compliance with the License.\n","# You may obtain a copy of the License at\n","#\n","#     http://www.apache.org/licenses/LICENSE-2.0\n","#\n","# Unless required by applicable law or agreed to in writing, software\n","# distributed under the License is distributed on an \"AS IS\" BASIS,\n","# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","# See the License for the specific language governing permissions and\n","# limitations under the License.\n","\"\"\"PyTorch BART model, ported from the fairseq repo.\"\"\"\n","import math\n","import random\n","import warnings\n","from typing import Dict, List, Optional, Tuple\n","\n","import numpy as np\n","import torch\n","import torch.nn.functional as F\n","from torch import Tensor, nn\n","from torch.nn import CrossEntropyLoss\n","\n","from transformers.modeling_bart import *\n","\n","logger = logging.get_logger(__name__)\n","\n","_CONFIG_FOR_DOC = \"BartConfig\"\n","_TOKENIZER_FOR_DOC = \"BartTokenizer\"\n","\n","BART_PRETRAINED_MODEL_ARCHIVE_LIST = [\n","    \"facebook/bart-base\",\n","    \"facebook/bart-large\",\n","    \"facebook/bart-large-mnli\",\n","    \"facebook/bart-large-cnn\",\n","    \"facebook/bart-large-xsum\",\n","    \"facebook/mbart-large-en-ro\",\n","]\n","# This list is incomplete. See all BART models at https://huggingface.co/models?filter=bart\n","\n","\n","BART_START_DOCSTRING = r\"\"\"\n","    This model inherits from :class:`~transformers.PreTrainedModel`. Check the superclass documentation for the generic\n","    methods the library implements for all its model (such as downloading or saving, resizing the input embeddings,\n","    pruning heads etc.)\n","    This model is also a PyTorch `torch.nn.Module <https://pytorch.org/docs/stable/nn.html#torch.nn.Module>`__ subclass.\n","    Use it as a regular PyTorch Module and refer to the PyTorch documentation for all matter related to general\n","    usage and behavior.\n","    Parameters:\n","        config (:class:`~transformers.BartConfig`): Model configuration class with all the parameters of the model.\n","            Initializing with a config file does not load the weights associated with the model, only the configuration.\n","            Check out the :meth:`~transformers.PreTrainedModel.from_pretrained` method to load the model weights.\n","\"\"\"\n","\n","BART_GENERATION_EXAMPLE = r\"\"\"\n","    Summarization example::\n","        >>> from transformers import BartTokenizer, BartForConditionalGeneration, BartConfig\n","        >>> # see ``examples/summarization/bart/run_eval.py`` for a longer example\n","        >>> model = BartForConditionalGeneration.from_pretrained('facebook/bart-large-cnn')\n","        >>> tokenizer = BartTokenizer.from_pretrained('facebook/bart-large-cnn')\n","        >>> ARTICLE_TO_SUMMARIZE = \"My friends are cool but they eat too many carbs.\"\n","        >>> inputs = tokenizer([ARTICLE_TO_SUMMARIZE], max_length=1024, return_tensors='pt')\n","        >>> # Generate Summary\n","        >>> summary_ids = model.generate(inputs['input_ids'], num_beams=4, max_length=5, early_stopping=True)\n","        >>> print([tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=False) for g in summary_ids])\n","\"\"\"\n","\n","BART_INPUTS_DOCSTRING = r\"\"\"\n","    Args:\n","        input_ids (:obj:`torch.LongTensor` of shape :obj:`(batch_size, sequence_length)`):\n","            Indices of input sequence tokens in the vocabulary. Padding will be ignored by default should you provide\n","            it.\n","            Indices can be obtained using :class:`~transformers.BartTokenizer`.\n","            See :meth:`transformers.PreTrainedTokenizer.encode` and\n","            :meth:`transformers.PreTrainedTokenizer.__call__` for details.\n","            `What are input IDs? <../glossary.html#input-ids>`__\n","        attention_mask (:obj:`torch.Tensor` of shape :obj:`(batch_size, sequence_length)`, `optional`):\n","            Mask to avoid performing attention on padding token indices.\n","            Mask values selected in ``[0, 1]``:\n","            - 1 for tokens that are **not masked**,\n","            - 0 for tokens that are **masked**.\n","            `What are attention masks? <../glossary.html#attention-mask>`__\n","        decoder_input_ids (:obj:`torch.LongTensor` of shape :obj:`(batch_size, target_sequence_length)`, `optional`):\n","            Provide for translation and summarization training. By default, the model will create this tensor by\n","            shifting the :obj:`input_ids` to the right, following the paper.\n","        decoder_attention_mask (:obj:`torch.BoolTensor` of shape :obj:`(batch_size, tgt_seq_len)`, `optional`):\n","            Default behavior: generate a tensor that ignores pad tokens in :obj:`decoder_input_ids`. Causal mask will\n","            also be used by default.\n","            If you want to change padding behavior, you should read :func:`modeling_bart._prepare_decoder_inputs` and\n","            modify to your needs. See diagram 1 in `the paper <https://arxiv.org/abs/1910.13461>`__ for more\n","            information on the default strategy.\n","        encoder_outputs (:obj:`tuple(tuple(torch.FloatTensor)`, `optional`):\n","            Tuple consists of (:obj:`last_hidden_state`, `optional`: :obj:`hidden_states`, `optional`: :obj:`attentions`)\n","            :obj:`last_hidden_state` of shape :obj:`(batch_size, sequence_length, hidden_size)`, `optional`) is a\n","            sequence of hidden-states at the output of the last layer of the encoder. Used in the cross-attention of\n","            the decoder.\n","        past_key_values (:obj:`tuple(tuple(torch.FloatTensor))` of length :obj:`config.n_layers` with each tuple having 4 tensors of shape :obj:`(batch_size, num_heads, sequence_length - 1, embed_size_per_head)`):\n","            Contains precomputed key and value hidden-states of the attention blocks. Can be used to speed up decoding.\n","            If :obj:`past_key_values` are used, the user can optionally input only the last\n","            ``decoder_input_ids`` (those that don't have their past key value states given to this model) of shape\n","            :obj:`(batch_size, 1)` instead of all ``decoder_input_ids`` of shape :obj:`(batch_size, sequence_length)`.\n","        use_cache (:obj:`bool`, `optional`):\n","            If set to :obj:`True`, :obj:`past_key_values` key value states are returned and can be used to speed up\n","            decoding (see :obj:`past_key_values`).\n","        output_attentions (:obj:`bool`, `optional`):\n","            Whether or not to return the attentions tensors of all attention layers. See ``attentions`` under returned\n","            tensors for more detail.\n","        output_hidden_states (:obj:`bool`, `optional`):\n","            Whether or not to return the hidden states of all layers. See ``hidden_states`` under returned tensors for\n","            more detail.\n","        return_dict (:obj:`bool`, `optional`):\n","            Whether or not to return a :class:`~transformers.file_utils.ModelOutput` instead of a plain tuple.\n","\"\"\"\n","\n","\n","def invert_mask(attention_mask):\n","    \"\"\"Turns 1->0, 0->1, False->True, True-> False\"\"\"\n","    assert attention_mask.dim() == 2\n","    return attention_mask.eq(0)\n","\n","\n","def _prepare_bart_decoder_inputs(\n","        config, input_ids, decoder_input_ids=None, decoder_padding_mask=None, causal_mask_dtype=torch.float32\n","):\n","    \"\"\"Prepare masks that ignore padding tokens in the decoder and a causal mask for the decoder if\n","    none are provided. This mimics the default behavior in fairseq. To override it pass in masks.\n","    Note: this is not called during generation\n","    \"\"\"\n","    pad_token_id = config.pad_token_id\n","    if decoder_input_ids is None:\n","        decoder_input_ids = shift_tokens_right(input_ids, pad_token_id)\n","    bsz, tgt_len = decoder_input_ids.size()\n","    if decoder_padding_mask is None:\n","        decoder_padding_mask = make_padding_mask(decoder_input_ids, pad_token_id)\n","    else:\n","        decoder_padding_mask = invert_mask(decoder_padding_mask)\n","    if decoder_padding_mask is not None and decoder_padding_mask.shape[1] > 1:\n","        # never mask leading token, even if it is pad\n","        decoder_padding_mask[:, 0] = decoder_padding_mask[:, 1]\n","    tmp = fill_with_neg_inf(torch.zeros(tgt_len, tgt_len))\n","    mask = torch.arange(tmp.size(-1))\n","    tmp.masked_fill_(mask < (mask + 1).view(tmp.size(-1), 1), 0)\n","    causal_mask = tmp.to(dtype=causal_mask_dtype, device=decoder_input_ids.device)\n","    return decoder_input_ids, decoder_padding_mask, causal_mask\n","\n","\n","class PretrainedBartModel(PreTrainedModel):\n","    config_class = BartConfig\n","    base_model_prefix = \"model\"\n","\n","    def _init_weights(self, module):\n","        std = self.config.init_std\n","        if isinstance(module, nn.Linear):\n","            module.weight.data.normal_(mean=0.0, std=std)\n","            if module.bias is not None:\n","                module.bias.data.zero_()\n","        elif isinstance(module, SinusoidalPositionalEmbedding):\n","            pass\n","        elif isinstance(module, nn.Embedding):\n","            module.weight.data.normal_(mean=0.0, std=std)\n","            if module.padding_idx is not None:\n","                module.weight.data[module.padding_idx].zero_()\n","\n","    @property\n","    def dummy_inputs(self):\n","        pad_token = self.config.pad_token_id\n","        input_ids = torch.tensor([[0, 6, 10, 4, 2], [0, 8, 12, 2, pad_token]], device=self.device)\n","        dummy_inputs = {\n","            \"attention_mask\": input_ids.ne(pad_token),\n","            \"input_ids\": input_ids,\n","        }\n","        return dummy_inputs\n","\n","\n","def _make_linear_from_emb(emb):\n","    vocab_size, emb_size = emb.weight.shape\n","    lin_layer = nn.Linear(vocab_size, emb_size, bias=False)\n","    lin_layer.weight.data = emb.weight.data\n","    return lin_layer\n","\n","\n","# Helper Functions, mostly for making masks\n","def _check_shapes(shape_1, shape2):\n","    if shape_1 != shape2:\n","        raise AssertionError(\"shape mismatch: {} != {}\".format(shape_1, shape2))\n","\n","\n","def shift_tokens_right(input_ids, pad_token_id):\n","    \"\"\"Shift input ids one token to the right, and wrap the last non pad token (usually <eos>).\"\"\"\n","    prev_output_tokens = input_ids.clone()\n","    index_of_eos = (input_ids.ne(pad_token_id).sum(dim=1) - 1).unsqueeze(-1)\n","    prev_output_tokens[:, 0] = input_ids.gather(1, index_of_eos).squeeze()\n","    prev_output_tokens[:, 1:] = input_ids[:, :-1]\n","    return prev_output_tokens\n","\n","\n","def make_padding_mask(input_ids, padding_idx=1):\n","    \"\"\"True for pad tokens\"\"\"\n","    padding_mask = input_ids.eq(padding_idx)\n","    if not padding_mask.any():\n","        padding_mask = None\n","    return padding_mask\n","\n","\n","# Helper Modules\n","\n","\n","class EncoderLayer(nn.Module):\n","    def __init__(self, config: BartConfig):\n","        super().__init__()\n","        self.embed_dim = config.d_model\n","        self.self_attn = Attention(self.embed_dim, config.encoder_attention_heads, dropout=config.attention_dropout)\n","        self.normalize_before = config.normalize_before\n","        self.self_attn_layer_norm = LayerNorm(self.embed_dim)\n","        self.dropout = config.dropout\n","        self.activation_fn = ACT2FN[config.activation_function]\n","        self.activation_dropout = config.activation_dropout\n","        self.fc1 = nn.Linear(self.embed_dim, config.encoder_ffn_dim)\n","        self.fc2 = nn.Linear(config.encoder_ffn_dim, self.embed_dim)\n","        self.final_layer_norm = LayerNorm(self.embed_dim)\n","\n","    def forward(self, x, encoder_padding_mask, output_attentions=False):\n","        \"\"\"\n","        Args:\n","            x (Tensor): input to the layer of shape `(seq_len, batch, embed_dim)`\n","            encoder_padding_mask (ByteTensor): binary ByteTensor of shape\n","                `(batch, src_len)` where padding elements are indicated by ``1``.\n","            for t_tgt, t_src is excluded (or masked out), =0 means it is\n","            included in attention\n","        Returns:\n","            encoded output of shape `(seq_len, batch, embed_dim)`\n","        \"\"\"\n","        residual = x\n","        if self.normalize_before:\n","            x = self.self_attn_layer_norm(x)\n","        x, attn_weights = self.self_attn(\n","            query=x, key=x, key_padding_mask=encoder_padding_mask, output_attentions=output_attentions\n","        )\n","        x = F.dropout(x, p=self.dropout, training=self.training)\n","        x = residual + x\n","        if not self.normalize_before:\n","            x = self.self_attn_layer_norm(x)\n","\n","        residual = x\n","        if self.normalize_before:\n","            x = self.final_layer_norm(x)\n","        x = self.activation_fn(self.fc1(x))\n","        x = F.dropout(x, p=self.activation_dropout, training=self.training)\n","        x = self.fc2(x)\n","        x = F.dropout(x, p=self.dropout, training=self.training)\n","        x = residual + x\n","        if not self.normalize_before:\n","            x = self.final_layer_norm(x)\n","        if torch.isinf(x).any() or torch.isnan(x).any():\n","            clamp_value = torch.finfo(x.dtype).max - 1000\n","            x = torch.clamp(x, min=-clamp_value, max=clamp_value)\n","        return x, attn_weights\n","\n","\n","class BartEncoder(nn.Module):\n","    \"\"\"\n","    Transformer encoder consisting of *config.encoder_layers* self attention layers. Each layer\n","    is a :class:`EncoderLayer`.\n","    Args:\n","        config: BartConfig\n","    \"\"\"\n","\n","    def __init__(self, config: BartConfig, embed_tokens):\n","        super().__init__()\n","\n","        self.dropout = config.dropout\n","        self.layerdrop = config.encoder_layerdrop\n","\n","        embed_dim = embed_tokens.embedding_dim\n","        self.embed_scale = math.sqrt(embed_dim) if config.scale_embedding else 1.0\n","        self.padding_idx = embed_tokens.padding_idx\n","        self.max_source_positions = config.max_position_embeddings\n","\n","        self.embed_tokens = embed_tokens\n","        if config.static_position_embeddings:\n","            self.embed_positions = SinusoidalPositionalEmbedding(\n","                config.max_position_embeddings, embed_dim, self.padding_idx\n","            )\n","        else:\n","            self.embed_positions = LearnedPositionalEmbedding(\n","                config.max_position_embeddings,\n","                embed_dim,\n","                self.padding_idx,\n","                config.extra_pos_embeddings,\n","            )\n","        self.layers = nn.ModuleList([EncoderLayer(config) for _ in range(config.encoder_layers)])\n","        self.layernorm_embedding = LayerNorm(embed_dim) if config.normalize_embedding else nn.Identity()\n","        # mbart has one extra layer_norm\n","        self.layer_norm = LayerNorm(config.d_model) if config.add_final_layer_norm else None\n","\n","    def forward(\n","            self, input_ids, attention_mask=None, output_attentions=False, output_hidden_states=False, return_dict=False\n","    ):\n","        \"\"\"\n","        Args:\n","            input_ids (LongTensor): tokens in the source language of shape\n","                `(batch, src_len)`\n","            attention_mask (torch.LongTensor): indicating which indices are padding tokens.\n","        Returns:\n","            BaseModelOutput or Tuple comprised of:\n","                - **x** (Tensor): the last encoder layer's output of\n","                  shape `(src_len, batch, embed_dim)`\n","                - **encoder_states** (tuple(torch.FloatTensor)): all intermediate\n","                  hidden states of shape `(src_len, batch, embed_dim)`.\n","                  Only populated if *output_hidden_states:* is True.\n","                - **all_attentions** (tuple(torch.FloatTensor)): Attention weights for each layer.\n","                During training might not be of length n_layers because of layer dropout.\n","        \"\"\"\n","        # check attention mask and invert\n","        if attention_mask is not None:\n","            attention_mask = invert_mask(attention_mask)\n","\n","        inputs_embeds = self.embed_tokens(input_ids) * self.embed_scale\n","        embed_pos = self.embed_positions(input_ids)\n","        x = inputs_embeds + embed_pos\n","        x = self.layernorm_embedding(x)\n","        x = F.dropout(x, p=self.dropout, training=self.training)\n","\n","        # B x T x C -> T x B x C\n","        x = x.transpose(0, 1)\n","\n","        encoder_states = [] if output_hidden_states else None\n","        all_attentions = () if output_attentions else None\n","        for encoder_layer in self.layers:\n","            if output_hidden_states:\n","                encoder_states.append(x)\n","            # add LayerDrop (see https://arxiv.org/abs/1909.11556 for description)\n","            dropout_probability = random.uniform(0, 1)\n","            if self.training and (dropout_probability < self.layerdrop):  # skip the layer\n","                attn = None\n","            else:\n","                x, attn = encoder_layer(x, attention_mask, output_attentions=output_attentions)\n","\n","            if output_attentions:\n","                all_attentions = all_attentions + (attn,)\n","\n","        if self.layer_norm:\n","            x = self.layer_norm(x)\n","        if output_hidden_states:\n","            encoder_states.append(x)\n","            # T x B x C -> B x T x C\n","            encoder_states = tuple(hidden_state.transpose(0, 1) for hidden_state in encoder_states)\n","\n","        # T x B x C -> B x T x C\n","        x = x.transpose(0, 1)\n","\n","        if not return_dict:\n","            return tuple(v for v in [x, encoder_states, all_attentions] if v is not None)\n","        return BaseModelOutput(last_hidden_state=x, hidden_states=encoder_states, attentions=all_attentions)\n","\n","\n","class DecoderLayer(nn.Module):\n","    def __init__(self, config: BartConfig):\n","        super().__init__()\n","        self.embed_dim = config.d_model\n","\n","        self.self_attn = Attention(\n","            embed_dim=self.embed_dim,\n","            num_heads=config.decoder_attention_heads,\n","            dropout=config.attention_dropout,\n","        )\n","        self.dropout = config.dropout\n","        self.activation_fn = ACT2FN[config.activation_function]\n","        self.activation_dropout = config.activation_dropout\n","        self.normalize_before = config.normalize_before\n","\n","        self.self_attn_layer_norm = LayerNorm(self.embed_dim)\n","        self.encoder_attn = Attention(\n","            self.embed_dim,\n","            config.decoder_attention_heads,\n","            dropout=config.attention_dropout,\n","            encoder_decoder_attention=True,\n","        )\n","        self.encoder_attn_layer_norm = LayerNorm(self.embed_dim)\n","        self.fc1 = nn.Linear(self.embed_dim, config.decoder_ffn_dim)\n","        self.fc2 = nn.Linear(config.decoder_ffn_dim, self.embed_dim)\n","        self.final_layer_norm = LayerNorm(self.embed_dim)\n","\n","    def forward(\n","            self,\n","            x,\n","            encoder_hidden_states,\n","            encoder_attn_mask=None,\n","            layer_state=None,\n","            causal_mask=None,\n","            decoder_padding_mask=None,\n","            output_attentions=False,\n","    ):\n","        residual = x\n","\n","        if layer_state is None:\n","            layer_state = {}\n","        if self.normalize_before:\n","            x = self.self_attn_layer_norm(x)\n","        # Self Attention\n","\n","        x, self_attn_weights = self.self_attn(\n","            query=x,\n","            key=x,\n","            layer_state=layer_state,  # adds keys to layer state\n","            key_padding_mask=decoder_padding_mask,\n","            attn_mask=causal_mask,\n","            output_attentions=output_attentions,\n","        )\n","        x = F.dropout(x, p=self.dropout, training=self.training)\n","        x = residual + x\n","        if not self.normalize_before:\n","            x = self.self_attn_layer_norm(x)\n","\n","        # Cross attention\n","        residual = x\n","        assert self.encoder_attn.cache_key != self.self_attn.cache_key\n","        if self.normalize_before:\n","            x = self.encoder_attn_layer_norm(x)\n","        x, _ = self.encoder_attn(\n","            query=x,\n","            key=encoder_hidden_states,\n","            key_padding_mask=encoder_attn_mask,\n","            layer_state=layer_state,  # mutates layer state\n","        )\n","        x = F.dropout(x, p=self.dropout, training=self.training)\n","        x = residual + x\n","        if not self.normalize_before:\n","            x = self.encoder_attn_layer_norm(x)\n","\n","        # Fully Connected\n","        residual = x\n","        if self.normalize_before:\n","            x = self.final_layer_norm(x)\n","        x = self.activation_fn(self.fc1(x))\n","        x = F.dropout(x, p=self.activation_dropout, training=self.training)\n","        x = self.fc2(x)\n","        x = F.dropout(x, p=self.dropout, training=self.training)\n","        x = residual + x\n","        if not self.normalize_before:\n","            x = self.final_layer_norm(x)\n","        return (\n","            x,\n","            self_attn_weights,\n","            layer_state,\n","        )  # just self_attn weights for now, following t5, layer_state = cache for decoding\n","\n","\n","class BartDecoder(nn.Module):\n","    \"\"\"\n","    Transformer decoder consisting of *config.decoder_layers* layers. Each layer\n","    is a :class:`DecoderLayer`.\n","    Args:\n","        config: BartConfig\n","        embed_tokens (torch.nn.Embedding): output embedding\n","    \"\"\"\n","\n","    def __init__(self, config: BartConfig, embed_tokens: nn.Embedding):\n","        super().__init__()\n","        self.dropout = config.dropout\n","        self.layerdrop = config.decoder_layerdrop\n","        self.do_blenderbot_90_layernorm = config.do_blenderbot_90_layernorm  # layernorm variant\n","        self.padding_idx = embed_tokens.padding_idx\n","        self.max_target_positions = config.max_position_embeddings\n","        self.embed_scale = math.sqrt(config.d_model) if config.scale_embedding else 1.0\n","        self.embed_tokens = embed_tokens\n","        if config.static_position_embeddings:\n","            self.embed_positions = SinusoidalPositionalEmbedding(\n","                config.max_position_embeddings, config.d_model, config.pad_token_id\n","            )\n","        else:\n","            self.embed_positions = LearnedPositionalEmbedding(\n","                config.max_position_embeddings,\n","                config.d_model,\n","                self.padding_idx,\n","                config.extra_pos_embeddings\n","            )\n","        self.layers = nn.ModuleList(\n","            [DecoderLayer(config) for _ in range(config.decoder_layers)]\n","        )  # type: List[DecoderLayer]\n","        self.layernorm_embedding = LayerNorm(config.d_model) if config.normalize_embedding else nn.Identity()\n","        self.layer_norm = LayerNorm(config.d_model) if config.add_final_layer_norm else None\n","        self.config = config\n","\n","    def set_position_embedding(self, special_tag_start_id, tag_first=True):\n","        if tag_first:\n","            embed_positions = DecoderLearnedPositionalEmbedding(\n","                self.config.max_position_embeddings,\n","                self.config.d_model,\n","                self.padding_idx,\n","                self.config.extra_pos_embeddings,\n","                special_tag_start_id\n","            )\n","        else:\n","            embed_positions = DecoderLearnedPositionalEmbedding2(\n","                self.config.max_position_embeddings,\n","                self.config.d_model,\n","                self.padding_idx,\n","                self.config.extra_pos_embeddings,\n","                special_tag_start_id\n","            )\n","\n","        embed_positions.weight.data = self.embed_positions.weight.data\n","        self.embed_positions = embed_positions\n","\n","    def forward(\n","            self,\n","            input_ids,\n","            encoder_hidden_states,\n","            encoder_padding_mask,\n","            decoder_padding_mask,\n","            decoder_causal_mask,\n","            past_key_values=None,\n","            use_cache=False,\n","            output_attentions=False,\n","            output_hidden_states=False,\n","            return_dict=False,\n","            use_pos_cache=False,\n","            **unused,\n","    ):\n","        \"\"\"\n","        Includes several features from \"Jointly Learning to Align and\n","        Translate with Transformer Models\" (Garg et al., EMNLP 2019).\n","        Args:\n","            input_ids (LongTensor): previous decoder outputs of shape\n","                `(batch, tgt_len)`, for teacher forcing\n","            encoder_hidden_states: output from the encoder, used for\n","                encoder-side attention\n","            encoder_padding_mask: for ignoring pad tokens\n","            past_key_values (dict or None): dictionary used for storing state during generation\n","        Returns:\n","            BaseModelOutputWithPast or tuple:\n","                - the decoder's features of shape `(batch, tgt_len, embed_dim)`\n","                - the cache\n","                - hidden states\n","                - attentions\n","        \"\"\"\n","        if \"decoder_cached_states\" in unused:\n","            warnings.warn(\n","                \"The `decoder_cached_states` argument is deprecated and will be removed in a future version, use `past_key_values` instead.\",\n","                FutureWarning,\n","            )\n","            past_key_values = unused.pop(\"decoder_cached_states\")\n","        if \"decoder_past_key_values\" in unused:\n","            warnings.warn(\n","                \"The `decoder_past_key_values` argument is deprecated and will be removed in a future version, use `past_key_values` instead.\",\n","                FutureWarning,\n","            )\n","            past_key_values = unused.pop(\"decoder_past_key_values\")\n","\n","        # check attention mask and invert\n","        if encoder_padding_mask is not None:\n","            encoder_padding_mask = invert_mask(encoder_padding_mask)\n","\n","        # embed positions\n","        positions = self.embed_positions(input_ids, use_cache=use_pos_cache)\n","\n","        if use_pos_cache:\n","            input_ids = input_ids[:, -1:]\n","            positions = positions[:, -1:]\n","\n","        x = self.embed_tokens(input_ids) * self.embed_scale\n","        if self.do_blenderbot_90_layernorm:\n","            x = self.layernorm_embedding(x)\n","            x += positions\n","        else:\n","            x += positions\n","            x = self.layernorm_embedding(x)\n","\n","        x = F.dropout(x, p=self.dropout, training=self.training)\n","\n","        # Convert to Bart output format: (seq_len, BS, model_dim) -> (BS, seq_len, model_dim)\n","        x = x.transpose(0, 1)\n","        encoder_hidden_states = encoder_hidden_states.transpose(0, 1)\n","\n","        # decoder layers\n","        all_hidden_states = () if output_hidden_states else None\n","        all_self_attns = () if output_attentions else None\n","        next_decoder_cache = []\n","        for idx, decoder_layer in enumerate(self.layers):\n","            # add LayerDrop (see https://arxiv.org/abs/1909.11556 for description)\n","            if output_hidden_states:\n","                all_hidden_states += (x,)\n","            dropout_probability = random.uniform(0, 1)\n","            if self.training and (dropout_probability < self.layerdrop):\n","                continue\n","\n","            layer_state = past_key_values[idx] if past_key_values is not None else None\n","\n","            x, layer_self_attn, layer_past = decoder_layer(\n","                x,\n","                encoder_hidden_states,\n","                encoder_attn_mask=encoder_padding_mask,\n","                decoder_padding_mask=decoder_padding_mask,\n","                layer_state=layer_state,\n","                causal_mask=decoder_causal_mask,\n","                output_attentions=output_attentions,\n","            )\n","\n","            if use_cache:\n","                next_decoder_cache.append(layer_past.copy())\n","\n","            if output_attentions:\n","                all_self_attns += (layer_self_attn,)\n","\n","        if self.layer_norm:  # if config.add_final_layer_norm (mBART)\n","            x = self.layer_norm(x)\n","\n","        # Convert to standard output format: (seq_len, BS, model_dim) -> (BS, seq_len, model_dim)\n","        if output_hidden_states:\n","            all_hidden_states = tuple(hidden_state.transpose(0, 1) for hidden_state in all_hidden_states)\n","        x = x.transpose(0, 1)\n","        encoder_hidden_states = encoder_hidden_states.transpose(0, 1)\n","\n","        next_cache = next_decoder_cache if use_cache else None\n","\n","        if not return_dict:\n","            return tuple(v for v in [x, next_cache, all_hidden_states, all_self_attns] if v is not None)\n","        return BaseModelOutputWithPast(\n","            last_hidden_state=x, past_key_values=next_cache, hidden_states=all_hidden_states, attentions=all_self_attns\n","        )\n","\n","\n","def _reorder_buffer(attn_cache, new_order):\n","    for k, input_buffer_k in attn_cache.items():\n","        if input_buffer_k is not None:\n","            attn_cache[k] = input_buffer_k.index_select(0, new_order)\n","    return attn_cache\n","\n","\n","class Attention(nn.Module):\n","    \"\"\"Multi-headed attention from 'Attention Is All You Need' paper\"\"\"\n","\n","    def __init__(\n","            self,\n","            embed_dim,\n","            num_heads,\n","            dropout=0.0,\n","            bias=True,\n","            encoder_decoder_attention=False,  # otherwise self_attention\n","    ):\n","        super().__init__()\n","        self.embed_dim = embed_dim\n","        self.num_heads = num_heads\n","        self.dropout = dropout\n","        self.head_dim = embed_dim // num_heads\n","        assert self.head_dim * num_heads == self.embed_dim, \"embed_dim must be divisible by num_heads\"\n","        self.scaling = self.head_dim ** -0.5\n","\n","        self.encoder_decoder_attention = encoder_decoder_attention\n","        self.k_proj = nn.Linear(embed_dim, embed_dim, bias=bias)\n","        self.v_proj = nn.Linear(embed_dim, embed_dim, bias=bias)\n","        self.q_proj = nn.Linear(embed_dim, embed_dim, bias=bias)\n","        self.out_proj = nn.Linear(embed_dim, embed_dim, bias=bias)\n","        self.cache_key = \"encoder_decoder\" if self.encoder_decoder_attention else \"self\"\n","\n","    def _shape(self, tensor, seq_len, bsz):\n","        return tensor.contiguous().view(seq_len, bsz * self.num_heads, self.head_dim).transpose(0, 1)\n","\n","    def forward(\n","            self,\n","            query,\n","            key: Optional[Tensor],\n","            key_padding_mask: Optional[Tensor] = None,\n","            layer_state: Optional[Dict[str, Optional[Tensor]]] = None,\n","            attn_mask: Optional[Tensor] = None,\n","            output_attentions=False,\n","    ) -> Tuple[Tensor, Optional[Tensor]]:\n","        \"\"\"Input shape: Time(SeqLen) x Batch x Channel\"\"\"\n","        static_kv: bool = self.encoder_decoder_attention\n","        tgt_len, bsz, embed_dim = query.size()\n","        assert embed_dim == self.embed_dim\n","        assert list(query.size()) == [tgt_len, bsz, embed_dim]\n","        # get here for encoder decoder cause of static_kv\n","        if layer_state is not None:  # reuse k,v and encoder_padding_mask\n","            saved_state = layer_state.get(self.cache_key, {})\n","            if \"prev_key\" in saved_state and static_kv:\n","                # previous time steps are cached - no need to recompute key and value if they are static\n","                key = None\n","        else:\n","            saved_state = None\n","            layer_state = {}\n","\n","        q = self.q_proj(query) * self.scaling\n","        if static_kv:\n","            if key is None:\n","                k = v = None\n","            else:\n","                k = self.k_proj(key)\n","                v = self.v_proj(key)\n","        else:\n","            k = self.k_proj(query)\n","            v = self.v_proj(query)\n","\n","        q = self._shape(q, tgt_len, bsz)\n","        if k is not None:\n","            k = self._shape(k, -1, bsz)\n","        if v is not None:\n","            v = self._shape(v, -1, bsz)\n","        if saved_state is not None:\n","            k, v, key_padding_mask = self._use_saved_state(k, v, saved_state, key_padding_mask, static_kv, bsz)\n","        # Update cache\n","        layer_state[self.cache_key] = {\n","            \"prev_key\": k.view(bsz, self.num_heads, -1, self.head_dim),\n","            \"prev_value\": v.view(bsz, self.num_heads, -1, self.head_dim),\n","            \"prev_key_padding_mask\": key_padding_mask if not static_kv else None,\n","        }\n","\n","        assert k is not None\n","        src_len = k.size(1)\n","        attn_weights = torch.bmm(q, k.transpose(1, 2))\n","        assert attn_weights.size() == (bsz * self.num_heads, tgt_len, src_len)\n","\n","        if attn_mask is not None:\n","            attn_weights = attn_weights.view(bsz, self.num_heads, tgt_len, src_len) + attn_mask\n","            attn_weights = attn_weights.view(bsz * self.num_heads, tgt_len, src_len)\n","\n","        # This is part of a workaround to get around fork/join parallelism not supporting Optional types.\n","        if key_padding_mask is not None and key_padding_mask.dim() == 0:\n","            key_padding_mask = None\n","        assert key_padding_mask is None or key_padding_mask.size()[:2] == (\n","            bsz,\n","            src_len,\n","        )\n","\n","        if key_padding_mask is not None:  # don't attend to padding symbols\n","            attn_weights = attn_weights.view(bsz, self.num_heads, tgt_len, src_len)\n","            reshaped = key_padding_mask.unsqueeze(1).unsqueeze(2)\n","            attn_weights = attn_weights.masked_fill(reshaped, float(\"-inf\"))\n","            attn_weights = attn_weights.view(bsz * self.num_heads, tgt_len, src_len)\n","        attn_weights = F.softmax(attn_weights, dim=-1)\n","        attn_probs = F.dropout(\n","            attn_weights,\n","            p=self.dropout,\n","            training=self.training,\n","        )\n","\n","        assert v is not None\n","        attn_output = torch.bmm(attn_probs, v)\n","        assert attn_output.size() == (bsz * self.num_heads, tgt_len, self.head_dim)\n","        attn_output = attn_output.transpose(0, 1).contiguous().view(tgt_len, bsz, embed_dim)\n","        attn_output = self.out_proj(attn_output)\n","        if output_attentions:\n","            attn_weights = attn_weights.view(bsz, self.num_heads, tgt_len, src_len)\n","        else:\n","            attn_weights = None\n","        return attn_output, attn_weights\n","\n","    def _use_saved_state(self, k, v, saved_state, key_padding_mask, static_kv, bsz):\n","        # saved states are stored with shape (bsz, num_heads, seq_len, head_dim)\n","        if \"prev_key\" in saved_state:\n","            _prev_key = saved_state[\"prev_key\"]\n","            assert _prev_key is not None\n","            prev_key = _prev_key.view(bsz * self.num_heads, -1, self.head_dim)\n","            if static_kv:\n","                k = prev_key\n","            else:\n","                assert k is not None\n","                k = torch.cat([prev_key, k], dim=1)\n","        if \"prev_value\" in saved_state:\n","            _prev_value = saved_state[\"prev_value\"]\n","            assert _prev_value is not None\n","            prev_value = _prev_value.view(bsz * self.num_heads, -1, self.head_dim)\n","            if static_kv:\n","                v = prev_value\n","            else:\n","                assert v is not None\n","                v = torch.cat([prev_value, v], dim=1)\n","        assert k is not None and v is not None\n","        prev_key_padding_mask: Optional[Tensor] = saved_state.get(\"prev_key_padding_mask\", None)\n","        if prev_key_padding_mask is not None:\n","            if static_kv:\n","                new_key_padding_mask = prev_key_padding_mask\n","            else:\n","                new_key_padding_mask = torch.cat([prev_key_padding_mask, key_padding_mask], dim=1)\n","        else:\n","            new_key_padding_mask = key_padding_mask\n","        return k, v, new_key_padding_mask\n","\n","\n","class BartClassificationHead(nn.Module):\n","    \"\"\"Head for sentence-level classification tasks.\"\"\"\n","\n","    # This can trivially be shared with RobertaClassificationHead\n","\n","    def __init__(\n","            self,\n","            input_dim,\n","            inner_dim,\n","            num_classes,\n","            pooler_dropout,\n","    ):\n","        super().__init__()\n","        self.dense = nn.Linear(input_dim, inner_dim)\n","        self.dropout = nn.Dropout(p=pooler_dropout)\n","        self.out_proj = nn.Linear(inner_dim, num_classes)\n","\n","    def forward(self, x):\n","        x = self.dropout(x)\n","        x = self.dense(x)\n","        x = torch.tanh(x)\n","        x = self.dropout(x)\n","        x = self.out_proj(x)\n","        return x\n","\n","\n","class LearnedPositionalEmbedding(nn.Embedding):\n","    \"\"\"\n","    This module learns positional embeddings up to a fixed maximum size.\n","    Padding ids are ignored by either offsetting based on padding_idx\n","    or by setting padding_idx to None and ensuring that the appropriate\n","    position ids are passed to the forward function.\n","    \"\"\"\n","\n","    def __init__(self, num_embeddings: int, embedding_dim: int, padding_idx: int, offset):\n","        # Bart is set up so that if padding_idx is specified then offset the embedding ids by 2\n","        # and adjust num_embeddings appropriately. Other models dont have this hack\n","        self.offset = offset\n","        assert padding_idx is not None\n","        num_embeddings += offset\n","        super().__init__(num_embeddings, embedding_dim, padding_idx=padding_idx)\n","\n","    def forward(self, input_ids, use_cache=False):\n","        \"\"\"Input is expected to be of size [bsz x seqlen].\"\"\"\n","        bsz, seq_len = input_ids.shape[:2]\n","        if use_cache:\n","            positions = input_ids.data.new(1, 1).fill_(seq_len - 1)  # called before slicing\n","        else:\n","            # starts at 0, ends at 1-seq_len\n","            positions = torch.arange(seq_len, dtype=torch.long, device=self.weight.device)\n","        return super().forward(positions + self.offset)\n","\n","\n","class DecoderLearnedPositionalEmbedding(nn.Embedding):\n","    \"\"\"\n","    主要修改是，position的是循环的\n","    This module learns positional embeddings up to a fixed maximum size.\n","    Padding ids are ignored by either offsetting based on padding_idx\n","    or by setting padding_idx to None and ensuring that the appropriate\n","    position ids are passed to the forward function.\n","    \"\"\"\n","\n","    def __init__(self, num_embeddings: int, embedding_dim: int, padding_idx: int, offset,\n","                 special_tag_start_id=None):\n","        # Bart is set up so that if padding_idx is specified then offset the embedding ids by 2\n","        # and adjust num_embeddings appropriately. Other models dont have this hack\n","        self.offset = offset\n","        assert padding_idx is not None\n","        num_embeddings += offset\n","        self.special_tag_start_id = special_tag_start_id  # 这个id之后的词是特殊词汇\n","        super().__init__(num_embeddings, embedding_dim, padding_idx=padding_idx)\n","\n","    def forward(self, input_ids, use_cache=False):\n","        \"\"\"Input is expected to be of size [bsz x seqlen].\"\"\"\n","        if self.special_tag_start_id is None or input_ids.size(1)<2:\n","            bsz, seq_len = input_ids.shape[:2]\n","            if use_cache:\n","                positions = input_ids.data.new(1, 1).fill_(seq_len - 1)  # called before slicing\n","            else:\n","                # starts at 0, ends at 1-seq_len\n","                positions = torch.arange(seq_len, dtype=torch.long, device=self.weight.device)\n","        else:\n","            # 实现的是每个位置重新开始position\n","            \"\"\"\n","                大概意思是，假设input_ids中假设大于4是特殊符号，那么输入是\n","                [[2, 4, 1, 2, 3, 5, 1],\n","                 [2, 5, 3, 3, 0, 0, 0]]时，输出为\n","                [[0, 1, 2, 3, 4, 1, 2],\n","                 [0, 1, 2, 3, 4, 5, 6] 每个大于4的位置都会重置\n","            \"\"\"\n","            _input_ids = input_ids[:, 1:]\n","            bsz, seq_len = _input_ids.shape[:2]\n","            special_tag_mask = _input_ids.ge(self.special_tag_start_id)  # bsz x max_len\n","            if special_tag_mask.sum()>0:\n","                num_masks = special_tag_mask.cumsum(dim=1).max()  # 表示最长的\n","                arange_indices = torch.arange(seq_len).to(_input_ids).expand_as(_input_ids)  # bsz x max_len\n","                special_tag_indice = arange_indices.masked_select(special_tag_mask)  # a vector只包含所有的special的indice\n","                indices = torch.arange(num_masks).to(_input_ids)[None].repeat(bsz, 1)  # bsz x mask_len\n","                mask = indices.lt(special_tag_mask.sum(dim=1, keepdim=True))\n","                indices = indices.masked_scatter(mask, special_tag_indice)\n","                _, inverted_indices = special_tag_mask.cumsum(dim=-1).unique(return_inverse=True)\n","\n","                inverted_indices = inverted_indices - inverted_indices[:, :1]\n","                inverted_indices = inverted_indices.masked_fill(inverted_indices.ge(indices.size(1)), max(indices.size(1)-1, 0))\n","                positions = indices.gather(index=inverted_indices, dim=1)\n","                positions = (arange_indices - positions) + 1\n","            else:\n","                positions = torch.arange(seq_len+1, dtype=torch.long, device=self.weight.device)[None]\n","\n","            if use_cache:\n","                positions = positions[:, -1:]\n","            else:\n","                positions = torch.cat([input_ids.new_zeros(bsz, 1), positions], dim=1)\n","\n","        return super().forward(positions + self.offset)\n","\n","\n","class DecoderLearnedPositionalEmbedding2(nn.Embedding):\n","    \"\"\"\n","    主要修改是，position的是循环的, 和上面的区别是tag所在的位置不同\n","    This module learns positional embeddings up to a fixed maximum size.\n","    Padding ids are ignored by either offsetting based on padding_idx\n","    or by setting padding_idx to None and ensuring that the appropriate\n","    position ids are passed to the forward function.\n","    \"\"\"\n","\n","    def __init__(self, num_embeddings: int, embedding_dim: int, padding_idx: int, offset,\n","                 special_tag_start_id=None):\n","        # Bart is set up so that if padding_idx is specified then offset the embedding ids by 2\n","        # and adjust num_embeddings appropriately. Other models dont have this hack\n","        self.offset = offset\n","        assert padding_idx is not None\n","        num_embeddings += offset\n","        self.special_tag_start_id = special_tag_start_id  # 这个id之后的词是特殊词汇\n","        super().__init__(num_embeddings, embedding_dim, padding_idx=padding_idx)\n","\n","    def forward(self, input_ids, use_cache=False):\n","        \"\"\"Input is expected to be of size [bsz x seqlen].\"\"\"\n","        if self.special_tag_start_id is None or input_ids.size(1)<2:\n","            bsz, seq_len = input_ids.shape[:2]\n","            if use_cache:\n","                positions = input_ids.data.new(1, 1).fill_(seq_len - 1)  # called before slicing\n","            else:\n","                # starts at 0, ends at 1-seq_len\n","                positions = torch.arange(seq_len, dtype=torch.long, device=self.weight.device)\n","        else:\n","            # 实现的是每个位置重新开始position\n","            \"\"\"\n","                大概意思是，假设input_ids中假设大于4是特殊符号，那么输入是\n","                [[2, 1, 2, 3, 4, 1, 5],\n","                 [2, 3, 3, 5, 0, 0, 0]]时，输出为\n","                [[0, 1, 2, 3, 4, 1, 2],\n","                 [0, 1, 2, 3, 4, 5, 6] 每个大于4的位置都会重置\n","            \"\"\"\n","            _input_ids = input_ids[:, 1:]  # 把sos去掉\n","            bsz, seq_len = _input_ids.shape[:2]\n","            special_tag_mask = _input_ids.ge(self.special_tag_start_id)  # bsz x max_len\n","            if special_tag_mask.sum()>0:\n","                num_masks = special_tag_mask.cumsum(dim=1)  # 表示最长的\n","                num_masks_value = num_masks.max()\n","                arange_indices = torch.arange(seq_len).to(_input_ids).expand_as(_input_ids)  # bsz x max_len\n","\n","                special_tag_indice = arange_indices.masked_select(special_tag_mask)  # a vector只包含所有的special的indice\n","                indices = torch.arange(num_masks_value).to(_input_ids)[None].repeat(bsz, 1)  # bsz x mask_len\n","                mask = indices.lt(special_tag_mask.sum(dim=-1, keepdim=True))\n","                special_tag_indice = indices.masked_scatter(mask, special_tag_indice)\n","\n","                indices = torch.cat([special_tag_indice.new_zeros(bsz, 1), special_tag_indice[:, :-1] + 1], dim=1)\n","                _, inverted_indices = special_tag_mask.flip(dims=[1]).cumsum(dim=-1).flip(dims=[1]).unique(\n","                    return_inverse=True)\n","                values = inverted_indices[:, 0]  # bsz\n","                inverted_indices = values[:, None] - inverted_indices\n","                inverted_indices = inverted_indices.masked_fill(inverted_indices.ge(indices.size(1)), indices.size(1)-1)\n","\n","                positions = indices.gather(index=inverted_indices, dim=1)\n","                positions = arange_indices - positions + 1\n","            else:\n","                positions = torch.arange(seq_len+1, dtype=torch.long, device=self.weight.device)[None]\n","\n","        if use_cache:\n","            positions = positions[:, -1:]\n","        else:\n","            positions = torch.cat([input_ids.new_zeros(bsz, 1), positions], dim=1)\n","\n","        return super().forward(positions + self.offset)\n","\n","\n","def LayerNorm(normalized_shape, eps=1e-5, elementwise_affine=True):\n","    if torch.cuda.is_available():\n","        try:\n","            from apex.normalization import FusedLayerNorm\n","\n","            return FusedLayerNorm(normalized_shape, eps, elementwise_affine)\n","        except ImportError:\n","            pass\n","    return torch.nn.LayerNorm(normalized_shape, eps, elementwise_affine)\n","\n","\n","def fill_with_neg_inf(t):\n","    \"\"\"FP16-compatible function that fills a input_ids with -inf.\"\"\"\n","    return t.float().fill_(float(\"-inf\")).type_as(t)\n","\n","\n","# Public API\n","def _get_shape(t):\n","    return getattr(t, \"shape\", None)\n","\n","\n","class BartModel(PretrainedBartModel):\n","    def __init__(self, config: BartConfig):\n","        super().__init__(config)\n","\n","        padding_idx, vocab_size = config.pad_token_id, config.vocab_size\n","        self.shared = nn.Embedding(vocab_size, config.d_model, padding_idx)\n","\n","        self.encoder = BartEncoder(config, self.shared)\n","        self.decoder = BartDecoder(config, self.shared)\n","\n","        self.init_weights()\n","\n","    \n","    def forward(\n","            self,\n","            input_ids,\n","            attention_mask=None,\n","            decoder_input_ids=None,\n","            decoder_attention_mask=None,\n","            encoder_outputs: Optional[Tuple] = None,\n","            past_key_values=None,\n","            use_cache=None,\n","            output_attentions=None,\n","            output_hidden_states=None,\n","            return_dict=None,\n","            **kwargs,\n","    ):\n","        if \"decoder_past_key_values\" in kwargs:\n","            warnings.warn(\n","                \"The `decoder_past_key_values` argument is deprecated and will be removed in a future version, use `past_key_values` instead.\",\n","                FutureWarning,\n","            )\n","            past_key_values = kwargs.pop(\"decoder_past_key_values\")\n","\n","        if decoder_input_ids is None:\n","            use_cache = False\n","\n","        output_attentions = output_attentions if output_attentions is not None else self.config.output_attentions\n","        output_hidden_states = (\n","            output_hidden_states if output_hidden_states is not None else self.config.output_hidden_states\n","        )\n","        use_cache = use_cache if use_cache is not None else self.config.use_cache\n","        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n","\n","        # make masks if user doesn't supply\n","        if not use_cache:\n","            decoder_input_ids, decoder_padding_mask, causal_mask = _prepare_bart_decoder_inputs(\n","                self.config,\n","                input_ids,\n","                decoder_input_ids=decoder_input_ids,\n","                decoder_padding_mask=decoder_attention_mask,\n","                causal_mask_dtype=self.shared.weight.dtype,\n","            )\n","        else:\n","            decoder_padding_mask, causal_mask = None, None\n","\n","        assert decoder_input_ids is not None\n","\n","        if encoder_outputs is None:\n","            encoder_outputs = self.encoder(\n","                input_ids=input_ids,\n","                attention_mask=attention_mask,\n","                output_attentions=output_attentions,\n","                output_hidden_states=output_hidden_states,\n","                return_dict=return_dict,\n","            )\n","        # If the user passed a tuple for encoder_outputs, we wrap it in a BaseModelOuput when return_dict=False\n","        elif return_dict and not isinstance(encoder_outputs, BaseModelOutput):\n","            encoder_outputs = BaseModelOutput(\n","                last_hidden_state=encoder_outputs[0],\n","                hidden_states=encoder_outputs[1] if len(encoder_outputs) > 1 else None,\n","                attentions=encoder_outputs[2] if len(encoder_outputs) > 2 else None,\n","            )\n","\n","        # decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\n","        decoder_outputs = self.decoder(\n","            decoder_input_ids,\n","            encoder_outputs[0],\n","            attention_mask,\n","            decoder_padding_mask,\n","            decoder_causal_mask=causal_mask,\n","            past_key_values=past_key_values,\n","            use_cache=use_cache,\n","            output_attentions=output_attentions,\n","            output_hidden_states=output_hidden_states,\n","            return_dict=return_dict,\n","        )\n","\n","        if not return_dict:\n","            return decoder_outputs + encoder_outputs\n","\n","        return Seq2SeqModelOutput(\n","            last_hidden_state=decoder_outputs.last_hidden_state,\n","            past_key_values=decoder_outputs.past_key_values,\n","            decoder_hidden_states=decoder_outputs.hidden_states,\n","            decoder_attentions=decoder_outputs.attentions,\n","            encoder_last_hidden_state=encoder_outputs.last_hidden_state,\n","            encoder_hidden_states=encoder_outputs.hidden_states,\n","            encoder_attentions=encoder_outputs.attentions,\n","        )\n","\n","    def get_input_embeddings(self):\n","        return self.shared\n","\n","    def set_input_embeddings(self, value):\n","        self.shared = value\n","        self.encoder.embed_tokens = self.shared\n","        self.decoder.embed_tokens = self.shared\n","\n","    def get_output_embeddings(self):\n","        return _make_linear_from_emb(self.shared)  # make it on the fly\n","\n","\n","\n","class BartForConditionalGeneration(PretrainedBartModel):\n","    base_model_prefix = \"model\"\n","    authorized_missing_keys = [r\"final_logits_bias\", r\"encoder\\.version\", r\"decoder\\.version\"]\n","\n","    def __init__(self, config: BartConfig):\n","        super().__init__(config)\n","        base_model = BartModel(config)\n","        self.model = base_model\n","        self.register_buffer(\"final_logits_bias\", torch.zeros((1, self.model.shared.num_embeddings)))\n","\n","    def resize_token_embeddings(self, new_num_tokens: int) -> nn.Embedding:\n","        old_num_tokens = self.model.shared.num_embeddings\n","        new_embeddings = super().resize_token_embeddings(new_num_tokens)\n","        self.model.shared = new_embeddings\n","        self._resize_final_logits_bias(new_num_tokens, old_num_tokens)\n","        return new_embeddings\n","\n","    def _resize_final_logits_bias(self, new_num_tokens: int, old_num_tokens: int) -> None:\n","        if new_num_tokens <= old_num_tokens:\n","            new_bias = self.final_logits_bias[:, :new_num_tokens]\n","        else:\n","            extra_bias = torch.zeros((1, new_num_tokens - old_num_tokens), device=self.final_logits_bias.device)\n","            new_bias = torch.cat([self.final_logits_bias, extra_bias], dim=1)\n","        self.register_buffer(\"final_logits_bias\", new_bias)\n","\n","    \n","    def forward(\n","            self,\n","            input_ids,\n","            attention_mask=None,\n","            decoder_input_ids=None,\n","            decoder_attention_mask=None,\n","            encoder_outputs=None,\n","            past_key_values=None,\n","            labels=None,\n","            use_cache=None,\n","            output_attentions=None,\n","            output_hidden_states=None,\n","            return_dict=None,\n","            **unused,\n","    ):\n","        r\"\"\"\n","        labels (:obj:`torch.LongTensor` of shape :obj:`(batch_size, sequence_length)`, `optional`):\n","            Labels for computing the masked language modeling loss.\n","            Indices should either be in ``[0, ..., config.vocab_size]`` or -100 (see ``input_ids`` docstring).\n","            Tokens with indices set to ``-100`` are ignored (masked), the loss is only computed for the tokens\n","            with labels in ``[0, ..., config.vocab_size]``.\n","        Returns:\n","        Conditional generation example::\n","            >>> # Mask filling only works for bart-large\n","            >>> from transformers import BartTokenizer, BartForConditionalGeneration\n","            >>> tokenizer = BartTokenizer.from_pretrained('facebook/bart-large')\n","            >>> TXT = \"My friends are <mask> but they eat too many carbs.\"\n","            >>> model = BartForConditionalGeneration.from_pretrained('facebook/bart-large')\n","            >>> input_ids = tokenizer([TXT], return_tensors='pt')['input_ids']\n","            >>> logits = model(input_ids).logits\n","            >>> masked_index = (input_ids[0] == tokenizer.mask_token_id).nonzero().item()\n","            >>> probs = logits[0, masked_index].softmax(dim=0)\n","            >>> values, predictions = probs.topk(5)\n","            >>> tokenizer.decode(predictions).split()\n","            >>> # ['good', 'great', 'all', 'really', 'very']\n","        \"\"\"\n","        if \"lm_labels\" in unused:\n","            warnings.warn(\n","                \"The `lm_labels` argument is deprecated and will be removed in a future version, use `labels` instead.\",\n","                FutureWarning,\n","            )\n","            labels = unused.pop(\"lm_labels\")\n","        if \"decoder_cached_states\" in unused:\n","            warnings.warn(\n","                \"The `decoder_cached_states` argument is deprecated and will be removed in a future version, use `past_key_values` instead.\",\n","                FutureWarning,\n","            )\n","            past_key_values = unused.pop(\"decoder_cached_states\")\n","        if \"decoder_past_key_values\" in unused:\n","            warnings.warn(\n","                \"The `decoder_past_key_values` argument is deprecated and will be removed in a future version, use `past_key_values` instead.\",\n","                FutureWarning,\n","            )\n","            past_key_values = unused.pop(\"decoder_past_key_values\")\n","        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n","\n","        if labels is not None:\n","            use_cache = False\n","            if decoder_input_ids is None:\n","                decoder_input_ids = shift_tokens_right(labels, self.config.pad_token_id)\n","\n","        outputs = self.model(\n","            input_ids,\n","            attention_mask=attention_mask,\n","            decoder_input_ids=decoder_input_ids,\n","            encoder_outputs=encoder_outputs,\n","            decoder_attention_mask=decoder_attention_mask,\n","            past_key_values=past_key_values,\n","            use_cache=use_cache,\n","            output_attentions=output_attentions,\n","            output_hidden_states=output_hidden_states,\n","            return_dict=return_dict,\n","        )\n","        lm_logits = F.linear(outputs[0], self.model.shared.weight, bias=self.final_logits_bias)\n","\n","        masked_lm_loss = None\n","        if labels is not None:\n","            loss_fct = CrossEntropyLoss()\n","            # TODO(SS): do we need to ignore pad tokens in labels?\n","            masked_lm_loss = loss_fct(lm_logits.view(-1, self.config.vocab_size), labels.view(-1))\n","\n","        if not return_dict:\n","            output = (lm_logits,) + outputs[1:]\n","            return ((masked_lm_loss,) + output) if masked_lm_loss is not None else output\n","\n","        return Seq2SeqLMOutput(\n","            loss=masked_lm_loss,\n","            logits=lm_logits,\n","            past_key_values=outputs.past_key_values,\n","            decoder_hidden_states=outputs.decoder_hidden_states,\n","            decoder_attentions=outputs.decoder_attentions,\n","            encoder_last_hidden_state=outputs.encoder_last_hidden_state,\n","            encoder_hidden_states=outputs.encoder_hidden_states,\n","            encoder_attentions=outputs.encoder_attentions,\n","        )\n","\n","    def prepare_inputs_for_generation(\n","            self, decoder_input_ids, past, attention_mask, use_cache, encoder_outputs, **kwargs\n","    ):\n","        return {\n","            \"input_ids\": None,  # encoder_outputs is defined. input_ids not needed\n","            \"encoder_outputs\": encoder_outputs,\n","            \"past_key_values\": past,\n","            \"decoder_input_ids\": decoder_input_ids,\n","            \"attention_mask\": attention_mask,\n","            \"use_cache\": use_cache,  # change this to avoid caching (presumably for debugging)\n","        }\n","\n","    def adjust_logits_during_generation(self, logits, cur_len, max_length):\n","        if cur_len == 1 and self.config.force_bos_token_to_be_generated:\n","            self._force_token_ids_generation(logits, self.config.bos_token_id)\n","        elif cur_len == max_length - 1 and self.config.eos_token_id is not None:\n","            self._force_token_ids_generation(logits, self.config.eos_token_id)\n","        return logits\n","\n","    def _force_token_ids_generation(self, scores, token_id) -> None:\n","        \"\"\"force one of token_ids to be generated by setting prob of all other tokens to 0 (logprob=-float(\"inf\"))\"\"\"\n","        scores[:, [x for x in range(self.config.vocab_size) if x != token_id]] = -float(\"inf\")\n","\n","    @staticmethod\n","    def _reorder_cache(past, beam_idx):\n","        reordered_past = []\n","        for layer_past in past:\n","            # get the correct batch idx from decoder layer's batch dim for cross and self-attn\n","            layer_past_new = {\n","                attn_key: _reorder_buffer(attn_cache, beam_idx) for attn_key, attn_cache in layer_past.items()\n","            }\n","            reordered_past.append(layer_past_new)\n","        return reordered_past\n","\n","    def get_encoder(self):\n","        return self.model.encoder\n","\n","    def get_output_embeddings(self):\n","        return _make_linear_from_emb(self.model.shared)  # make it on the fly\n","\n","\n","\n","class BartForSequenceClassification(PretrainedBartModel):\n","    def __init__(self, config: BartConfig, **kwargs):\n","        super().__init__(config, **kwargs)\n","        self.model = BartModel(config)\n","        self.classification_head = BartClassificationHead(\n","            config.d_model,\n","            config.d_model,\n","            config.num_labels,\n","            config.classifier_dropout,\n","        )\n","        self.model._init_weights(self.classification_head.dense)\n","        self.model._init_weights(self.classification_head.out_proj)\n","\n","    \n","    def forward(\n","            self,\n","            input_ids,\n","            attention_mask=None,\n","            decoder_input_ids=None,\n","            decoder_attention_mask=None,\n","            encoder_outputs=None,\n","            labels=None,\n","            use_cache=None,\n","            output_attentions=None,\n","            output_hidden_states=None,\n","            return_dict=None,\n","    ):\n","        r\"\"\"\n","        labels (:obj:`torch.LongTensor` of shape :obj:`(batch_size,)`, `optional`):\n","            Labels for computing the sequence classification/regression loss.\n","            Indices should be in :obj:`[0, ..., config.num_labels - 1]`.\n","            If :obj:`config.num_labels > 1` a classification loss is computed (Cross-Entropy).\n","        \"\"\"\n","        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n","        if labels is not None:\n","            use_cache = False\n","\n","        outputs = self.model(\n","            input_ids,\n","            attention_mask=attention_mask,\n","            decoder_input_ids=decoder_input_ids,\n","            decoder_attention_mask=decoder_attention_mask,\n","            encoder_outputs=encoder_outputs,\n","            use_cache=use_cache,\n","            output_attentions=output_attentions,\n","            output_hidden_states=output_hidden_states,\n","            return_dict=return_dict,\n","        )\n","        x = outputs[0]  # last hidden state\n","        eos_mask = input_ids.eq(self.config.eos_token_id)\n","        if len(torch.unique(eos_mask.sum(1))) > 1:\n","            raise ValueError(\"All examples must have the same number of <eos> tokens.\")\n","        sentence_representation = x[eos_mask, :].view(x.size(0), -1, x.size(-1))[:, -1, :]\n","        logits = self.classification_head(sentence_representation)\n","\n","        loss = None\n","        if labels is not None:\n","            loss_fct = CrossEntropyLoss()\n","            loss = loss_fct(logits.view(-1, self.config.num_labels), labels.view(-1))\n","\n","        if not return_dict:\n","            output = (logits,) + outputs[1:]\n","            return ((loss,) + output) if loss is not None else output\n","\n","        return Seq2SeqSequenceClassifierOutput(\n","            loss=loss,\n","            logits=logits,\n","            past_key_values=outputs.past_key_values,\n","            decoder_hidden_states=outputs.decoder_hidden_states,\n","            decoder_attentions=outputs.decoder_attentions,\n","            encoder_last_hidden_state=outputs.encoder_last_hidden_state,\n","            encoder_hidden_states=outputs.encoder_hidden_states,\n","            encoder_attentions=outputs.encoder_attentions,\n","        )\n","\n","\n","\n","class BartForQuestionAnswering(PretrainedBartModel):\n","    def __init__(self, config):\n","        super().__init__(config)\n","\n","        config.num_labels = 2\n","        self.num_labels = config.num_labels\n","\n","        self.model = BartModel(config)\n","        self.qa_outputs = nn.Linear(config.hidden_size, config.num_labels)\n","\n","        self.model._init_weights(self.qa_outputs)\n","\n","    \n","    def forward(\n","            self,\n","            input_ids,\n","            attention_mask=None,\n","            decoder_input_ids=None,\n","            decoder_attention_mask=None,\n","            encoder_outputs=None,\n","            start_positions=None,\n","            end_positions=None,\n","            use_cache=None,\n","            output_attentions=None,\n","            output_hidden_states=None,\n","            return_dict=None,\n","    ):\n","        r\"\"\"\n","        start_positions (:obj:`torch.LongTensor` of shape :obj:`(batch_size,)`, `optional`):\n","            Labels for position (index) of the start of the labelled span for computing the token classification loss.\n","            Positions are clamped to the length of the sequence (`sequence_length`).\n","            Position outside of the sequence are not taken into account for computing the loss.\n","        end_positions (:obj:`torch.LongTensor` of shape :obj:`(batch_size,)`, `optional`):\n","            Labels for position (index) of the end of the labelled span for computing the token classification loss.\n","            Positions are clamped to the length of the sequence (`sequence_length`).\n","            Position outside of the sequence are not taken into account for computing the loss.\n","        \"\"\"\n","        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n","        if start_positions is not None and end_positions is not None:\n","            use_cache = False\n","\n","        outputs = self.model(\n","            input_ids,\n","            attention_mask=attention_mask,\n","            decoder_input_ids=decoder_input_ids,\n","            decoder_attention_mask=decoder_attention_mask,\n","            encoder_outputs=encoder_outputs,\n","            use_cache=use_cache,\n","            output_attentions=output_attentions,\n","            output_hidden_states=output_hidden_states,\n","            return_dict=return_dict,\n","        )\n","\n","        sequence_output = outputs[0]\n","\n","        logits = self.qa_outputs(sequence_output)\n","        start_logits, end_logits = logits.split(1, dim=-1)\n","        start_logits = start_logits.squeeze(-1)\n","        end_logits = end_logits.squeeze(-1)\n","\n","        total_loss = None\n","        if start_positions is not None and end_positions is not None:\n","            # If we are on multi-GPU, split add a dimension\n","            if len(start_positions.size()) > 1:\n","                start_positions = start_positions.squeeze(-1)\n","            if len(end_positions.size()) > 1:\n","                end_positions = end_positions.squeeze(-1)\n","            # sometimes the start/end positions are outside our model inputs, we ignore these terms\n","            ignored_index = start_logits.size(1)\n","            start_positions.clamp_(0, ignored_index)\n","            end_positions.clamp_(0, ignored_index)\n","\n","            loss_fct = CrossEntropyLoss(ignore_index=ignored_index)\n","            start_loss = loss_fct(start_logits, start_positions)\n","            end_loss = loss_fct(end_logits, end_positions)\n","            total_loss = (start_loss + end_loss) / 2\n","\n","        if not return_dict:\n","            output = (\n","                         start_logits,\n","                         end_logits,\n","                     ) + outputs[1:]\n","            return ((total_loss,) + output) if total_loss is not None else output\n","\n","        return Seq2SeqQuestionAnsweringModelOutput(\n","            loss=total_loss,\n","            start_logits=start_logits,\n","            end_logits=end_logits,\n","            past_key_values=outputs.past_key_values,\n","            decoder_hidden_states=outputs.decoder_hidden_states,\n","            decoder_attentions=outputs.decoder_attentions,\n","            encoder_last_hidden_state=outputs.encoder_last_hidden_state,\n","            encoder_hidden_states=outputs.encoder_hidden_states,\n","            encoder_attentions=outputs.encoder_attentions,\n","        )\n","\n","\n","class SinusoidalPositionalEmbedding(nn.Embedding):\n","    \"\"\"This module produces sinusoidal positional embeddings of any length.\"\"\"\n","\n","    def __init__(self, num_positions, embedding_dim, padding_idx=None):\n","        super().__init__(num_positions, embedding_dim)\n","        if embedding_dim % 2 != 0:\n","            raise NotImplementedError(f\"odd embedding_dim {embedding_dim} not supported\")\n","        self.weight = self._init_weight(self.weight)\n","\n","    @staticmethod\n","    def _init_weight(out: nn.Parameter):\n","        \"\"\"Identical to the XLM create_sinusoidal_embeddings except features are not interleaved.\n","        The cos features are in the 2nd half of the vector. [dim // 2:]\n","        \"\"\"\n","        n_pos, dim = out.shape\n","        position_enc = np.array(\n","            [[pos / np.power(10000, 2 * (j // 2) / dim) for j in range(dim)] for pos in range(n_pos)]\n","        )\n","        out[:, 0: dim // 2] = torch.FloatTensor(np.sin(position_enc[:, 0::2]))  # This line breaks for odd n_pos\n","        out[:, dim // 2:] = torch.FloatTensor(np.cos(position_enc[:, 1::2]))\n","        out.detach_()\n","        out.requires_grad = False\n","        return out\n","\n","    @torch.no_grad()\n","    def forward(self, input_ids, use_cache=False):\n","        \"\"\"Input is expected to be of size [bsz x seqlen].\"\"\"\n","        bsz, seq_len = input_ids.shape[:2]\n","        if use_cache:\n","            positions = input_ids.data.new(1, 1).fill_(seq_len - 1)  # called before slicing\n","        else:\n","            # starts at 0, ends at 1-seq_len\n","            positions = torch.arange(seq_len, dtype=torch.long, device=self.weight.device)\n","        return super().forward(positions)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gM9Rbqb5DZzZ"},"outputs":[],"source":["import torch\n","from transformers import BartTokenizer\n","from fastNLP import seq_len_to_mask\n","from fastNLP.modules import Seq2SeqEncoder, Seq2SeqDecoder, State\n","import torch.nn.functional as F\n","from fastNLP.models import Seq2SeqModel\n","from torch import nn\n","import math\n","\n","\n","class FBartEncoder(Seq2SeqEncoder):\n","    def __init__(self, encoder):\n","        super().__init__()\n","        assert isinstance(encoder, BartEncoder)\n","        self.bart_encoder = encoder\n","\n","    def forward(self, src_tokens, src_seq_len):\n","        mask = seq_len_to_mask(src_seq_len, max_len=src_tokens.size(1))\n","        dict = self.bart_encoder(input_ids=src_tokens, attention_mask=mask, return_dict=True,\n","                                 output_hidden_states=True)\n","        encoder_outputs = dict.last_hidden_state\n","        hidden_states = dict.hidden_states\n","        return encoder_outputs, mask, hidden_states\n","\n","\n","class FBartDecoder(Seq2SeqDecoder):\n","    def __init__(self, decoder, pad_token_id, label_ids, use_encoder_mlp=True):\n","        super().__init__()\n","        assert isinstance(decoder, BartDecoder)\n","        self.decoder = decoder\n","        causal_mask = torch.zeros(512, 512).fill_(float('-inf'))\n","        causal_mask = causal_mask.triu(diagonal=1)\n","        self.register_buffer('causal_masks', causal_mask.float())\n","        self.pad_token_id = pad_token_id\n","        self.label_start_id = label_ids[0]\n","        self.label_end_id = label_ids[-1]+1\n","        # 0th position is <s>, 1st position is </s>\n","        mapping = torch.LongTensor([0, 2]+sorted(label_ids, reverse=False))\n","        self.register_buffer('mapping', mapping)\n","        self.src_start_index = len(mapping)  # 加上一个\n","        hidden_size = decoder.embed_tokens.weight.size(1)\n","        if use_encoder_mlp:\n","            self.encoder_mlp = nn.Sequential(nn.Linear(hidden_size, hidden_size),\n","                                             nn.Dropout(0.3),\n","                                             nn.ReLU(),\n","                                             nn.Linear(hidden_size, hidden_size))\n","\n","    def forward(self, tokens, state):\n","        # bsz, max_len = tokens.size()\n","        encoder_outputs = state.encoder_output\n","        encoder_pad_mask = state.encoder_mask\n","\n","        first = state.first\n","        # eos is 1\n","        cumsum = tokens.eq(1).flip(dims=[1]).cumsum(dim=-1)\n","        tgt_pad_mask = cumsum.flip(dims=[1]).ne(cumsum[:, -1:])\n","\n","        # mapping to the BART token index\n","        mapping_token_mask = tokens.lt(self.src_start_index)  #\n","        mapped_tokens = tokens.masked_fill(tokens.ge(self.src_start_index), 0)\n","        tag_mapped_tokens = self.mapping[mapped_tokens]\n","\n","        src_tokens_index = tokens - self.src_start_index # bsz x num_src_token\n","        src_tokens_index = src_tokens_index.masked_fill(src_tokens_index.lt(0), 0)\n","        src_tokens = state.src_tokens\n","        if first is not None:\n","            src_tokens = src_tokens.gather(index=first, dim=1)\n","        word_mapped_tokens = src_tokens.gather(index=src_tokens_index, dim=1)\n","\n","        tokens = torch.where(mapping_token_mask, tag_mapped_tokens, word_mapped_tokens)\n","        tokens = tokens.masked_fill(tgt_pad_mask, self.pad_token_id)\n","\n","        if self.training:\n","            tokens = tokens[:, :-1]\n","            decoder_pad_mask = tokens.eq(self.pad_token_id)\n","            dict = self.decoder(input_ids=tokens,\n","                                encoder_hidden_states=encoder_outputs,\n","                                encoder_padding_mask=encoder_pad_mask,\n","                                decoder_padding_mask=decoder_pad_mask,\n","                                decoder_causal_mask=self.causal_masks[:tokens.size(1), :tokens.size(1)],\n","                                return_dict=True)\n","        else:\n","            past_key_values = state.past_key_values\n","            dict = self.decoder(input_ids=tokens,\n","                                encoder_hidden_states=encoder_outputs,\n","                                encoder_padding_mask=encoder_pad_mask,\n","                                decoder_padding_mask=None,\n","                                decoder_causal_mask=None,\n","                                past_key_values=past_key_values,\n","                                use_cache=True,\n","                                return_dict=True)\n","        hidden_state = dict.last_hidden_state  # bsz x max_len x hidden_size\n","        if not self.training:\n","            state.past_key_values = dict.past_key_values\n","\n","        logits = hidden_state.new_full((hidden_state.size(0), hidden_state.size(1), self.src_start_index+src_tokens.size(-1)),\n","                                       fill_value=-1e24)\n","\n","        # first get the\n","        eos_scores = F.linear(hidden_state, self.decoder.embed_tokens.weight[2:3])  # bsz x max_len x 1\n","        tag_scores = F.linear(hidden_state, self.decoder.embed_tokens.weight[self.label_start_id:self.label_end_id])  # bsz x max_len x num_class\n","\n","        # bsz x max_word_len x hidden_size\n","        src_outputs = state.encoder_output\n","\n","        if hasattr(self, 'encoder_mlp'):\n","            src_outputs = self.encoder_mlp(src_outputs)\n","\n","        if first is not None:\n","            mask = first.eq(0)  # bsz x 1 x max_word_len, 为1的地方是padding\n","            src_outputs = src_outputs.gather(index=first.unsqueeze(2).repeat(1, 1, src_outputs.size(-1)), dim=1)\n","        else:\n","            mask = state.encoder_mask.eq(0)\n","\n","        mask = mask.unsqueeze(1).__or__(src_tokens.eq(2).cumsum(dim=1).ge(1).unsqueeze(1))\n","        word_scores = torch.einsum('blh,bnh->bln', hidden_state, src_outputs)  # bsz x max_len x max_word_len\n","        word_scores = word_scores.masked_fill(mask, -1e32)\n","\n","        logits[:, :, 1:2] = eos_scores\n","        logits[:, :, 2:self.src_start_index] = tag_scores\n","        logits[:, :, self.src_start_index:] = word_scores\n","\n","        return logits\n","\n","    def decode(self, tokens, state):\n","        return self(tokens, state)[:, -1]\n","\n","\n","class CaGFBartDecoder(FBartDecoder):\n","    # Copy and generate,\n","    def __init__(self, decoder, pad_token_id, label_ids, use_encoder_mlp=False):\n","        super().__init__(decoder, pad_token_id, label_ids, use_encoder_mlp=use_encoder_mlp)\n","\n","    def forward(self, tokens, state):\n","        encoder_outputs = state.encoder_output\n","        encoder_pad_mask = state.encoder_mask\n","        first = state.first\n","\n","        cumsum = tokens.eq(1).flip(dims=[1]).cumsum(dim=-1)\n","        tgt_pad_mask = cumsum.flip(dims=[1]).ne(cumsum[:, -1:])\n","\n","        mapping_token_mask = tokens.lt(self.src_start_index)\n","        mapped_tokens = tokens.masked_fill(tokens.ge(self.src_start_index), 0)\n","        tag_mapped_tokens = self.mapping[mapped_tokens]\n","\n","        src_tokens_index = tokens - self.src_start_index # bsz x num_src_token\n","        src_tokens_index = src_tokens_index.masked_fill(src_tokens_index.lt(0), 0)\n","        src_tokens = state.src_tokens\n","        if first is not None:\n","            src_tokens = src_tokens.gather(index=first, dim=1)\n","        word_mapped_tokens = src_tokens.gather(index=src_tokens_index, dim=1)\n","\n","        tokens = torch.where(mapping_token_mask, tag_mapped_tokens, word_mapped_tokens)  # bsz x max_len\n","        tokens = tokens.masked_fill(tgt_pad_mask, self.pad_token_id)\n","\n","        if self.training:\n","            tokens = tokens[:, :-1]\n","            decoder_pad_mask = tokens.eq(self.pad_token_id)  # decoder需要让pad位置为1\n","            dict = self.decoder(input_ids=tokens,\n","                                encoder_hidden_states=encoder_outputs,\n","                                encoder_padding_mask=encoder_pad_mask,\n","                                decoder_padding_mask=decoder_pad_mask,\n","                                decoder_causal_mask=self.causal_masks[:tokens.size(1), :tokens.size(1)],\n","                                return_dict=True)\n","        else:\n","            past_key_values = state.past_key_values\n","            dict = self.decoder(input_ids=tokens,\n","                                encoder_hidden_states=encoder_outputs,\n","                                encoder_padding_mask=encoder_pad_mask,\n","                                decoder_padding_mask=None,\n","                                decoder_causal_mask=None,\n","                                past_key_values=past_key_values,\n","                                use_cache=True,\n","                                return_dict=True)\n","        hidden_state = dict.last_hidden_state  # bsz x max_len x hidden_size\n","        if not self.training:\n","            state.past_key_values = dict.past_key_values\n","\n","        logits = hidden_state.new_full((hidden_state.size(0), hidden_state.size(1), self.src_start_index+src_tokens.size(-1)),\n","                                       fill_value=-1e24)\n","\n","        eos_scores = F.linear(hidden_state, self.decoder.embed_tokens.weight[2:3])  # bsz x max_len x 1\n","        tag_scores = F.linear(hidden_state, self.decoder.embed_tokens.weight[self.label_start_id:self.label_end_id])  # bsz x max_len x num_class\n","\n","\n","        # bsz x max_bpe_len x hidden_size\n","        src_outputs = state.encoder_output\n","        if hasattr(self, 'encoder_mlp'):\n","            src_outputs = self.encoder_mlp(src_outputs)\n","\n","        if first is not None:\n","            mask = first.eq(0)  # bsz x 1 x max_word_len, 为1的地方是padding\n","            # bsz x max_word_len x hidden_size\n","            src_outputs = src_outputs.gather(index=first.unsqueeze(2).repeat(1, 1, src_outputs.size(-1)), dim=1)\n","        else:\n","            mask = state.encoder_mask.eq(0)\n","            # src_outputs = self.decoder.embed_tokens(src_tokens)\n","        mask = mask.unsqueeze(1)\n","        input_embed = self.decoder.embed_tokens(src_tokens)  # bsz x max_word_len x hidden_size\n","        word_scores = torch.einsum('blh,bnh->bln', hidden_state, src_outputs)  # bsz x max_len x max_word_len\n","        gen_scores = torch.einsum('blh,bnh->bln', hidden_state, input_embed)  # bsz x max_len x max_word_len\n","        word_scores = (gen_scores + word_scores)/2\n","        mask = mask.__or__(src_tokens.eq(2).cumsum(dim=1).ge(1).unsqueeze(1))\n","        word_scores = word_scores.masked_fill(mask, -1e32)\n","\n","        logits[:, :, 1:2] = eos_scores\n","        logits[:, :, 2:self.src_start_index] = tag_scores\n","        logits[:, :, self.src_start_index:] = word_scores\n","\n","        return logits\n","\n","\n","class BartSeq2SeqModel(Seq2SeqModel):\n","    @classmethod\n","    def build_model(cls, bart_model, tokenizer, label_ids, decoder_type=None, copy_gate=False,\n","                    use_encoder_mlp=False, use_recur_pos=False, tag_first=False):\n","        model = BartModel.from_pretrained(bart_model)\n","        num_tokens, _ = model.encoder.embed_tokens.weight.shape\n","        model.resize_token_embeddings(len(tokenizer.unique_no_split_tokens)+num_tokens)\n","        encoder = model.encoder\n","        decoder = model.decoder\n","\n","        if use_recur_pos:\n","            decoder.set_position_embedding(label_ids[0], tag_first)\n","\n","        _tokenizer = BartTokenizer.from_pretrained(bart_model)\n","        for token in tokenizer.unique_no_split_tokens:\n","            if token[:2] == '<<':\n","                index = tokenizer.convert_tokens_to_ids(tokenizer.tokenize(token))\n","                if len(index)>1:\n","                    raise RuntimeError(f\"{token} wrong split\")\n","                else:\n","                    index = index[0]\n","                assert index>=num_tokens, (index, num_tokens, token)\n","                indexes = _tokenizer.convert_tokens_to_ids(_tokenizer.tokenize(token[2:-2]))\n","                embed = model.encoder.embed_tokens.weight.data[indexes[0]]\n","                for i in indexes[1:]:\n","                    embed += model.decoder.embed_tokens.weight.data[i]\n","                embed /= len(indexes)\n","                model.decoder.embed_tokens.weight.data[index] = embed\n","\n","        encoder = FBartEncoder(encoder)\n","        label_ids = sorted(label_ids)\n","        if decoder_type is None:\n","            assert copy_gate is False\n","            decoder = FBartDecoder(decoder, pad_token_id=tokenizer.pad_token_id, label_ids=label_ids)\n","        elif decoder_type =='avg_score':\n","            decoder = CaGFBartDecoder(decoder, pad_token_id=tokenizer.pad_token_id, label_ids=label_ids,\n","                                              use_encoder_mlp=use_encoder_mlp)\n","        else:\n","            raise RuntimeError(\"Unsupported feature.\")\n","\n","        return cls(encoder=encoder, decoder=decoder)\n","\n","    def prepare_state(self, src_tokens, src_seq_len=None, first=None, tgt_seq_len=None):\n","        encoder_outputs, encoder_mask, hidden_states = self.encoder(src_tokens, src_seq_len)\n","        src_embed_outputs = hidden_states[0]\n","        state = BartState(encoder_outputs, encoder_mask, src_tokens, first, src_embed_outputs)\n","        # setattr(state, 'tgt_seq_len', tgt_seq_len)\n","        return state\n","\n","    def forward(self, src_tokens, tgt_tokens, src_seq_len, tgt_seq_len, first):\n","        \"\"\"\n","        :param torch.LongTensor src_tokens: source的token\n","        :param torch.LongTensor tgt_tokens: target的token\n","        :param torch.LongTensor first: 显示每个, bsz x max_word_len\n","        :param torch.LongTensor src_seq_len: src的长度\n","        :param torch.LongTensor tgt_seq_len: target的长度，默认用不上\n","        :return: {'pred': torch.Tensor}, 其中pred的shape为bsz x max_len x vocab_size\n","        \"\"\"\n","        state = self.prepare_state(src_tokens, src_seq_len, first, tgt_seq_len)\n","        decoder_output = self.decoder(tgt_tokens, state)\n","        if isinstance(decoder_output, torch.Tensor):\n","            return {'pred': decoder_output}\n","        elif isinstance(decoder_output, (tuple, list)):\n","            return {'pred': decoder_output[0]}\n","        else:\n","            raise TypeError(f\"Unsupported return type from Decoder:{type(self.decoder)}\")\n","\n","\n","\n","class BartState(State):\n","    def __init__(self, encoder_output, encoder_mask, src_tokens, first, src_embed_outputs):\n","        super().__init__(encoder_output, encoder_mask)\n","        self.past_key_values = None\n","        self.src_tokens = src_tokens\n","        self.first = first\n","        self.src_embed_outputs = src_embed_outputs\n","\n","    def reorder_state(self, indices: torch.LongTensor):\n","        super().reorder_state(indices)\n","        self.src_tokens = self._reorder_state(self.src_tokens, indices)\n","        if self.first is not None:\n","            self.first = self._reorder_state(self.first, indices)\n","        self.src_embed_outputs = self._reorder_state(self.src_embed_outputs, indices)\n","        if self.past_key_values is not None:\n","            new = []\n","            for layer in self.past_key_values:\n","                new_layer = {}\n","                for key1 in list(layer.keys()):\n","                    new_layer_ = {}\n","                    for key2 in list(layer[key1].keys()):\n","                        if layer[key1][key2] is not None:\n","                            layer[key1][key2] = self._reorder_state(layer[key1][key2], indices)\n","                            # print(key1, key2, layer[key1][key2].shape)\n","                        new_layer_[key2] = layer[key1][key2]\n","                    new_layer[key1] = new_layer_\n","                new.append(new_layer)\n","            self.past_key_values = new"]},{"cell_type":"markdown","metadata":{"id":"dVLiv9MiD_70"},"source":["#Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3OujcjF8D3qv"},"outputs":[],"source":["\n","import torch\n","from torch import nn\n","from fastNLP.models.seq2seq_model import Seq2SeqModel\n","from fastNLP.modules.decoder.seq2seq_decoder import Seq2SeqDecoder, State\n","import torch.nn.functional as F\n","from fastNLP.core.utils import _get_model_device\n","from functools import partial\n","\n","\n","class SequenceGeneratorModel(nn.Module):\n","    \"\"\"\n","    用于封装Seq2SeqModel使其可以做生成任务\n","    \"\"\"\n","\n","    def __init__(self, seq2seq_model: Seq2SeqModel, bos_token_id, eos_token_id=None, max_length=30, max_len_a=0.0,\n","                 num_beams=1, do_sample=True,\n","                 repetition_penalty=1, length_penalty=1.0, pad_token_id=0,\n","                 restricter=None):\n","        \"\"\"\n","        :param Seq2SeqModel seq2seq_model: 序列到序列模型. 会使用seq2seq_model的decoder进行生成\n","        :param int,None bos_token_id: 句子开头的token id\n","        :param int,None eos_token_id: 句子结束的token id\n","        :param int max_length: 生成句子的最大长度, 每句话的decode长度为max_length + max_len_a*src_len\n","        :param float max_len_a: 每句话的decode长度为max_length + max_len_a*src_len。 如果不为0，需要保证State中包含encoder_mask\n","        :param int num_beams: beam search的大小\n","        :param bool do_sample: 是否通过采样的方式生成\n","        :param float temperature: 只有在do_sample为True才有意义\n","        :param int top_k: 只从top_k中采样\n","        :param float top_p: 只从top_p的token中采样，nucles sample\n","        :param float repetition_penalty: 多大程度上惩罚重复的token\n","        :param float length_penalty: 对长度的惩罚，小于1鼓励长句，大于1鼓励短剧\n","        :param int pad_token_id: 当某句话生成结束之后，之后生成的内容用pad_token_id补充\n","        \"\"\"\n","        super().__init__()\n","        self.seq2seq_model = seq2seq_model\n","        self.restricter = restricter\n","        self.generator = SequenceGenerator(seq2seq_model.decoder, max_length=max_length, max_len_a=max_len_a,\n","                                           num_beams=num_beams,\n","                                           do_sample=do_sample,\n","                                           bos_token_id=bos_token_id,\n","                                           eos_token_id=eos_token_id,\n","                                           repetition_penalty=repetition_penalty, length_penalty=length_penalty,\n","                                           pad_token_id=pad_token_id,\n","                                           restricter=restricter)\n","\n","    def forward(self, src_tokens, tgt_tokens, src_seq_len=None, tgt_seq_len=None, first=None):\n","        \"\"\"\n","        透传调用seq2seq_model的forward\n","        :param torch.LongTensor src_tokens: bsz x max_len\n","        :param torch.LongTensor tgt_tokens: bsz x max_len'\n","        :param torch.LongTensor src_seq_len: bsz\n","        :param torch.LongTensor tgt_seq_len: bsz\n","        :return:\n","        \"\"\"\n","\n","        return self.seq2seq_model(src_tokens, tgt_tokens, src_seq_len, tgt_seq_len, first)\n","\n","    def predict(self, src_tokens, src_seq_len=None, first=None):\n","        \"\"\"\n","        给定source的内容，输出generate的内容\n","        :param torch.LongTensor src_tokens: bsz x max_len\n","        :param torch.LongTensor src_seq_len: bsz\n","        :return:\n","        \"\"\"\n","        state = self.seq2seq_model.prepare_state(src_tokens, src_seq_len, first)\n","        result = self.generator.generate(state)\n","        return {'pred': result}\n","\n","\n","r\"\"\"\n","\"\"\"\n","\n","__all__ = [\n","    'SequenceGenerator'\n","]\n","\n","\n","\n","class SequenceGenerator:\n","    \"\"\"\n","    给定一个Seq2SeqDecoder，decode出句子\n","    \"\"\"\n","    def __init__(self, decoder: Seq2SeqDecoder, max_length=20, max_len_a=0.0, num_beams=1,\n","                 do_sample=False, bos_token_id=None, eos_token_id=None,\n","                 repetition_penalty=1, length_penalty=1.0, pad_token_id=0, restricter=None):\n","        \"\"\"\n","        :param Seq2SeqDecoder decoder: Decoder对象\n","        :param int max_length: 生成句子的最大长度, 每句话的decode长度为max_length + max_len_a*src_len\n","        :param float max_len_a: 每句话的decode长度为max_length + max_len_a*src_len。 如果不为0，需要保证State中包含encoder_mask\n","        :param int num_beams: beam search的大小\n","        :param bool do_sample: 是否通过采样的方式生成\n","        :param float temperature: 只有在do_sample为True才有意义\n","        :param int top_k: 只从top_k中采样\n","        :param float top_p: 只从top_p的token中采样，nucles sample\n","        :param int,None bos_token_id: 句子开头的token id\n","        :param int,None eos_token_id: 句子结束的token id\n","        :param float repetition_penalty: 多大程度上惩罚重复的token\n","        :param float length_penalty: 对长度的惩罚，小于1鼓励长句，大于1鼓励短剧\n","        :param int pad_token_id: 当某句话生成结束之后，之后生成的内容用pad_token_id补充\n","        \"\"\"\n","        self.generate_func = partial(greedy_generate, decoder=decoder, max_length=max_length, max_len_a=max_len_a,\n","                                     num_beams=num_beams,\n","                                     bos_token_id=bos_token_id, eos_token_id=eos_token_id,\n","                                     repetition_penalty=repetition_penalty,\n","                                     length_penalty=length_penalty, pad_token_id=pad_token_id,\n","                                     restricter=restricter)\n","        self.do_sample = do_sample\n","        self.max_length = max_length\n","        self.num_beams = num_beams\n","        self.bos_token_id = bos_token_id\n","        self.eos_token_id = eos_token_id\n","        self.repetition_penalty = repetition_penalty\n","        self.length_penalty = length_penalty\n","        self.decoder = decoder\n","        self.pad_token_id = pad_token_id\n","        self.restricter = restricter\n","        self.max_len_a = max_len_a\n","\n","    def set_new_generator(self, max_length=-1, max_len_a=-1, num_beams=-1,\n","                          repetition_penalty=-1, length_penalty=-1, restricter=-1):\n","        if max_length == -1:\n","            max_length = self.max_length\n","        if max_len_a == -1:\n","            max_len_a = self.max_len_a\n","        if num_beams == -1:\n","            num_beams = self.num_beams\n","        if repetition_penalty == -1:\n","            repetition_penalty = self.repetition_penalty\n","        if length_penalty == -1:\n","            length_penalty = self.length_penalty\n","        if restricter == -1:\n","            restricter = self.restricter\n","        self.generate_func = partial(greedy_generate, decoder=self.decoder, max_length=max_length, max_len_a=max_len_a,\n","                                     num_beams=num_beams,\n","                                     bos_token_id=self.bos_token_id, eos_token_id=self.eos_token_id,\n","                                     repetition_penalty=repetition_penalty,\n","                                     length_penalty=length_penalty, pad_token_id=self.pad_token_id,\n","                                     restricter=restricter)\n","\n","    @torch.no_grad()\n","    def generate(self, state, tokens=None):\n","        \"\"\"\n","        :param State state: encoder结果的State, 是与Decoder配套是用的\n","        :param torch.LongTensor,None tokens: batch_size x length, 开始的token\n","        :return: bsz x max_length' 生成的token序列。如果eos_token_id不为None, 每个sequence的结尾一定是eos_token_id\n","        \"\"\"\n","\n","        return self.generate_func(tokens=tokens, state=state)\n","\n","@torch.no_grad()\n","def greedy_generate(decoder, tokens=None, state=None, max_length=20, max_len_a=0.0, num_beams=1,\n","                    bos_token_id=None, eos_token_id=None, pad_token_id=0,\n","                    repetition_penalty=1, length_penalty=1.0, restricter=None):\n","    \"\"\"\n","    贪婪地搜索句子\n","    :param Decoder decoder: Decoder对象\n","    :param torch.LongTensor tokens: batch_size x len, decode的输入值，如果为None，则自动从bos_token_id开始生成\n","    :param State state: 应该包含encoder的一些输出。\n","    :param int max_length: 生成句子的最大长度, 每句话的decode长度为max_length + max_len_a*src_len\n","    :param float max_len_a: 每句话的decode长度为max_length + max_len_a*src_len。 如果不为0，需要保证State中包含encoder_mask\n","    :param int num_beams: 使用多大的beam进行解码。\n","    :param int bos_token_id: 如果tokens传入为None，则使用bos_token_id开始往后解码。\n","    :param int eos_token_id: 结束的token，如果为None，则一定会解码到max_length这么长。\n","    :param int pad_token_id: pad的token id\n","    :param float repetition_penalty: 对重复出现的token多大的惩罚。\n","    :param float length_penalty: 对每个token（除了eos）按照长度进行一定的惩罚。\n","    :return:\n","    \"\"\"\n","    if num_beams == 1:\n","        token_ids = _no_beam_search_generate(decoder, tokens=tokens, state=state, max_length=max_length, max_len_a=max_len_a,\n","                                             bos_token_id=bos_token_id, eos_token_id=eos_token_id,\n","                                             repetition_penalty=repetition_penalty, length_penalty=length_penalty,\n","                                             pad_token_id=pad_token_id, restricter=restricter)\n","    else:\n","        token_ids = _beam_search_generate(decoder, tokens=tokens, state=state, max_length=max_length, max_len_a=max_len_a,\n","                                          num_beams=num_beams,\n","                                          bos_token_id=bos_token_id, eos_token_id=eos_token_id, do_sample=False,\n","                                          repetition_penalty=repetition_penalty, length_penalty=length_penalty,\n","                                          pad_token_id=pad_token_id, restricter=restricter)\n","\n","    return token_ids\n","\n","\n","def _no_beam_search_generate(decoder: Seq2SeqDecoder, state, tokens=None, max_length=20, max_len_a=0.0, bos_token_id=None,\n","                             eos_token_id=None,\n","                             repetition_penalty=1.0, length_penalty=1.0, pad_token_id=0,\n","                             restricter=None):\n","    device = _get_model_device(decoder)\n","    if tokens is None:\n","        if bos_token_id is None:\n","            raise RuntimeError(\"You have to specify either `tokens` or `bos_token_id`.\")\n","        batch_size = state.num_samples\n","        if batch_size is None:\n","            raise RuntimeError(\"Cannot infer the number of samples from `state`.\")\n","        tokens = torch.full([batch_size, 1], fill_value=bos_token_id, dtype=torch.long).to(device)\n","    batch_size = tokens.size(0)\n","    if state.num_samples:\n","        assert state.num_samples == batch_size, \"The number of samples in `tokens` and `state` should match.\"\n","\n","    if eos_token_id is None:\n","        _eos_token_id = -1\n","    else:\n","        _eos_token_id = eos_token_id\n","\n","    scores = decoder.decode(tokens=tokens, state=state)  # 主要是为了update state\n","    # 这里需要考虑如果在第一个位置就结束的情况\n","    # if _eos_token_id!=-1:\n","    #     scores[:, _eos_token_id] = -1e12\n","\n","    if restricter is not None:\n","        _, next_tokens = restricter(state, tokens, scores, num_beams=1)\n","    else:\n","        next_tokens = scores.argmax(dim=-1, keepdim=True)\n","    token_ids = torch.cat([tokens, next_tokens], dim=1)\n","    cur_len = token_ids.size(1)\n","    dones = token_ids.new_zeros(batch_size).eq(1).__or__(next_tokens.squeeze(1).eq(eos_token_id))\n","    # tokens = tokens[:, -1:]\n","\n","    if max_len_a!=0:\n","        # (bsz x num_beams, )\n","        if state.encoder_mask is not None:\n","            max_lengths = (state.encoder_mask.sum(dim=1).float()*max_len_a).long() + max_length\n","        else:\n","            max_lengths = tokens.new_full((tokens.size(0), ), fill_value=max_length, dtype=torch.long)\n","        real_max_length = max_lengths.max().item()\n","    else:\n","        real_max_length = max_length\n","        if state.encoder_mask is not None:\n","            max_lengths = state.encoder_mask.new_ones(state.encoder_mask.size(0)).long()*max_length\n","        else:\n","            max_lengths = tokens.new_full((tokens.size(0),), fill_value=max_length, dtype=torch.long)\n","\n","    while cur_len < real_max_length:\n","        scores = decoder.decode(tokens=token_ids, state=state)  # batch_size x vocab_size\n","\n","        if repetition_penalty != 1.0:\n","            token_scores = scores.gather(dim=1, index=token_ids)\n","            lt_zero_mask = token_scores.lt(0).float()\n","            ge_zero_mask = lt_zero_mask.eq(0).float()\n","            token_scores = lt_zero_mask * repetition_penalty * token_scores + ge_zero_mask / repetition_penalty * token_scores\n","            scores.scatter_(dim=1, index=token_ids, src=token_scores)\n","\n","        if eos_token_id is not None and length_penalty != 1.0:\n","            token_scores = scores / cur_len ** length_penalty  # batch_size x vocab_size\n","            eos_mask = scores.new_ones(scores.size(1))\n","            eos_mask[eos_token_id] = 0\n","            eos_mask = eos_mask.unsqueeze(0).eq(1)\n","            scores = scores.masked_scatter(eos_mask, token_scores)  # 也即除了eos，其他词的分数经过了放大/缩小\n","\n","        if restricter is not None:\n","            _, next_tokens = restricter(state, token_ids, scores, 1)\n","        else:\n","            next_tokens = scores.argmax(dim=-1, keepdim=True)\n","        next_tokens = next_tokens.squeeze(-1)\n","\n","        # 如果已经达到对应的sequence长度了，就直接填为eos了\n","        if _eos_token_id!=-1:\n","            next_tokens = next_tokens.masked_fill(max_lengths.eq(cur_len+1), _eos_token_id)\n","        next_tokens = next_tokens.masked_fill(dones, pad_token_id)  # 对已经搜索完成的sample做padding\n","        tokens = next_tokens.unsqueeze(1)\n","\n","        token_ids = torch.cat([token_ids, tokens], dim=-1)  # batch_size x max_len\n","\n","        end_mask = next_tokens.eq(_eos_token_id)\n","        dones = dones.__or__(end_mask)\n","        cur_len += 1\n","\n","        if dones.min() == 1:\n","            break\n","\n","    # if eos_token_id is not None:\n","    #     tokens.scatter(index=max_lengths[:, None], dim=1, value=eos_token_id)  # 将最大长度位置设置为eos\n","    # if cur_len == max_length:\n","    #     token_ids[:, -1].masked_fill_(~dones, eos_token_id)  # 若到最长长度仍未到EOS，则强制将最后一个词替换成eos\n","    return token_ids\n","\n","\n","def _beam_search_generate(decoder: Seq2SeqDecoder, tokens=None, state=None, max_length=20, max_len_a=0.0, num_beams=4,\n","                          bos_token_id=None, eos_token_id=None, do_sample=True,\n","                          repetition_penalty=1.0, length_penalty=None, pad_token_id=0,\n","                          restricter=None) -> torch.LongTensor:\n","    assert do_sample is False\n","    # 进行beam search\n","    device = _get_model_device(decoder)\n","    if tokens is None:\n","        if bos_token_id is None:\n","            raise RuntimeError(\"You have to specify either `tokens` or `bos_token_id`.\")\n","        batch_size = state.num_samples\n","        if batch_size is None:\n","            raise RuntimeError(\"Cannot infer the number of samples from `state`.\")\n","        tokens = torch.full([batch_size, 1], fill_value=bos_token_id, dtype=torch.long).to(device)\n","    batch_size = tokens.size(0)\n","    if state.num_samples:\n","        assert state.num_samples == batch_size, \"The number of samples in `tokens` and `state` should match.\"\n","\n","    if eos_token_id is None:\n","        _eos_token_id = -1\n","    else:\n","        _eos_token_id = eos_token_id\n","\n","    scores = decoder.decode(tokens=tokens, state=state)  # 这里要传入的是整个句子的长度\n","    # 这里需要考虑如果在第一个位置就结束的情况\n","    # if _eos_token_id!=-1:\n","    #     scores[:, _eos_token_id] = -1e12\n","    vocab_size = scores.size(1)\n","    assert vocab_size >= num_beams, \"num_beams should be smaller than the number of vocabulary size.\"\n","\n","    scores = F.log_softmax(scores, dim=-1)  # (batch_size, vocab_size)\n","    # 得到(batch_size, num_beams), (batch_size, num_beams)\n","    # TODO 把限制写到这个位置, 加1是因为需要考虑输出就是eos的情况\n","    if restricter is not None:\n","        _next_scores, _next_tokens = restricter(state, tokens, scores, num_beams+1)\n","    else:\n","        # 是bsz x (num_beams+1)大小的东西\n","        _next_scores, _next_tokens = torch.topk(scores, num_beams+1, dim=1, largest=True, sorted=True)\n","\n","    # 根据index来做顺序的调转\n","    indices = torch.arange(batch_size, dtype=torch.long).to(device)\n","    indices = indices.repeat_interleave(num_beams)\n","    state.reorder_state(indices)\n","    tokens = tokens.index_select(dim=0, index=indices)  # batch_size * num_beams x length\n","\n","    # if hasattr(state, 'tgt_seq_len'):  # TODO 应该需要删除\n","    #     max_lengths = state.tgt_seq_len\n","    #     real_max_length = max_lengths.max().item()\n","    if max_len_a!=0:\n","        # (bsz x num_beams, )\n","        if state.encoder_mask is not None:\n","            max_lengths = (state.encoder_mask.sum(dim=1).float()*max_len_a).long() + max_length\n","        else:\n","            max_lengths = tokens.new_full((batch_size*num_beams, ), fill_value=max_length, dtype=torch.long)\n","        real_max_length = max_lengths.max().item()\n","    else:\n","        real_max_length = max_length\n","        if state.encoder_mask is not None:\n","            max_lengths = state.encoder_mask.new_ones(state.encoder_mask.size(0)).long()*max_length\n","        else:\n","            max_lengths = tokens.new_full((batch_size*num_beams,), fill_value=max_length, dtype=torch.long)\n","    hypos = [\n","        BeamHypotheses(num_beams, real_max_length, length_penalty, early_stopping=False) for _ in range(batch_size)\n","    ]\n","\n","    not_eos_mask = _next_tokens.ne(_eos_token_id)  # 为1的地方不是eos\n","    keep_mask = not_eos_mask.cumsum(dim=1).le(num_beams)  # 为1的地方需要保留\n","    keep_mask = not_eos_mask.__and__(keep_mask)  # 为1的地方是需要进行下一步search的\n","\n","    next_tokens = _next_tokens.masked_select(keep_mask).view(batch_size, num_beams)  # 这是真的接下来要继续的\n","    next_scores = _next_scores.masked_select(keep_mask).view(batch_size, num_beams)\n","\n","    rows, cols = not_eos_mask.eq(0)[:, :num_beams].nonzero(as_tuple=True)\n","\n","    if len(rows)>0:  # 说明有的开头就结束了\n","        for row, col in zip(rows.tolist(), cols.tolist()):\n","            _token = torch.cat([tokens[row*num_beams], _next_tokens[row, col:col+1]], dim=0)\n","            hypos[row].add(_token.clone(), _next_scores[row, col].item())\n","\n","    # 记录生成好的token (batch_size', cur_len)\n","    token_ids = torch.cat([tokens, next_tokens.view(-1, 1)], dim=-1)\n","    dones = [False] * batch_size\n","\n","    beam_scores = next_scores.view(-1)  # batch_size * num_beams\n","\n","    #  用来记录已经生成好的token的长度\n","    cur_len = token_ids.size(1)\n","\n","    # 0, num_beams, 2*num_beams, ...\n","    batch_inds_with_numbeams_interval = (torch.arange(batch_size) * num_beams).view(-1, 1).to(token_ids)\n","\n","    while cur_len < real_max_length:\n","        scores = decoder.decode(token_ids, state)  # (bsz x num_beams, vocab_size)\n","        if repetition_penalty != 1.0:\n","            token_scores = scores.gather(dim=1, index=token_ids)\n","            lt_zero_mask = token_scores.lt(0).float()\n","            ge_zero_mask = lt_zero_mask.eq(0).float()\n","            token_scores = lt_zero_mask * repetition_penalty * token_scores + ge_zero_mask / repetition_penalty * token_scores\n","            scores.scatter_(dim=1, index=token_ids, src=token_scores)\n","\n","        if _eos_token_id!=-1:\n","            max_len_eos_mask = max_lengths.eq(cur_len+1)\n","            eos_scores = scores[:, _eos_token_id]\n","            # 如果已经达到最大长度，就把eos的分数加大\n","            scores[:, _eos_token_id] = torch.where(max_len_eos_mask, eos_scores+1e32, eos_scores)\n","\n","        scores = F.log_softmax(scores, dim=-1)  # (batch_size * num_beams, vocab_size)\n","        _scores = scores + beam_scores[:, None]  # (batch_size * num_beams, vocab_size)\n","        _scores = _scores.view(batch_size, -1)  # (batch_size, num_beams*vocab_size)\n","        # TODO 把限制加到这个位置\n","        if restricter is not None:\n","            next_scores, ids = restricter(state, token_ids, _scores, 2 * num_beams)\n","        else:\n","            next_scores, ids = torch.topk(_scores, 2 * num_beams, dim=1, largest=True, sorted=True)  # (bsz, 2*num_beams)\n","        from_which_beam = ids // vocab_size  # (batch_size, 2*num_beams)\n","        next_tokens = ids % vocab_size  # (batch_size, 2*num_beams)\n","\n","        #  接下来需要组装下一个batch的结果。\n","        #  需要选定哪些留下来\n","        # next_scores, sorted_inds = next_scores.sort(dim=-1, descending=True)\n","        # next_tokens = next_tokens.gather(dim=1, index=sorted_inds)\n","        # from_which_beam = from_which_beam.gather(dim=1, index=sorted_inds)\n","\n","        not_eos_mask = next_tokens.ne(_eos_token_id)  # 为1的地方不是eos\n","        keep_mask = not_eos_mask.cumsum(dim=1).le(num_beams)  # 为1的地方需要保留\n","        keep_mask = not_eos_mask.__and__(keep_mask)  # 为1的地方是需要进行下一步search的\n","\n","        _next_tokens = next_tokens.masked_select(keep_mask).view(-1, 1)\n","        _from_which_beam = from_which_beam.masked_select(keep_mask).view(batch_size, num_beams)  # 上面的token是来自哪个beam\n","        _next_scores = next_scores.masked_select(keep_mask).view(batch_size, num_beams)\n","        beam_scores = _next_scores.view(-1)\n","\n","        flag = True\n","        if cur_len+1 == real_max_length:\n","            eos_batch_idx = torch.arange(batch_size).to(next_tokens).repeat_interleave(repeats=num_beams, dim=0)\n","            eos_beam_ind = torch.arange(num_beams).to(token_ids).repeat(batch_size)  # 表示的是indice\n","            eos_beam_idx = from_which_beam[:, :num_beams].reshape(-1)  # 表示的是从哪个beam获取得到的\n","        else:\n","            # 将每个batch中在num_beam内的序列添加到结束中, 为1的地方需要结束了\n","            effective_eos_mask = next_tokens[:, :num_beams].eq(_eos_token_id)  # batch_size x num_beams\n","            if effective_eos_mask.sum().gt(0):\n","                eos_batch_idx, eos_beam_ind = effective_eos_mask.nonzero(as_tuple=True)\n","                # 是由于from_which_beam是 (batch_size, 2*num_beams)的，所以需要2*num_beams\n","                eos_beam_idx = eos_batch_idx * num_beams * 2 + eos_beam_ind\n","                eos_beam_idx = from_which_beam.view(-1)[eos_beam_idx]  # 获取真实的从哪个beam获取的eos\n","            else:\n","                flag = False\n","\n","        if flag:\n","            _token_ids = torch.cat([token_ids, _next_tokens], dim=-1)\n","            for batch_idx, beam_ind, beam_idx in zip(eos_batch_idx.tolist(), eos_beam_ind.tolist(),\n","                                                     eos_beam_idx.tolist()):\n","                if not dones[batch_idx]:\n","                    score = next_scores[batch_idx, beam_ind].item()\n","                    # 之后需要在结尾新增一个eos\n","                    if _eos_token_id!=-1:\n","                        hypos[batch_idx].add(_token_ids[batch_idx * num_beams + beam_idx, :cur_len].clone(), score)\n","                    else:\n","                        hypos[batch_idx].add(_token_ids[batch_idx * num_beams + beam_idx].clone(), score)\n","\n","        # 更改state状态, 重组token_ids\n","        reorder_inds = (batch_inds_with_numbeams_interval + _from_which_beam).view(-1)  # flatten成一维\n","        state.reorder_state(reorder_inds)\n","        # 重新组织token_ids的状态\n","        token_ids = torch.cat([token_ids.index_select(index=reorder_inds, dim=0), _next_tokens], dim=-1)\n","\n","        for batch_idx in range(batch_size):\n","            dones[batch_idx] = dones[batch_idx] or hypos[batch_idx].is_done(next_scores[batch_idx, 0].item()) or \\\n","                               max_lengths[batch_idx*num_beams]==cur_len+1\n","\n","        cur_len += 1\n","\n","        if all(dones):\n","            break\n","\n","    # select the best hypotheses\n","    tgt_len = token_ids.new_zeros(batch_size)\n","    best = []\n","\n","    for i, hypotheses in enumerate(hypos):\n","        best_hyp = max(hypotheses.hyp, key=lambda x: x[0])[1]\n","        # 把上面替换为非eos的词替换回eos\n","        if _eos_token_id!=-1:\n","            best_hyp = torch.cat([best_hyp, best_hyp.new_ones(1)*_eos_token_id])\n","        tgt_len[i] = len(best_hyp)\n","        best.append(best_hyp)\n","\n","    # generate target batch\n","    decoded = token_ids.new_zeros(batch_size, tgt_len.max().item()).fill_(pad_token_id)\n","    for i, hypo in enumerate(best):\n","        decoded[i, :tgt_len[i]] = hypo\n","\n","    return decoded\n","\n","\n","class BeamHypotheses(object):\n","    def __init__(self, num_beams, max_length, length_penalty, early_stopping):\n","        \"\"\"\n","        Initialize n-best list of hypotheses.\n","        \"\"\"\n","        self.max_length = max_length - 1  # ignoring bos_token\n","        self.length_penalty = length_penalty\n","        self.early_stopping = early_stopping\n","        self.num_beams = num_beams\n","        self.hyp = []\n","        self.worst_score = 1e9\n","\n","    def __len__(self):\n","        \"\"\"\n","        Number of hypotheses in the list.\n","        \"\"\"\n","        return len(self.hyp)\n","\n","    def add(self, hyp, sum_logprobs):\n","        \"\"\"\n","        Add a new hypothesis to the list.\n","        \"\"\"\n","        score = sum_logprobs / len(hyp) ** self.length_penalty\n","        if len(self) < self.num_beams or score > self.worst_score:\n","            self.hyp.append((score, hyp))\n","            if len(self) > self.num_beams:\n","                sorted_scores = sorted([(s, idx) for idx, (s, _) in enumerate(self.hyp)])\n","                del self.hyp[sorted_scores[0][1]]\n","                self.worst_score = sorted_scores[1][0]\n","            else:\n","                self.worst_score = min(score, self.worst_score)\n","\n","    def is_done(self, best_sum_logprobs):\n","        \"\"\"\n","        If there are enough hypotheses and that none of the hypotheses being generated\n","        can become better than the worst one in the heap, then we are done with this sentence.\n","        \"\"\"\n","        if len(self) < self.num_beams:\n","            return False\n","        elif self.early_stopping:\n","            return True\n","        else:\n","            return self.worst_score >= best_sum_logprobs / self.max_length ** self.length_penalty"]},{"cell_type":"markdown","metadata":{"id":"PE8Y8i_gt9rg"},"source":["#LOSS and METRIC"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Jpp_mQ5wuAyl"},"outputs":[],"source":["from fastNLP import LossBase\n","import torch.nn.functional as F\n","from fastNLP import seq_len_to_mask\n","\n","\n","class Seq2SeqLoss(LossBase):\n","    def __init__(self):\n","        super().__init__()\n","\n","    def get_loss(self, tgt_tokens, tgt_seq_len, pred):\n","        \"\"\"\n","        :param tgt_tokens: bsz x max_len, [sos, tokens, eos]\n","        :param pred: bsz x max_len-1 x vocab_size\n","        :return:\n","        \"\"\"\n","        tgt_seq_len = tgt_seq_len - 1\n","        mask = seq_len_to_mask(tgt_seq_len, max_len=tgt_tokens.size(1) - 1).eq(0)\n","        tgt_tokens = tgt_tokens[:, 1:].masked_fill(mask, -100)\n","        loss = F.cross_entropy(target=tgt_tokens, input=pred.transpose(1, 2))\n","        return loss"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aUQYJUKfuBn3"},"outputs":[],"source":["from fastNLP import MetricBase\n","from fastNLP.core.metrics import _compute_f_pre_rec\n","from collections import Counter\n","\n","\n","class Seq2SeqSpanMetric(MetricBase):\n","    def __init__(self, eos_token_id, num_labels, opinion_first=True):\n","        super(Seq2SeqSpanMetric, self).__init__()\n","        self.eos_token_id = eos_token_id\n","        self.num_labels = num_labels\n","        self.word_start_index = num_labels + 2  # +2, shift for sos and eos\n","\n","        self.quad_fp = 0\n","        self.quad_tp = 0\n","        self.quad_fn = 0\n","        self.em = 0\n","        self.invalid = 0\n","        self.total = 0\n","        assert opinion_first is False, \"Current metric only supports aspect first\"\n","\n","        self.opinin_first = opinion_first\n","\n","    def evaluate(self, target_span, pred, tgt_tokens):\n","        self.total += pred.size(0)\n","        pred_eos_index = pred.flip(dims=[1]).eq(self.eos_token_id).cumsum(dim=1).long()\n","        target_eos_index = tgt_tokens.flip(dims=[1]).eq(self.eos_token_id).cumsum(dim=1).long()\n","\n","        pred = pred[:, 1:]  # delete </s>\n","        tgt_tokens = tgt_tokens[:, 1:]\n","        pred_seq_len = pred_eos_index.flip(dims=[1]).eq(pred_eos_index[:, -1:]).sum(dim=1)  # bsz\n","        pred_seq_len = (pred_seq_len - 2).tolist()\n","        target_seq_len = target_eos_index.flip(dims=[1]).eq(target_eos_index[:, -1:]).sum(dim=1)  # bsz\n","        target_seq_len = (target_seq_len - 2).tolist()\n","        pred_spans = []\n","        for i, (ts, ps) in enumerate(zip(target_span, pred.tolist())):\n","            em = 0\n","            ps = ps[:pred_seq_len[i]]\n","            if pred_seq_len[i] == target_seq_len[i]:\n","                em = int(\n","                    tgt_tokens[i, :target_seq_len[i]].eq(pred[i, :target_seq_len[i]]).sum().item() == target_seq_len[i])\n","            self.em += em\n","            invalid = 0\n","            pairs = []\n","            cur_pair = []\n","            if len(ps):\n","                count = 0\n","                for index, j in enumerate(ps):\n","                    if j < self.word_start_index:\n","                        cur_pair.append(j)\n","                        if count<2:\n","                            count+=1\n","                        else:\n","                            if len(cur_pair) != 7 or cur_pair[0] > cur_pair[1] or cur_pair[4] > cur_pair[5]:\n","                                invalid = 1\n","                            else:\n","                                pairs.append(tuple(cur_pair))\n","                            cur_pair = []\n","                            count=0\n","                    else:\n","                        cur_pair.append(j)\n","            pred_spans.append(pairs.copy())\n","            self.invalid += invalid\n","\n","            ts = set([tuple(t) for t in ts])\n","            ps = set(pairs)\n","            for p in list(ps):\n","                if p in ts:\n","                    ts.remove(p)\n","                    self.quad_tp += 1\n","                else:\n","                    self.quad_fp += 1\n","\n","            self.quad_fn += len(ts)\n","\n","    def get_metric(self, reset=True):\n","        res = {}\n","        f, pre, rec = _compute_f_pre_rec(1, self.quad_tp, self.quad_fn, self.quad_fp)\n","\n","        res['quad_f'] = round(f, 4)*100\n","        res['quad_rec'] = round(rec, 4)*100\n","        res['quad_pre'] = round(pre, 4)*100\n","\n","        res['em'] = round(self.em / self.total, 4)\n","        res['invalid'] = round(self.invalid / self.total, 4)\n","        if reset:\n","            self.quad_fp = 0\n","            self.quad_tp = 0\n","            self.quad_fn = 0\n","            self.em = 0\n","            self.invalid = 0\n","            self.total = 0\n","        return res\n","\n","\n","def _compute_tp_fn_fp(ps, ts):\n","    ps = ps.copy()\n","    tp = 0\n","    fp = 0\n","    fn = 0\n","    if isinstance(ts, set):\n","        ts = {key: 1 for key in list(ts)}\n","    if isinstance(ps, set):\n","        ps = {key: 1 for key in list(ps)}\n","    for key in ts.keys():\n","        t_num = ts[key]\n","        if key not in ps:\n","            p_num = 0\n","        else:\n","            p_num = ps[key]\n","        tp += min(p_num, t_num)\n","        fp += max(p_num - t_num, 0)\n","        fn += max(t_num - p_num, 0)\n","        if key in ps:\n","            ps.pop(key)\n","    fp += sum(ps.values())\n","    return tp, fn, fp"]},{"cell_type":"markdown","metadata":{"id":"Zd3VqYYYuLc3"},"source":["#UTILS"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GvIcO41euLVM"},"outputs":[],"source":["import numpy as np\n","\n","\n","def get_max_len_max_len_a(data_bundle, max_len=10):\n","    \"\"\"\n","    :param data_bundle:\n","    :param max_len:\n","    :return:\n","    \"\"\"\n","    max_len_a = -1\n","    for name, ds in data_bundle.iter_datasets():\n","        if name=='train':continue\n","        src_seq_len = np.array(ds.get_field('src_seq_len').content)\n","        tgt_seq_len = np.array(ds.get_field('tgt_seq_len').content)\n","        _len_a = round(max(np.maximum(tgt_seq_len - max_len+2, 0)/src_seq_len), 1)\n","\n","        if _len_a>max_len_a:\n","            max_len_a = _len_a\n","\n","    return max_len, max_len_a\n","\n","\n","def get_num_parameters(model):\n","    num_param = 0\n","    for name, param in model.named_parameters():\n","        num_param += np.prod(param.size())\n","    print(f\"The number of parameters is {num_param}\")"]},{"cell_type":"markdown","metadata":{"id":"eLT2o2uRM_1v"},"source":["#Train"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jGJdZwREM_Ff"},"outputs":[],"source":["import sys\n","sys.path.append('../')\n","import os\n","if 'p' in os.environ:\n","    os.environ['CUDA_VISIBLE_DEVICES'] = os.environ['p']\n","    # os.environ['CUDA_VISIBLE_DEVICES'] = '7'\n","\n","import warnings\n","warnings.filterwarnings('ignore')\n","from fastNLP import Trainer,Tester\n","from fastNLP import BucketSampler, GradientClipCallback, cache_results, WarmupCallback\n","from fastNLP import FitlogCallback\n","from fastNLP.core.sampler import SortedSampler\n","import fitlog\n","from torch import optim\n","\n","# fitlog.debug()\n","lr = 5e-5\n","n_epochs = 50\n","batch_size = 5\n","num_beams = 4\n","dataset_name = 'pengb/16res'\n","opinion_first = False\n","length_penalty = 1.0\n","\n","decoder_type = 'avg_score'\n","bart_name = 'facebook/bart-base'\n","use_encoder_mlp = 1"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"s7DvIWAbQOCX"},"outputs":[],"source":["demo = False\n","if demo:\n","    cache_fn = f\"caches/data_{bart_name}_{dataset_name}_{opinion_first}_demo.pt\"\n","else:\n","    cache_fn = f\"caches/data_{bart_name}_{dataset_name}_{opinion_first}.pt\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VRfiNhwJQN89"},"outputs":[],"source":["@cache_results(cache_fn, _refresh=False)\n","def get_data():\n","    pipe = BartBPEABSAPipe(tokenizer=bart_name, opinion_first=opinion_first)\n","    data_bundle = pipe.process_from_file(f'/content/drive/MyDrive/Sentiment Analysis/data/Laptop-ACOS/json', demo=demo)\n","    return data_bundle, pipe.tokenizer, pipe.mapping2id, pipe.mapping2targetid"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":148,"referenced_widgets":["77e9b179893f4ab3ba51a6391b1fc8bb","b6d7f3ec2d59448dac6ccc071e9ab4bc","b78c687c808b4b75bbd4e21d090ec025","a57323016e534561a35f8ea64f508337","861c7f22be0a4eecb1b26b9865ce6a21","1fa7e4a72f484185ad2707f96af677c5","5833af8070994e5aa22ae242d67e2f51","e8d65133832b4cde8508b1bcc19289b2","1a180cfba5384384ba92bc15b45ad5cd","885f8baf1ed749829d80c9588950baa0","93e56765d22b4b88afae06d77f128703","1585dc1f347945309742b457f824e738","13d9e8c85c6a496aaf09b7254195c216","75c589213bc44c769ab05d6e65d172af","2d4124f8b6c84862b6af77061bd6a895","20ddf36655f64059b9ab5a30ed02e01d","274245a3820548ab9e7b135389c8a8ee","993a4c9aa53e40e39d2abb7f77ed133e","86adb814b36a4e8ea508d7019311b780","8e85d5e683334d9c86ecb1c126934a38","2eacaeaed42c4c2ca6df7b8d0b31c94f","0317021790d640e2b206bebe1c242ab9","d2e015ec3661471bade1d827b6dd8ef1","e1aef09207784f6da9619acf9776f202","76ded5525c6c46c396052fc204a399c7","aea9a7d58aa441d19fe5b36830dfed25","f9d080f43a0449768cbf39ce6149dfe5","b862e02145fb4ad0a937e6083d8966d2","a1bbcbddf93744978b98afc8d4c136a8","f052ea01c6b445e7a1e0a2374e7bd6a2","7c7423113958457c956ecad224249510","8eb8f86261c84fb88bc08977ef7ad1cd","14e1df0ea1a04945a90b90bee7905a36","1a04ef7de487423db5ce6a422d36dbc0","c0d8bd50549f472f80041302bd8e3c71","bd712b628a304a90b7bfdf80944c0316","ecc7ad2c6af94048a0dcdc7f153ce064","abd0839d1c734ae8b690b13b71f53bd6","072878d5e0314433aa64084aeb341f1d","0f2006f0315f4f24ad22353045857c80","82f71acba4d44024934edf3dc97b474f","bae6b83b098d40ef890cc1b19cbee79a","4fdec4654a5640f8bcd7e66913b4bdaf","1af8e3c02f844762908e3bdbc1b3df20","53a4809ee7ea405cb3894e2388deada1","dfd77ddea8d74cddb95559442706e0ba","a96d8a5eca614f8b9b1e16b1c2db8d59","6b2dd62933af4018bf0ab4ce217cbba6","e8ee34d8f098400d95ec58f374ce8e79","745640fde7b94bd3b0617d7b2553dedf","ff5a510b7129480fbde37fcd50778694","3ff91b64b924474380a42235370bd1f7","eb47b6dad8df41f5926657da36baec92","d6837d42897d45ba8ebe8cfade160a21","7ed1f2510bf347b8af068b11304b3b47","6c00442857134aa18cd24ee13ea97e87","8ae9d9ed94ce41008d0cc6911556c83c","dbc7f98eb96d4872970076b5afeb7c47","e7ca370f360440f3addeb7718f912939","063326c8b99842b4aff01b6c0b5034a6","91c7035922eb4f8bacd18e0660ba30c0","677318ba6b414ff3b899bcc526739eb1","393f680356ff4d3899d88f47da4a6157","6e59fea295b64760a3978a4b7399005b","76beef09ad2043f2ad4e98ea3113b7c4","132fd2d0273749fdb3ef30fb78da3229"]},"executionInfo":{"elapsed":30630,"status":"ok","timestamp":1654621131721,"user":{"displayName":"Duy Hoang","userId":"17457647490907439684"},"user_tz":-420},"id":"eQGhrUXuR1Vz","outputId":"b318cbce-c0cf-4e7a-a067-895d12fed49f"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/1.55k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"77e9b179893f4ab3ba51a6391b1fc8bb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/899k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1585dc1f347945309742b457f824e738"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/456k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d2e015ec3661471bade1d827b6dd8ef1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Pre. tgt. for `dev`:   0%|          | 0/326 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1a04ef7de487423db5ce6a422d36dbc0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Pre. tgt. for `test`:   0%|          | 0/816 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"53a4809ee7ea405cb3894e2388deada1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Pre. tgt. for `train`:   0%|          | 0/2934 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6c00442857134aa18cd24ee13ea97e87"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Save cache to caches/data_facebook/bart-base_pengb/16res_False.pt.\n","The number of tokens in tokenizer  50265\n"]}],"source":["data_bundle, tokenizer, mapping2id, mapping2targetid = get_data()\n","max_len = 10\n","max_len_a = {\n","    'penga/14lap': 0.9,\n","    'penga/14res': 1,\n","    'penga/15res': 1.2,\n","    'penga/16res': 0.9,\n","    'pengb/14lap': 1.1,\n","    'pengb/14res': 1.2,\n","    'pengb/15res': 0.9,\n","    'pengb/16res': 1.2\n","}[dataset_name]\n","\n","print(\"The number of tokens in tokenizer \", len(tokenizer.decoder))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kqv9619xJBEa"},"outputs":[],"source":["idtarget2map = {v: k for k, v in mapping2targetid.items()}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IBh3BFTWnkTX"},"outputs":[],"source":["bos_token_id = 0  #\n","eos_token_id = 1  #\n","label_ids = list(mapping2id.values())\n","vocab_size = len(tokenizer)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"C4oB7u5hbfj7","executionInfo":{"status":"ok","timestamp":1654621459949,"user_tz":-420,"elapsed":4409,"user":{"displayName":"Duy Hoang","userId":"17457647490907439684"}},"outputId":"a8568027-cdc4-46d8-fa04-f1d78d3f22e0"},"outputs":[{"output_type":"stream","name":"stdout","text":["50301 50306\n"]}],"source":["\n","model = BartSeq2SeqModel.build_model(bart_name, tokenizer, label_ids=label_ids, decoder_type=decoder_type,\n","                                     copy_gate=False, use_encoder_mlp=use_encoder_mlp, use_recur_pos=False)\n","print(vocab_size, model.decoder.decoder.embed_tokens.weight.data.size(0))\n","model = SequenceGeneratorModel(model, bos_token_id=bos_token_id,\n","                               eos_token_id=eos_token_id,\n","                               max_length=max_len, max_len_a=max_len_a,num_beams=num_beams, do_sample=False,\n","                               repetition_penalty=1, length_penalty=length_penalty, pad_token_id=eos_token_id,\n","                               restricter=None)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FJz0cJszWZP1"},"outputs":[],"source":["model=torch.load(\"/content/drive/MyDrive/Sentiment Analysis/data/Laptop-ACOS/model/best_SequenceGeneratorModel_quad_f_2022-04-19-09-02-39-319227\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7iC0zaq2bYVv"},"outputs":[],"source":["\n","import torch\n","if torch.cuda.is_available():\n","    # device = list([i for i in range(torch.cuda.device_count())])\n","    device = 'cuda'\n","else:\n","    device = 'cpu'\n","\n","parameters = []\n","params = {'lr':lr, 'weight_decay':1e-2}\n","params['params'] = [param for name, param in model.named_parameters() if not ('bart_encoder' in name or 'bart_decoder' in name)]\n","parameters.append(params)\n","\n","params = {'lr':lr, 'weight_decay':1e-2}\n","params['params'] = []\n","for name, param in model.named_parameters():\n","    if ('bart_encoder' in name or 'bart_decoder' in name) and not ('layernorm' in name or 'layer_norm' in name):\n","        params['params'].append(param)\n","parameters.append(params)\n","\n","params = {'lr':lr, 'weight_decay':0}\n","params['params'] = []\n","for name, param in model.named_parameters():\n","    if ('bart_encoder' in name or 'bart_decoder' in name) and ('layernorm' in name or 'layer_norm' in name):\n","        params['params'].append(param)\n","parameters.append(params)\n","\n","optimizer = optim.AdamW(parameters)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hEmyntdObt0i"},"outputs":[],"source":["\n","callbacks = []\n","callbacks.append(GradientClipCallback(clip_value=5, clip_type='value'))\n","callbacks.append(WarmupCallback(warmup=0.01, schedule='linear'))\n","callbacks.append(FitlogCallback(data_bundle.get_dataset('test')))\n","\n","sampler = None\n","# sampler = ConstTokenNumSampler('src_seq_len', max_token=1000)\n","sampler = BucketSampler(seq_len_field_name='src_seq_len')\n","metric = Seq2SeqSpanMetric(eos_token_id, num_labels=len(label_ids), opinion_first=opinion_first)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1858,"status":"ok","timestamp":1650358957326,"user":{"displayName":"Duy Hoang","userId":"17457647490907439684"},"user_tz":-420},"id":"TIlie3ekbzBK","outputId":"29449889-331e-4390-eb07-11dd2579ac6b"},"outputs":[{"name":"stdout","output_type":"stream","text":["input fields after batch(if batch size is 2):\n","\ttgt_tokens: (1)type:torch.Tensor (2)dtype:torch.int64, (3)shape:torch.Size([2, 9]) \n","\tsrc_tokens: (1)type:torch.Tensor (2)dtype:torch.int64, (3)shape:torch.Size([2, 23]) \n","\tsrc_seq_len: (1)type:torch.Tensor (2)dtype:torch.int64, (3)shape:torch.Size([2]) \n","\ttgt_seq_len: (1)type:torch.Tensor (2)dtype:torch.int64, (3)shape:torch.Size([2]) \n","target fields after batch(if batch size is 2):\n","\ttgt_tokens: (1)type:torch.Tensor (2)dtype:torch.int64, (3)shape:torch.Size([2, 9]) \n","\ttarget_span: (1)type:numpy.ndarray (2)dtype:int64, (3)shape:(2, 1, 7) \n","\ttgt_seq_len: (1)type:torch.Tensor (2)dtype:torch.int64, (3)shape:torch.Size([2]) \n","\n"]}],"source":["fitlog.set_log_dir('/content/caches')\n","\n","model_path = \"/content/drive/MyDrive/Sentiment Analysis/data/Laptop-ACOS/model\"\n","\n","\n","trainer = Trainer(train_data=data_bundle.get_dataset('train'), model=model, optimizer=optimizer,\n","                  loss=Seq2SeqLoss(),\n","                  batch_size=batch_size, sampler=sampler, drop_last=False, update_every=1,\n","                  num_workers=2, n_epochs=n_epochs, print_every=1,\n","                  dev_data=data_bundle.get_dataset('dev'), metrics=metric, metric_key='quad_f',\n","                  validate_every=-1, save_path=model_path, use_tqdm=True, device=device,\n","                  callbacks=callbacks, check_code_level=0, test_use_tqdm=False,\n","                  test_sampler=SortedSampler('src_seq_len'), dev_batch_size=batch_size)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["6ac0cb69e3a84184b4cfd221767cb2b4","4b4f78d1d132492097708bd98fa14137","5ca7e239f42749488dc11327b4e8af1d","56b4b05a9e80474b9ac6cba7dad901be","dd1419f1c82848a0b8c7129aea84517d","1fb2d79089dc4aafafb2f3600033d2e0","1ec44894be994573b66d98dd3a8e5cd0","2bfba6d48ada4103924cfbd817b1772a","73a5dcbd814c41ea9a2e798b8bbfdb21","1fcb503e49bd42fca11217d3fb73551c","efc16a5e5a224127ba1a7919d5c317e2"]},"executionInfo":{"elapsed":2613811,"status":"ok","timestamp":1650361573531,"user":{"displayName":"Duy Hoang","userId":"17457647490907439684"},"user_tz":-420},"id":"8M33ue43b09m","outputId":"e9551348-d8eb-437d-f51d-ce0a23dcb44b"},"outputs":[{"name":"stdout","output_type":"stream","text":["training epochs started 2022-04-19-09-02-39-319227\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6ac0cb69e3a84184b4cfd221767cb2b4","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/29350 [00:00<?, ?it/s, loss:{0:<6.5f}]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Evaluate data in 73.28 seconds!\n","Evaluate data in 156.26 seconds!\n","FitlogCallback evaluation on data-test:\n","Seq2SeqSpanMetric: quad_f=38.4, quad_rec=37.46, quad_pre=39.4, em=0.3076, invalid=0.0135\n","Evaluation on dev at Epoch 1/50. Step:587/29350: \n","Seq2SeqSpanMetric: quad_f=42.13, quad_rec=41.46, quad_pre=42.82, em=0.3896, invalid=0.0061\n","\n","Evaluate data in 78.59 seconds!\n","Evaluate data in 176.89 seconds!\n","FitlogCallback evaluation on data-test:\n","Seq2SeqSpanMetric: quad_f=37.95, quad_rec=37.11, quad_pre=38.82, em=0.3186, invalid=0.0159\n","Evaluation on dev at Epoch 2/50. Step:1174/29350: \n","Seq2SeqSpanMetric: quad_f=41.9, quad_rec=41.23, quad_pre=42.59, em=0.3804, invalid=0.0031\n","\n","Evaluate data in 85.05 seconds!\n","Evaluate data in 190.23 seconds!\n","FitlogCallback evaluation on data-test:\n","Seq2SeqSpanMetric: quad_f=37.86, quad_rec=37.37, quad_pre=38.37, em=0.3174, invalid=0.0208\n","Evaluation on dev at Epoch 3/50. Step:1761/29350: \n","Seq2SeqSpanMetric: quad_f=41.730000000000004, quad_rec=41.69, quad_pre=41.78, em=0.3804, invalid=0.0123\n","\n","Evaluate data in 71.37 seconds!\n","Evaluate data in 154.42 seconds!\n","FitlogCallback evaluation on data-test:\n","Seq2SeqSpanMetric: quad_f=35.480000000000004, quad_rec=34.339999999999996, quad_pre=36.69, em=0.2953, invalid=0.0147\n","Evaluation on dev at Epoch 4/50. Step:2348/29350: \n","Seq2SeqSpanMetric: quad_f=38.800000000000004, quad_rec=38.269999999999996, quad_pre=39.34, em=0.3712, invalid=0.0\n","\n","Evaluate data in 68.61 seconds!\n","Evaluate data in 149.17 seconds!\n","FitlogCallback evaluation on data-test:\n","Seq2SeqSpanMetric: quad_f=39.660000000000004, quad_rec=38.06, quad_pre=41.39, em=0.337, invalid=0.0098\n","Evaluation on dev at Epoch 5/50. Step:2935/29350: \n","Seq2SeqSpanMetric: quad_f=45.65, quad_rec=44.190000000000005, quad_pre=47.199999999999996, em=0.4202, invalid=0.0215\n","\n","Evaluate data in 75.75 seconds!\n","Evaluate data in 164.29 seconds!\n","FitlogCallback evaluation on data-test:\n","Seq2SeqSpanMetric: quad_f=37.72, quad_rec=36.33, quad_pre=39.22, em=0.3186, invalid=0.0184\n","Evaluation on dev at Epoch 6/50. Step:3522/29350: \n","Seq2SeqSpanMetric: quad_f=42.3, quad_rec=41.0, quad_pre=43.69, em=0.3865, invalid=0.0123\n","\n","Evaluate data in 69.06 seconds!\n","Evaluate data in 162.04 seconds!\n","FitlogCallback evaluation on data-test:\n","Seq2SeqSpanMetric: quad_f=36.97, quad_rec=36.94, quad_pre=37.0, em=0.2966, invalid=0.0172\n","Evaluation on dev at Epoch 7/50. Step:4109/29350: \n","Seq2SeqSpanMetric: quad_f=40.46, quad_rec=40.32, quad_pre=40.6, em=0.3712, invalid=0.0153\n","\n","\n","In Epoch:5/Step:2935, got best dev performance:\n","Seq2SeqSpanMetric: quad_f=45.65, quad_rec=44.190000000000005, quad_pre=47.199999999999996, em=0.4202, invalid=0.0215\n"]},{"data":{"text/plain":["{'best_epoch': 5,\n"," 'best_eval': {'Seq2SeqSpanMetric': {'em': 0.4202,\n","   'invalid': 0.0215,\n","   'quad_f': 45.65,\n","   'quad_pre': 47.199999999999996,\n","   'quad_rec': 44.190000000000005}},\n"," 'best_step': 2935,\n"," 'seconds': 2613.89}"]},"execution_count":27,"metadata":{},"output_type":"execute_result"}],"source":["trainer.train(load_best_model=False)\n"]},{"cell_type":"markdown","metadata":{"id":"apnS0DwNQA58"},"source":["#Testing"]},{"cell_type":"code","source":["model.to(\"cuda\")"],"metadata":{"id":"Qkh9ez0c3vB3"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":69,"referenced_widgets":["85873f08bfea4900ba4fcba519f182b5","ff16507299e84d8298c6060afbe56b3d","d8e7882f57dd41f7beb6e17a44741d7b","1660b201b9d94ca2b11c5bb23ba79466","dc98ba02df374ad1b7a0cb45db6c5b86","5e4c3d1864514bb697be62524962cc6a","3607437e511843b5aecff7b8697ee530","37c820ff2556469796f2f47dce677537","62b39d95f4924e67805d82407c029134","e25b8f5ce6944de9a38d44a10001b811","72982d228826466bbb979f8ff40afc11"]},"executionInfo":{"elapsed":206456,"status":"ok","timestamp":1652978510276,"user":{"displayName":"Duy Hoang","userId":"17457647490907439684"},"user_tz":-420},"id":"GNg64gFoOl8c","outputId":"a6d0c0e8-3668-49a2-fc4a-18b651b00196"},"outputs":[{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/164 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"85873f08bfea4900ba4fcba519f182b5"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Evaluate data in 206.34 seconds!\n","[tester] \n","Seq2SeqSpanMetric: quad_f=39.660000000000004, quad_rec=38.06, quad_pre=41.39, em=0.337, invalid=0.0098\n"]}],"source":["tester = Tester(data_bundle.get_dataset('test'), model, metrics=metric,batch_size=batch_size)\n","eval_results = tester.test()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":561,"status":"ok","timestamp":1650365201789,"user":{"displayName":"Duy Hoang","userId":"17457647490907439684"},"user_tz":-420},"id":"1iiNWGhMQqY_","outputId":"84e7b9ec-9d8b-4715-e6cf-7cfbbfd4aae7"},"outputs":[{"name":"stdout","output_type":"stream","text":["816\n","326\n","2934\n"]}],"source":["print(len(data_bundle.get_dataset('test')))\n","print(len(data_bundle.get_dataset('dev')))\n","print(len(data_bundle.get_dataset('train')))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"u0m8qQTv0FWw"},"outputs":[],"source":["pipe = BartBPEABSAPipe(tokenizer=bart_name, opinion_first=opinion_first)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17,"referenced_widgets":["c20a73fba3b24a43be44f2850fab7649","6457a12f852c44b08f3036602c63f16a","4136225689e5409884824fc429f5e7f3","9fb40918075e4e348a58d7085a6a63a8","6b36e5eca83c4a2690db9e6b6f2957de","0717b9587d6147ff92c5ca6f8c76b587","ff6ef87977f14bf2b304e4aee56cf23b","744b54834b054ee59f87efa48fb41125","78db39eb97f74af5975905b9d1eb73ae","76966a47b81b4ed5a3776813ab08245b","dfd20a5297a3459187b6ac3a748d213a","41f4e6d4b55d4f90b0e66789020d5d7d","5bcb4ae6fb214f0fa10caca0fa511e62","b597d114bbfe46e3afac52e69f7c882c","d4b88231b8e44643a59cf46d02d183a7","4a3bd9546645452ca31b0c123919ed1c","209cd6349b91451290ad043ec3cb0569","98930f6252d940459f34ff8d24f4e292","1d6a7f3c2bd842c0a4a19a55342a519b","96edc6f0003741d39fa4a2e0caeb0526","3e8d2faa05754e929dc6cb255e53e16e","44f4b531a0f044d1aa15a97c5b202a8d"]},"executionInfo":{"elapsed":2737,"status":"ok","timestamp":1651161752800,"user":{"displayName":"Cao Duy Hoang","userId":"17498028471290040726"},"user_tz":-420},"id":"iLgsk_kg1SdQ","outputId":"8c80938c-e74d-4846-ee1c-5c1ccb8753b7"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Pre. tgt. for `test`:   0%|          | 0/64 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c20a73fba3b24a43be44f2850fab7649"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Pre. tgt. for `train`:   0%|          | 0/467 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"41f4e6d4b55d4f90b0e66789020d5d7d"}},"metadata":{}}],"source":["test_bundle = pipe.process_from_file(\"/content/drive/MyDrive/Sentiment Analysis/data/Laptop-ACOS/json/Implicit Explicit\")"]},{"cell_type":"markdown","metadata":{"id":"htqgAHuC50-3"},"source":["##IAIO"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":69,"referenced_widgets":["ba5b6487ccc24e59b84f97e48265f8e9","8af9caf917a441549b296fe08f4f0cff","a379af210f3443bc8bf16d9c6b9c441f","4fb8ff5a7fd047c581cb979b19c8bde2","e5c3650bc35d43f6a5ae442aada70996","ecb179a2fbf548759c1cb675f99654f6","1473c3dc47104a2e9c1d60a225ded991","4a952c78440445ddb3a045287b8d94d5","e05f09c5fd4549d099ed8c873da407b4","af5e3130f0024bfd93bf9dc105fc61a5","5ada919ba49f4affac3a46037800edb9"]},"executionInfo":{"elapsed":16108,"status":"ok","timestamp":1651161604943,"user":{"displayName":"Cao Duy Hoang","userId":"17498028471290040726"},"user_tz":-420},"id":"zvpcgAO-12Is","outputId":"fda66896-b4eb-4818-e42f-0c2ac96df16c"},"outputs":[{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/13 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ba5b6487ccc24e59b84f97e48265f8e9"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Evaluate data in 16.18 seconds!\n","[tester] \n","Seq2SeqSpanMetric: quad_f=29.79, quad_rec=31.819999999999997, quad_pre=28.000000000000004, em=0.2969, invalid=0.0\n"]}],"source":["tester = Tester(test_bundle.get_dataset('test'), model, metrics=metric,batch_size=batch_size)\n","eval_results = tester.test()"]},{"cell_type":"markdown","metadata":{"id":"wUIufUfy53L4"},"source":["##EAEO"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":69,"referenced_widgets":["7f00d63532aa47a2bbfd3175eb6289c3","d83758beab174ae6b242dfab4f5d4e58","d18a0849c9834eee8931fc8ab566bb0a","1e9c6ea2d3d246b4b4f343d18f241671","5d04210ff8bb4a3088e624059b5fa43c","1e6fc2321fa7453598f2816a27976d5b","1fe4a50c9b02422d945ffa0095414cec","6a5d01d81680469b91057465c7921a67","0ef6d1941d9944ef9270e438c4f48ac6","2c79d553517941dcb4b54ca31c558ea2","cb6dfa452eeb4551a117bf9bf3a16a57"]},"executionInfo":{"elapsed":115117,"status":"ok","timestamp":1651161720020,"user":{"displayName":"Cao Duy Hoang","userId":"17498028471290040726"},"user_tz":-420},"id":"fvBlQYuH19rw","outputId":"f810ec1b-eef8-4481-9bbe-601ffac3881f"},"outputs":[{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/94 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7f00d63532aa47a2bbfd3175eb6289c3"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Evaluate data in 114.85 seconds!\n","[tester] \n","Seq2SeqSpanMetric: quad_f=39.85, quad_rec=39.85, quad_pre=39.85, em=0.3276, invalid=0.0086\n"]}],"source":["tester = Tester(test_bundle.get_dataset('train'), model, metrics=metric,batch_size=batch_size)\n","eval_results = tester.test()"]},{"cell_type":"markdown","metadata":{"id":"8R292Wnd55pz"},"source":["##EAIO"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":321},"executionInfo":{"elapsed":13,"status":"error","timestamp":1651161752801,"user":{"displayName":"Cao Duy Hoang","userId":"17498028471290040726"},"user_tz":-420},"id":"-AlquKtq1-NR","outputId":"105ca497-d7d6-465a-c6e7-cc4c150340fc"},"outputs":[{"output_type":"stream","name":"stdout","text":["DataBundle do NOT have DataSet named dev. It should be one of dict_keys(['test', 'train']).\n"]},{"output_type":"error","ename":"KeyError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m<ipython-input-35-e124636ac606>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtester\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTester\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_bundle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'dev'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0meval_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtester\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/fastNLP/io/data_bundle.py\u001b[0m in \u001b[0;36mget_dataset\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m     74\u001b[0m                         \u001b[0;34mf'It should be one of {self.datasets.keys()}.'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdelete_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: \"DataBundle do NOT have DataSet named dev. It should be one of dict_keys(['test', 'train']).\""]}],"source":["tester = Tester(test_bundle.get_dataset('dev'), model, metrics=metric,batch_size=batch_size)\n","eval_results = tester.test()"]},{"cell_type":"markdown","metadata":{"id":"YVsH5aS86GrU"},"source":["##IAEO"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":89,"referenced_widgets":["1d7a21ece00640a7a217f121b61af8d0","67e1c05200524ce0be5d0269ebc41de8","65d19bd7586c4169896f1482400f4351","11569ca5ca8c4e7d989151571b182faa","42625e8e3bf0424e9bba5e906740d5fd","619ef086d9b245c5bf476af4fa1068d2","41787032210a4beeb7c7ed3e03190c63","a555f9ce52204e1eba737cccda0c0216","b26e52a7360e447fa3a9b302fd74ae56","6e0ac7d933ac43b7995e804421c71409","2aac18cf00b84dccbe61354ac8aafca6"]},"executionInfo":{"elapsed":28614,"status":"ok","timestamp":1651161748608,"user":{"displayName":"Cao Duy Hoang","userId":"17498028471290040726"},"user_tz":-420},"id":"bnZl-7Vp6F1I","outputId":"559ad3e4-e165-43bf-9ce2-81f74124c018"},"outputs":[{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/26 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1d7a21ece00640a7a217f121b61af8d0"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Evaluate data in 27.74 seconds!\n","[tester] \n","Seq2SeqSpanMetric: quad_f=52.790000000000006, quad_rec=53.56999999999999, quad_pre=52.019999999999996, em=0.4453, invalid=0.0078\n"]}],"source":["tester = Tester(test_bundle.get_dataset('dev'), model, metrics=metric,batch_size=batch_size)\n","eval_results = tester.test()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1063,"status":"ok","timestamp":1650368782402,"user":{"displayName":"Duy Hoang","userId":"17457647490907439684"},"user_tz":-420},"id":"aFqm4tqYogvO","outputId":"bc9b8a07-1de3-46bf-fb9e-20908338aa9e"},"outputs":[{"data":{"text/plain":["+---------------+---------------+---------------+----------------+-----------------+----------------+-------------+-------------+\n","| raw_words     | aspects       | opinions      | tgt_tokens     | target_span     | src_tokens     | src_seq_len | tgt_seq_len |\n","+---------------+---------------+---------------+----------------+-----------------+----------------+-------------+-------------+\n","| ['<<null>>... | [{'index':... | [{'index':... | [0, 38, 38,... | [(38, 38, 15... | [0, 50265, ... | 23          | 16          |\n","| ['<<null>>... | [{'index':... | [{'index':... | [0, 38, 38,... | [(38, 38, 22... | [0, 50265, ... | 12          | 16          |\n","| ['<<null>>... | [{'index':... | [{'index':... | [0, 38, 38,... | [(38, 38, 15... | [0, 50265, ... | 9           | 9           |\n","| ['<<null>>... | [{'index':... | [{'index':... | [0, 38, 38,... | [(38, 38, 15... | [0, 50265, ... | 26          | 9           |\n","| ['<<null>>... | [{'index':... | [{'index':... | [0, 38, 38,... | [(38, 38, 15... | [0, 50265, ... | 19          | 9           |\n","| ['<<null>>... | [{'index':... | [{'index':... | [0, 38, 38,... | [(38, 38, 15... | [0, 50265, ... | 14          | 9           |\n","| ['<<null>>... | [{'index':... | [{'index':... | [0, 38, 38,... | [(38, 38, 15... | [0, 50265, ... | 10          | 9           |\n","| ['<<null>>... | [{'index':... | [{'index':... | [0, 38, 38,... | [(38, 38, 15... | [0, 50265, ... | 19          | 9           |\n","| ['<<null>>... | [{'index':... | [{'index':... | [0, 38, 38,... | [(38, 38, 15... | [0, 50265, ... | 11          | 16          |\n","| ['<<null>>... | [{'index':... | [{'index':... | [0, 38, 38,... | [(38, 38, 15... | [0, 50265, ... | 17          | 9           |\n","| ['<<null>>... | [{'index':... | [{'index':... | [0, 38, 38,... | [(38, 38, 15... | [0, 50265, ... | 5           | 9           |\n","| ['<<null>>... | [{'index':... | [{'index':... | [0, 38, 38,... | [(38, 38, 15... | [0, 50265, ... | 18          | 9           |\n","| ...           | ...           | ...           | ...            | ...             | ...            | ...         | ...         |\n","+---------------+---------------+---------------+----------------+-----------------+----------------+-------------+-------------+"]},"execution_count":48,"metadata":{},"output_type":"execute_result"}],"source":["tester_dev = test_bundle.get_dataset('dev')\n","tester_dev"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"x1JsqrN0ooL5"},"outputs":[],"source":["tester_dev[0][\"aspects\"]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5qDjqGVooSWb"},"outputs":[],"source":["amount = 0\n","for i in range(0,len(tester_dev)):\n","    amount+=len(tester_dev[i][\"opinions\"])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1650368663399,"user":{"displayName":"Duy Hoang","userId":"17457647490907439684"},"user_tz":-420},"id":"HgX4mUyhow_d","outputId":"18a1ab12-fe6b-40f3-876f-5a9fc0c0f7a8"},"outputs":[{"data":{"text/plain":["169"]},"execution_count":47,"metadata":{},"output_type":"execute_result"}],"source":["amount"]},{"cell_type":"markdown","metadata":{"id":"w132u__HLK5E"},"source":["#Test use"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"m61ToHByLKP0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1654621461934,"user_tz":-420,"elapsed":616,"user":{"displayName":"Duy Hoang","userId":"17457647490907439684"}},"outputId":"7dd48a4e-a84e-4e1d-dbe6-01db58ab606d"},"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([1, 1, 768])\n","torch.Size([1, 9, 768])\n","torch.Size([1, 1, 9])\n","##########################\n","torch.Size([4, 2, 768])\n","torch.Size([4, 9, 768])\n","torch.Size([4, 2, 9])\n","##########################\n","torch.Size([4, 3, 768])\n","torch.Size([4, 9, 768])\n","torch.Size([4, 3, 9])\n","##########################\n","torch.Size([4, 4, 768])\n","torch.Size([4, 9, 768])\n","torch.Size([4, 4, 9])\n","##########################\n","torch.Size([4, 5, 768])\n","torch.Size([4, 9, 768])\n","torch.Size([4, 5, 9])\n","##########################\n","torch.Size([4, 6, 768])\n","torch.Size([4, 9, 768])\n","torch.Size([4, 6, 9])\n","##########################\n","torch.Size([4, 7, 768])\n","torch.Size([4, 9, 768])\n","torch.Size([4, 7, 9])\n","##########################\n","torch.Size([4, 8, 768])\n","torch.Size([4, 9, 768])\n","torch.Size([4, 8, 9])\n","##########################\n","torch.Size([4, 9, 768])\n","torch.Size([4, 9, 768])\n","torch.Size([4, 9, 9])\n","##########################\n","torch.Size([4, 10, 768])\n","torch.Size([4, 9, 768])\n","torch.Size([4, 10, 9])\n","##########################\n"]}],"source":["import numpy as np\n","def tokenize_sentence(sentences,tokenizer,device = \"cpu\"):\n","    output_mold = []\n","    len_lst = []\n","    for i in range (0,len(sentences)):\n","        added_sentence = \"<<null>> \"+sentences[i]\n","        raw_words = added_sentence.split(\" \")\n","        word_bpes = [[tokenizer.bos_token_id]]\n","        for word in raw_words:\n","            bpes = tokenizer.tokenize(word, add_prefix_space=True)\n","            bpes = tokenizer.convert_tokens_to_ids(bpes)\n","            word_bpes.append(bpes)\n","        word_bpes.append([tokenizer.eos_token_id])\n","        output = list(chain(*word_bpes))\n","        output_mold.append(output)\n","    max_len = max(len(x) for x in output_mold)\n","    mold_np = np.ones([len(sentences),max_len])\n","    for i in range (0,len(sentences)):\n","        raw_words = output_mold[i]\n","        len_lst.append(len(raw_words))\n","        mold_np[i,:len_lst[-1]]=raw_words\n","    seg_token = torch.LongTensor(mold_np).to(device)\n","    seg_token_len = torch.LongTensor(len_lst).to(device)\n","    return seg_token , seg_token_len\n","\n","sentences = [\"asus laptop is not good\"]\n","seg_token, seg_token_len = tokenize_sentence(sentences,tokenizer,\"cuda\")\n","model.train(mode=False)\n","model.to(\"cuda\")   \n","res = model.predict(seg_token, seg_token_len)[\"pred\"]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6-heP7xgNSQ_"},"outputs":[],"source":["def translateResult(sentences,results,idtarget2map,tokenizer):\n","    converted_sentences=[]\n","    for i in sentences:\n","        lst = []\n","        for word in i.split(\" \"):\n","            bpes = tokenizer.tokenize(word, add_prefix_space=True)\n","            lst.extend(bpes)\n","        converted_sentences.append(\" \".join(lst))\n","    output_mold = []\n","    len_lst = []\n","    cap = len(idtarget2map)+2\n","    def translateResultChunk(block,sentence):\n","        output = []\n","        prev = None\n","        lst = sentence.split(\" \")\n","        for i in block:\n","            if i<cap:\n","                output.append(idtarget2map[i-2])\n","                continue\n","            if prev is not None:\n","                chunk = lst[prev:i-cap]\n","                text = \"\"\n","                for i in chunk:\n","                    if i[0]==\"Ġ\":\n","                        text =text +\" \"+i[1:]\n","                    else:\n","                        text =text +i\n","                output.append(text.strip())\n","                prev = None\n","            else:\n","                prev = i-cap-1\n","        return output\n","    for i in range(0,len(converted_sentences)):\n","        blocks=[]\n","        count=0\n","        cur_pair = []\n","        for o in results[i]:\n","            k = int(o)\n","            if k==0 or k==1:\n","                continue\n","            \n","            if k<cap:\n","                cur_pair.append(k)\n","\n","                if count<2:\n","                    count+=1\n","                else:\n","                    if not(len(cur_pair) != 7 or cur_pair[0] > cur_pair[1] or cur_pair[4] > cur_pair[5]):\n","                        blocks.append(translateResultChunk(cur_pair,\"NULL \"+converted_sentences[i]).copy())\n","                    cur_pair = []\n","                    count=0\n","            else:\n","                cur_pair.append(k)\n","        output_mold.append(blocks.copy())\n","    return output_mold"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":347,"status":"ok","timestamp":1654524372022,"user":{"displayName":"Duy Hoang","userId":"17457647490907439684"},"user_tz":-420},"id":"UbHuOz8kUMwK","outputId":"6ec9e02d-9ee6-4e88-a432-3565bf460e48"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["[[['NULL', 'LAPTOP', 'GENERAL', 'broken', 'NEG']]]"]},"metadata":{},"execution_count":29}],"source":["translateResult(sentences,res,idtarget2map,tokenizer)"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["im-ufjT0g6_L","MQwocvOY5EEi","BWeNjY13jF5C","dCtAWimziVXR","PE8Y8i_gt9rg","Zd3VqYYYuLc3","apnS0DwNQA58"],"name":"Transformer_sentiment.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"1ec44894be994573b66d98dd3a8e5cd0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1fb2d79089dc4aafafb2f3600033d2e0":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1fcb503e49bd42fca11217d3fb73551c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2bfba6d48ada4103924cfbd817b1772a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4b4f78d1d132492097708bd98fa14137":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1fb2d79089dc4aafafb2f3600033d2e0","placeholder":"​","style":"IPY_MODEL_1ec44894be994573b66d98dd3a8e5cd0","value":"Epoch 8/50:  16%"}},"56b4b05a9e80474b9ac6cba7dad901be":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1fcb503e49bd42fca11217d3fb73551c","placeholder":"​","style":"IPY_MODEL_efc16a5e5a224127ba1a7919d5c317e2","value":" 4696/29350 [43:33&lt;1:18:14,  5.25it/s, loss:0.06400]"}},"5ca7e239f42749488dc11327b4e8af1d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"danger","description":"","description_tooltip":null,"layout":"IPY_MODEL_2bfba6d48ada4103924cfbd817b1772a","max":29350,"min":0,"orientation":"horizontal","style":"IPY_MODEL_73a5dcbd814c41ea9a2e798b8bbfdb21","value":4696}},"6ac0cb69e3a84184b4cfd221767cb2b4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4b4f78d1d132492097708bd98fa14137","IPY_MODEL_5ca7e239f42749488dc11327b4e8af1d","IPY_MODEL_56b4b05a9e80474b9ac6cba7dad901be"],"layout":"IPY_MODEL_dd1419f1c82848a0b8c7129aea84517d"}},"73a5dcbd814c41ea9a2e798b8bbfdb21":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"dd1419f1c82848a0b8c7129aea84517d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"100%"}},"efc16a5e5a224127ba1a7919d5c317e2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c20a73fba3b24a43be44f2850fab7649":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6457a12f852c44b08f3036602c63f16a","IPY_MODEL_4136225689e5409884824fc429f5e7f3","IPY_MODEL_9fb40918075e4e348a58d7085a6a63a8"],"layout":"IPY_MODEL_6b36e5eca83c4a2690db9e6b6f2957de"}},"6457a12f852c44b08f3036602c63f16a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0717b9587d6147ff92c5ca6f8c76b587","placeholder":"​","style":"IPY_MODEL_ff6ef87977f14bf2b304e4aee56cf23b","value":"Pre. tgt. for `test`: 100%"}},"4136225689e5409884824fc429f5e7f3":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_744b54834b054ee59f87efa48fb41125","max":64,"min":0,"orientation":"horizontal","style":"IPY_MODEL_78db39eb97f74af5975905b9d1eb73ae","value":64}},"9fb40918075e4e348a58d7085a6a63a8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_76966a47b81b4ed5a3776813ab08245b","placeholder":"​","style":"IPY_MODEL_dfd20a5297a3459187b6ac3a748d213a","value":" 64/64 [00:00&lt;00:00, 238.01it/s]"}},"6b36e5eca83c4a2690db9e6b6f2957de":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"100%"}},"0717b9587d6147ff92c5ca6f8c76b587":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ff6ef87977f14bf2b304e4aee56cf23b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"744b54834b054ee59f87efa48fb41125":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"78db39eb97f74af5975905b9d1eb73ae":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"76966a47b81b4ed5a3776813ab08245b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dfd20a5297a3459187b6ac3a748d213a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"41f4e6d4b55d4f90b0e66789020d5d7d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5bcb4ae6fb214f0fa10caca0fa511e62","IPY_MODEL_b597d114bbfe46e3afac52e69f7c882c","IPY_MODEL_d4b88231b8e44643a59cf46d02d183a7"],"layout":"IPY_MODEL_4a3bd9546645452ca31b0c123919ed1c"}},"5bcb4ae6fb214f0fa10caca0fa511e62":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_209cd6349b91451290ad043ec3cb0569","placeholder":"​","style":"IPY_MODEL_98930f6252d940459f34ff8d24f4e292","value":"Pre. tgt. for `train`:  97%"}},"b597d114bbfe46e3afac52e69f7c882c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_1d6a7f3c2bd842c0a4a19a55342a519b","max":467,"min":0,"orientation":"horizontal","style":"IPY_MODEL_96edc6f0003741d39fa4a2e0caeb0526","value":467}},"d4b88231b8e44643a59cf46d02d183a7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3e8d2faa05754e929dc6cb255e53e16e","placeholder":"​","style":"IPY_MODEL_44f4b531a0f044d1aa15a97c5b202a8d","value":" 455/467 [00:02&lt;00:00, 210.13it/s]"}},"4a3bd9546645452ca31b0c123919ed1c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"100%"}},"209cd6349b91451290ad043ec3cb0569":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"98930f6252d940459f34ff8d24f4e292":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1d6a7f3c2bd842c0a4a19a55342a519b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"96edc6f0003741d39fa4a2e0caeb0526":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3e8d2faa05754e929dc6cb255e53e16e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"44f4b531a0f044d1aa15a97c5b202a8d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ba5b6487ccc24e59b84f97e48265f8e9":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8af9caf917a441549b296fe08f4f0cff","IPY_MODEL_a379af210f3443bc8bf16d9c6b9c441f","IPY_MODEL_4fb8ff5a7fd047c581cb979b19c8bde2"],"layout":"IPY_MODEL_e5c3650bc35d43f6a5ae442aada70996"}},"8af9caf917a441549b296fe08f4f0cff":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ecb179a2fbf548759c1cb675f99654f6","placeholder":"​","style":"IPY_MODEL_1473c3dc47104a2e9c1d60a225ded991","value":"Test: 100%"}},"a379af210f3443bc8bf16d9c6b9c441f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_4a952c78440445ddb3a045287b8d94d5","max":13,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e05f09c5fd4549d099ed8c873da407b4","value":13}},"4fb8ff5a7fd047c581cb979b19c8bde2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_af5e3130f0024bfd93bf9dc105fc61a5","placeholder":"​","style":"IPY_MODEL_5ada919ba49f4affac3a46037800edb9","value":" 13/13 [00:16&lt;00:00,  1.07it/s]"}},"e5c3650bc35d43f6a5ae442aada70996":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"100%"}},"ecb179a2fbf548759c1cb675f99654f6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1473c3dc47104a2e9c1d60a225ded991":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4a952c78440445ddb3a045287b8d94d5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e05f09c5fd4549d099ed8c873da407b4":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"af5e3130f0024bfd93bf9dc105fc61a5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5ada919ba49f4affac3a46037800edb9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7f00d63532aa47a2bbfd3175eb6289c3":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d83758beab174ae6b242dfab4f5d4e58","IPY_MODEL_d18a0849c9834eee8931fc8ab566bb0a","IPY_MODEL_1e9c6ea2d3d246b4b4f343d18f241671"],"layout":"IPY_MODEL_5d04210ff8bb4a3088e624059b5fa43c"}},"d83758beab174ae6b242dfab4f5d4e58":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1e6fc2321fa7453598f2816a27976d5b","placeholder":"​","style":"IPY_MODEL_1fe4a50c9b02422d945ffa0095414cec","value":"Test: 100%"}},"d18a0849c9834eee8931fc8ab566bb0a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_6a5d01d81680469b91057465c7921a67","max":94,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0ef6d1941d9944ef9270e438c4f48ac6","value":94}},"1e9c6ea2d3d246b4b4f343d18f241671":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2c79d553517941dcb4b54ca31c558ea2","placeholder":"​","style":"IPY_MODEL_cb6dfa452eeb4551a117bf9bf3a16a57","value":" 94/94 [01:54&lt;00:00,  1.03it/s]"}},"5d04210ff8bb4a3088e624059b5fa43c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"100%"}},"1e6fc2321fa7453598f2816a27976d5b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1fe4a50c9b02422d945ffa0095414cec":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6a5d01d81680469b91057465c7921a67":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0ef6d1941d9944ef9270e438c4f48ac6":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2c79d553517941dcb4b54ca31c558ea2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cb6dfa452eeb4551a117bf9bf3a16a57":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1d7a21ece00640a7a217f121b61af8d0":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_67e1c05200524ce0be5d0269ebc41de8","IPY_MODEL_65d19bd7586c4169896f1482400f4351","IPY_MODEL_11569ca5ca8c4e7d989151571b182faa"],"layout":"IPY_MODEL_42625e8e3bf0424e9bba5e906740d5fd"}},"67e1c05200524ce0be5d0269ebc41de8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_619ef086d9b245c5bf476af4fa1068d2","placeholder":"​","style":"IPY_MODEL_41787032210a4beeb7c7ed3e03190c63","value":"Test: 100%"}},"65d19bd7586c4169896f1482400f4351":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_a555f9ce52204e1eba737cccda0c0216","max":26,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b26e52a7360e447fa3a9b302fd74ae56","value":26}},"11569ca5ca8c4e7d989151571b182faa":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6e0ac7d933ac43b7995e804421c71409","placeholder":"​","style":"IPY_MODEL_2aac18cf00b84dccbe61354ac8aafca6","value":" 26/26 [00:27&lt;00:00,  1.03it/s]"}},"42625e8e3bf0424e9bba5e906740d5fd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"100%"}},"619ef086d9b245c5bf476af4fa1068d2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"41787032210a4beeb7c7ed3e03190c63":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a555f9ce52204e1eba737cccda0c0216":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b26e52a7360e447fa3a9b302fd74ae56":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6e0ac7d933ac43b7995e804421c71409":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2aac18cf00b84dccbe61354ac8aafca6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"85873f08bfea4900ba4fcba519f182b5":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ff16507299e84d8298c6060afbe56b3d","IPY_MODEL_d8e7882f57dd41f7beb6e17a44741d7b","IPY_MODEL_1660b201b9d94ca2b11c5bb23ba79466"],"layout":"IPY_MODEL_dc98ba02df374ad1b7a0cb45db6c5b86"}},"ff16507299e84d8298c6060afbe56b3d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5e4c3d1864514bb697be62524962cc6a","placeholder":"​","style":"IPY_MODEL_3607437e511843b5aecff7b8697ee530","value":"Test: 100%"}},"d8e7882f57dd41f7beb6e17a44741d7b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_37c820ff2556469796f2f47dce677537","max":164,"min":0,"orientation":"horizontal","style":"IPY_MODEL_62b39d95f4924e67805d82407c029134","value":164}},"1660b201b9d94ca2b11c5bb23ba79466":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e25b8f5ce6944de9a38d44a10001b811","placeholder":"​","style":"IPY_MODEL_72982d228826466bbb979f8ff40afc11","value":" 164/164 [03:26&lt;00:00,  1.02s/it]"}},"dc98ba02df374ad1b7a0cb45db6c5b86":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"100%"}},"5e4c3d1864514bb697be62524962cc6a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3607437e511843b5aecff7b8697ee530":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"37c820ff2556469796f2f47dce677537":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"62b39d95f4924e67805d82407c029134":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e25b8f5ce6944de9a38d44a10001b811":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"72982d228826466bbb979f8ff40afc11":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"77e9b179893f4ab3ba51a6391b1fc8bb":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b6d7f3ec2d59448dac6ccc071e9ab4bc","IPY_MODEL_b78c687c808b4b75bbd4e21d090ec025","IPY_MODEL_a57323016e534561a35f8ea64f508337"],"layout":"IPY_MODEL_861c7f22be0a4eecb1b26b9865ce6a21"}},"b6d7f3ec2d59448dac6ccc071e9ab4bc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1fa7e4a72f484185ad2707f96af677c5","placeholder":"​","style":"IPY_MODEL_5833af8070994e5aa22ae242d67e2f51","value":"Downloading: 100%"}},"b78c687c808b4b75bbd4e21d090ec025":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e8d65133832b4cde8508b1bcc19289b2","max":1553,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1a180cfba5384384ba92bc15b45ad5cd","value":1553}},"a57323016e534561a35f8ea64f508337":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_885f8baf1ed749829d80c9588950baa0","placeholder":"​","style":"IPY_MODEL_93e56765d22b4b88afae06d77f128703","value":" 1.55k/1.55k [00:00&lt;00:00, 19.5kB/s]"}},"861c7f22be0a4eecb1b26b9865ce6a21":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1fa7e4a72f484185ad2707f96af677c5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5833af8070994e5aa22ae242d67e2f51":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e8d65133832b4cde8508b1bcc19289b2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1a180cfba5384384ba92bc15b45ad5cd":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"885f8baf1ed749829d80c9588950baa0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"93e56765d22b4b88afae06d77f128703":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1585dc1f347945309742b457f824e738":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_13d9e8c85c6a496aaf09b7254195c216","IPY_MODEL_75c589213bc44c769ab05d6e65d172af","IPY_MODEL_2d4124f8b6c84862b6af77061bd6a895"],"layout":"IPY_MODEL_20ddf36655f64059b9ab5a30ed02e01d"}},"13d9e8c85c6a496aaf09b7254195c216":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_274245a3820548ab9e7b135389c8a8ee","placeholder":"​","style":"IPY_MODEL_993a4c9aa53e40e39d2abb7f77ed133e","value":"Downloading: 100%"}},"75c589213bc44c769ab05d6e65d172af":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_86adb814b36a4e8ea508d7019311b780","max":898823,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8e85d5e683334d9c86ecb1c126934a38","value":898823}},"2d4124f8b6c84862b6af77061bd6a895":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2eacaeaed42c4c2ca6df7b8d0b31c94f","placeholder":"​","style":"IPY_MODEL_0317021790d640e2b206bebe1c242ab9","value":" 899k/899k [00:00&lt;00:00, 9.98kB/s]"}},"20ddf36655f64059b9ab5a30ed02e01d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"274245a3820548ab9e7b135389c8a8ee":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"993a4c9aa53e40e39d2abb7f77ed133e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"86adb814b36a4e8ea508d7019311b780":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8e85d5e683334d9c86ecb1c126934a38":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2eacaeaed42c4c2ca6df7b8d0b31c94f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0317021790d640e2b206bebe1c242ab9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d2e015ec3661471bade1d827b6dd8ef1":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e1aef09207784f6da9619acf9776f202","IPY_MODEL_76ded5525c6c46c396052fc204a399c7","IPY_MODEL_aea9a7d58aa441d19fe5b36830dfed25"],"layout":"IPY_MODEL_f9d080f43a0449768cbf39ce6149dfe5"}},"e1aef09207784f6da9619acf9776f202":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b862e02145fb4ad0a937e6083d8966d2","placeholder":"​","style":"IPY_MODEL_a1bbcbddf93744978b98afc8d4c136a8","value":"Downloading: 100%"}},"76ded5525c6c46c396052fc204a399c7":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f052ea01c6b445e7a1e0a2374e7bd6a2","max":456318,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7c7423113958457c956ecad224249510","value":456318}},"aea9a7d58aa441d19fe5b36830dfed25":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8eb8f86261c84fb88bc08977ef7ad1cd","placeholder":"​","style":"IPY_MODEL_14e1df0ea1a04945a90b90bee7905a36","value":" 456k/456k [00:00&lt;00:00, 1.80MB/s]"}},"f9d080f43a0449768cbf39ce6149dfe5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b862e02145fb4ad0a937e6083d8966d2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a1bbcbddf93744978b98afc8d4c136a8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f052ea01c6b445e7a1e0a2374e7bd6a2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7c7423113958457c956ecad224249510":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8eb8f86261c84fb88bc08977ef7ad1cd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"14e1df0ea1a04945a90b90bee7905a36":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1a04ef7de487423db5ce6a422d36dbc0":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c0d8bd50549f472f80041302bd8e3c71","IPY_MODEL_bd712b628a304a90b7bfdf80944c0316","IPY_MODEL_ecc7ad2c6af94048a0dcdc7f153ce064"],"layout":"IPY_MODEL_abd0839d1c734ae8b690b13b71f53bd6"}},"c0d8bd50549f472f80041302bd8e3c71":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_072878d5e0314433aa64084aeb341f1d","placeholder":"​","style":"IPY_MODEL_0f2006f0315f4f24ad22353045857c80","value":"Pre. tgt. for `dev`:  99%"}},"bd712b628a304a90b7bfdf80944c0316":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_82f71acba4d44024934edf3dc97b474f","max":326,"min":0,"orientation":"horizontal","style":"IPY_MODEL_bae6b83b098d40ef890cc1b19cbee79a","value":326}},"ecc7ad2c6af94048a0dcdc7f153ce064":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4fdec4654a5640f8bcd7e66913b4bdaf","placeholder":"​","style":"IPY_MODEL_1af8e3c02f844762908e3bdbc1b3df20","value":" 324/326 [00:03&lt;00:00, 106.33it/s]"}},"abd0839d1c734ae8b690b13b71f53bd6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"100%"}},"072878d5e0314433aa64084aeb341f1d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0f2006f0315f4f24ad22353045857c80":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"82f71acba4d44024934edf3dc97b474f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bae6b83b098d40ef890cc1b19cbee79a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4fdec4654a5640f8bcd7e66913b4bdaf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1af8e3c02f844762908e3bdbc1b3df20":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"53a4809ee7ea405cb3894e2388deada1":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_dfd77ddea8d74cddb95559442706e0ba","IPY_MODEL_a96d8a5eca614f8b9b1e16b1c2db8d59","IPY_MODEL_6b2dd62933af4018bf0ab4ce217cbba6"],"layout":"IPY_MODEL_e8ee34d8f098400d95ec58f374ce8e79"}},"dfd77ddea8d74cddb95559442706e0ba":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_745640fde7b94bd3b0617d7b2553dedf","placeholder":"​","style":"IPY_MODEL_ff5a510b7129480fbde37fcd50778694","value":"Pre. tgt. for `test`:  99%"}},"a96d8a5eca614f8b9b1e16b1c2db8d59":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_3ff91b64b924474380a42235370bd1f7","max":816,"min":0,"orientation":"horizontal","style":"IPY_MODEL_eb47b6dad8df41f5926657da36baec92","value":816}},"6b2dd62933af4018bf0ab4ce217cbba6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d6837d42897d45ba8ebe8cfade160a21","placeholder":"​","style":"IPY_MODEL_7ed1f2510bf347b8af068b11304b3b47","value":" 805/816 [00:05&lt;00:00, 206.72it/s]"}},"e8ee34d8f098400d95ec58f374ce8e79":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"100%"}},"745640fde7b94bd3b0617d7b2553dedf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ff5a510b7129480fbde37fcd50778694":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3ff91b64b924474380a42235370bd1f7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"eb47b6dad8df41f5926657da36baec92":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d6837d42897d45ba8ebe8cfade160a21":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7ed1f2510bf347b8af068b11304b3b47":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6c00442857134aa18cd24ee13ea97e87":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8ae9d9ed94ce41008d0cc6911556c83c","IPY_MODEL_dbc7f98eb96d4872970076b5afeb7c47","IPY_MODEL_e7ca370f360440f3addeb7718f912939"],"layout":"IPY_MODEL_063326c8b99842b4aff01b6c0b5034a6"}},"8ae9d9ed94ce41008d0cc6911556c83c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_91c7035922eb4f8bacd18e0660ba30c0","placeholder":"​","style":"IPY_MODEL_677318ba6b414ff3b899bcc526739eb1","value":"Pre. tgt. for `train`: 100%"}},"dbc7f98eb96d4872970076b5afeb7c47":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_393f680356ff4d3899d88f47da4a6157","max":2934,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6e59fea295b64760a3978a4b7399005b","value":2934}},"e7ca370f360440f3addeb7718f912939":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_76beef09ad2043f2ad4e98ea3113b7c4","placeholder":"​","style":"IPY_MODEL_132fd2d0273749fdb3ef30fb78da3229","value":" 2920/2934 [00:16&lt;00:00, 172.74it/s]"}},"063326c8b99842b4aff01b6c0b5034a6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"100%"}},"91c7035922eb4f8bacd18e0660ba30c0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"677318ba6b414ff3b899bcc526739eb1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"393f680356ff4d3899d88f47da4a6157":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6e59fea295b64760a3978a4b7399005b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"76beef09ad2043f2ad4e98ea3113b7c4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"132fd2d0273749fdb3ef30fb78da3229":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}