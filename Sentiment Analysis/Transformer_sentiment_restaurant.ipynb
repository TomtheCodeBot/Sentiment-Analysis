{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Transformer_sentiment_restaurant.ipynb","provenance":[],"collapsed_sections":["im-ufjT0g6_L","MQwocvOY5EEi","YbqKcU-HwxFP","5aRhKFHQ9yXY","BWeNjY13jF5C","dCtAWimziVXR","HcuQh7sVUPq5","dVLiv9MiD_70","PE8Y8i_gt9rg","Zd3VqYYYuLc3"]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"d8a0a2e2132f43f2ba2f0663bd8b8897":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d0d8e088c9f549dfab384564c81cb63f","IPY_MODEL_bfe5125fbc9d47389ede8e31a57971de","IPY_MODEL_a286689b54cb4c7a8b6bf37bafa25674"],"layout":"IPY_MODEL_5ae6fd90b19d4391945ccdaf0b1f913d"}},"d0d8e088c9f549dfab384564c81cb63f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ac34afddd37745bfa78080eca39467c0","placeholder":"​","style":"IPY_MODEL_0fc95e00aa4749058b46864a655e5ef6","value":"Epoch 1/50:   1%"}},"bfe5125fbc9d47389ede8e31a57971de":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_fcf601c37a7243b299828b5c50744613","max":25500,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f3fa5a97665a4587a8ed2977f6c8c64e","value":158}},"a286689b54cb4c7a8b6bf37bafa25674":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c8cf22311ec14e60bfca507cc07f241a","placeholder":"​","style":"IPY_MODEL_db1a3576a87743b4b75f4fab0181fe58","value":" 158/25500 [00:28&lt;1:13:45,  5.73it/s, loss:0.00016]"}},"5ae6fd90b19d4391945ccdaf0b1f913d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"100%"}},"ac34afddd37745bfa78080eca39467c0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0fc95e00aa4749058b46864a655e5ef6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fcf601c37a7243b299828b5c50744613":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f3fa5a97665a4587a8ed2977f6c8c64e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c8cf22311ec14e60bfca507cc07f241a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"db1a3576a87743b4b75f4fab0181fe58":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"63732b415c304865bb4cd9bb00a8a815":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_cfbced143e4a471dbee5606e304d5cd6","IPY_MODEL_e330ed307a6148ed8d97223a2988da7d","IPY_MODEL_4c8b63a73d344c90b761a0dd09a18e54"],"layout":"IPY_MODEL_9021a79805ae4dac8acb5b0ce2f2d5cb"}},"cfbced143e4a471dbee5606e304d5cd6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e882644e26894f2bbbb6bd7043abe82d","placeholder":"​","style":"IPY_MODEL_40102d04f3854bb3a4831f013ed9a215","value":"Downloading: 100%"}},"e330ed307a6148ed8d97223a2988da7d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4cc28abe359f40aab0daff48228a385c","max":557941479,"min":0,"orientation":"horizontal","style":"IPY_MODEL_cfe403960a754390938bfdd38e8ef536","value":557941479}},"4c8b63a73d344c90b761a0dd09a18e54":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_805d03e1b79042c6a07a83e1c53618be","placeholder":"​","style":"IPY_MODEL_b44fdfa8aeb044059b719a94b054ae7a","value":" 558M/558M [00:20&lt;00:00, 22.3MB/s]"}},"9021a79805ae4dac8acb5b0ce2f2d5cb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e882644e26894f2bbbb6bd7043abe82d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"40102d04f3854bb3a4831f013ed9a215":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4cc28abe359f40aab0daff48228a385c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cfe403960a754390938bfdd38e8ef536":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"805d03e1b79042c6a07a83e1c53618be":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b44fdfa8aeb044059b719a94b054ae7a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"02f6b2acf68643ccb74b6ac41cbd9d93":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_20ade3e614c744ae8a05fd3d7dfef40d","IPY_MODEL_8f2f626491814f9e8f273ca372414cc3","IPY_MODEL_6295cc36bf8747db92e8ed07f6199a9c"],"layout":"IPY_MODEL_e99e70ada72f404eb47ee685bce5e59e"}},"20ade3e614c744ae8a05fd3d7dfef40d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9f84055b9cf04177a6f9e9e4bf3f6b7f","placeholder":"​","style":"IPY_MODEL_853b0abc2df54e9688b075d133b60346","value":"Test: 100%"}},"8f2f626491814f9e8f273ca372414cc3":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_5cd4cd00ab6d4775b5e260117fae33aa","max":30,"min":0,"orientation":"horizontal","style":"IPY_MODEL_bc31184e180c4d09a9564d350cfab35e","value":30}},"6295cc36bf8747db92e8ed07f6199a9c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8d55b4dc1857412ea21e4dc0c24945ee","placeholder":"​","style":"IPY_MODEL_eb5681b4a9824dbca6f7dae508b72adf","value":" 30/30 [00:10&lt;00:00,  3.04it/s]"}},"e99e70ada72f404eb47ee685bce5e59e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"100%"}},"9f84055b9cf04177a6f9e9e4bf3f6b7f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"853b0abc2df54e9688b075d133b60346":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5cd4cd00ab6d4775b5e260117fae33aa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bc31184e180c4d09a9564d350cfab35e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8d55b4dc1857412ea21e4dc0c24945ee":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"eb5681b4a9824dbca6f7dae508b72adf":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0aa3fe347f1648a890d644c6feee9908":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ccd0d58dc9664886b5d3910f1306dce4","IPY_MODEL_30b3aaab7bc64a629bed0e4ddd8b34c7","IPY_MODEL_577b56ab56804f9bb99d49c837f4f780"],"layout":"IPY_MODEL_ffcbb63ea7d54f9491771b8db7528e7e"}},"ccd0d58dc9664886b5d3910f1306dce4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_80de24a5416f4e568ac3ed535c60b20c","placeholder":"​","style":"IPY_MODEL_81ec4f64615e4f25b5335d4157a221f4","value":"Test: 100%"}},"30b3aaab7bc64a629bed0e4ddd8b34c7":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_18dd841c6b0c403c857f38bbcdcf2598","max":26,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7df691aea184491c8229b66d6ed22b1d","value":26}},"577b56ab56804f9bb99d49c837f4f780":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_29e403119db947a6b6369136a91ef1d8","placeholder":"​","style":"IPY_MODEL_400f7e5a67d94ce296c5c567ca6fd551","value":" 26/26 [00:14&lt;00:00,  2.67it/s]"}},"ffcbb63ea7d54f9491771b8db7528e7e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"100%"}},"80de24a5416f4e568ac3ed535c60b20c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"81ec4f64615e4f25b5335d4157a221f4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"18dd841c6b0c403c857f38bbcdcf2598":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7df691aea184491c8229b66d6ed22b1d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"29e403119db947a6b6369136a91ef1d8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"400f7e5a67d94ce296c5c567ca6fd551":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"64ca6d1523594483ac783983dd45aa77":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_91096cbbd89e41f1b17de00458ca8a3d","IPY_MODEL_bf48ba65376246989c14f2edb9b82fdc","IPY_MODEL_3472979d1f9e4c5eac14acfc285b0472"],"layout":"IPY_MODEL_ed19715562114330bbfba730aea866af"}},"91096cbbd89e41f1b17de00458ca8a3d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_02ad9ebd37744dd894ab945c835023a5","placeholder":"​","style":"IPY_MODEL_30b60763884d435eae8cec494b31ca8e","value":"Test: 100%"}},"bf48ba65376246989c14f2edb9b82fdc":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_e8b3d5695a4443b2bb59ecb7def03287","max":38,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c2f9674bd1ce4b9ab01dbda7f6641576","value":38}},"3472979d1f9e4c5eac14acfc285b0472":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fae2d50762194cb8984788410e817468","placeholder":"​","style":"IPY_MODEL_fb5c9fe10bcb4842b8f876d00fe15912","value":" 38/38 [00:10&lt;00:00,  3.44it/s]"}},"ed19715562114330bbfba730aea866af":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"100%"}},"02ad9ebd37744dd894ab945c835023a5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"30b60763884d435eae8cec494b31ca8e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e8b3d5695a4443b2bb59ecb7def03287":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c2f9674bd1ce4b9ab01dbda7f6641576":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"fae2d50762194cb8984788410e817468":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fb5c9fe10bcb4842b8f876d00fe15912":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"517db5d632b346cb87baf258608b1dc1":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_46be6628a7be4acda1829971061bbed4","IPY_MODEL_bb2ee036ca014aa1825753419864f0cc","IPY_MODEL_74089c52f4f644c99847a25b845718b7"],"layout":"IPY_MODEL_2c88083802fd493b8fa1e3e4f0d04288"}},"46be6628a7be4acda1829971061bbed4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f654aef16249475f949fdd91e91f11a3","placeholder":"​","style":"IPY_MODEL_d0962910946649648d2e3511feddc6c6","value":"Downloading: 100%"}},"bb2ee036ca014aa1825753419864f0cc":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_799ca9eb7b994ab2bffed25f0ce885fa","max":1553,"min":0,"orientation":"horizontal","style":"IPY_MODEL_570133c9c3574cbdaa3f79198e1a3f5f","value":1553}},"74089c52f4f644c99847a25b845718b7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ccd23235ef4240179fd86f39d6b20b2d","placeholder":"​","style":"IPY_MODEL_984305b0bb1446c58504527e70bb34fc","value":" 1.55k/1.55k [00:00&lt;00:00, 17.3kB/s]"}},"2c88083802fd493b8fa1e3e4f0d04288":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f654aef16249475f949fdd91e91f11a3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d0962910946649648d2e3511feddc6c6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"799ca9eb7b994ab2bffed25f0ce885fa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"570133c9c3574cbdaa3f79198e1a3f5f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ccd23235ef4240179fd86f39d6b20b2d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"984305b0bb1446c58504527e70bb34fc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"af3b6911a9cb415d987a5225dd013fa9":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5cf4c138d8194e11ac16cb35455b2657","IPY_MODEL_f9b838182ffa4a1a80948f5d36956201","IPY_MODEL_d16ef2ab6b20459694290be4d48bb62b"],"layout":"IPY_MODEL_479a2a3f6d0443eaba667d6f74218e46"}},"5cf4c138d8194e11ac16cb35455b2657":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1028abd27b5f47b7b97def956de38250","placeholder":"​","style":"IPY_MODEL_aee38c9ed738413392b53cfccfd989ac","value":"Downloading: 100%"}},"f9b838182ffa4a1a80948f5d36956201":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_13c7113f69fc474a8391650a00f4fd82","max":898823,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3225a8f23f7e484981b8d7031fe4cb91","value":898823}},"d16ef2ab6b20459694290be4d48bb62b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c710281fedb54a538a255229a3529c05","placeholder":"​","style":"IPY_MODEL_ee69ecfcabfa4f49a767496f8e648449","value":" 899k/899k [00:01&lt;00:00, 1.08MB/s]"}},"479a2a3f6d0443eaba667d6f74218e46":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1028abd27b5f47b7b97def956de38250":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"aee38c9ed738413392b53cfccfd989ac":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"13c7113f69fc474a8391650a00f4fd82":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3225a8f23f7e484981b8d7031fe4cb91":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c710281fedb54a538a255229a3529c05":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ee69ecfcabfa4f49a767496f8e648449":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fe5f2eb524174460b348439027985a4e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a1b72b82201649dbb898501b2bd8b096","IPY_MODEL_b645786308bc484cb001d9eb3558f59c","IPY_MODEL_7c45b14f906c4b46bc4020757fba5d8a"],"layout":"IPY_MODEL_c83fe92a948d4136ab5f1ada0a786e66"}},"a1b72b82201649dbb898501b2bd8b096":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_049a7945e44d4f03ba0b19718aa97e68","placeholder":"​","style":"IPY_MODEL_f468091b81f94d59a83551084d7f6375","value":"Downloading: 100%"}},"b645786308bc484cb001d9eb3558f59c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6615d1ec7a5f4e17b2a144268fcd96a3","max":456318,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8d878347504b4df5a8a5032f4a4f1ac4","value":456318}},"7c45b14f906c4b46bc4020757fba5d8a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_24cdbd1a46464d35a219b447a524b46b","placeholder":"​","style":"IPY_MODEL_65b4e31e4ab94e89b7ff54ec7a96b8dd","value":" 456k/456k [00:00&lt;00:00, 469kB/s]"}},"c83fe92a948d4136ab5f1ada0a786e66":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"049a7945e44d4f03ba0b19718aa97e68":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f468091b81f94d59a83551084d7f6375":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6615d1ec7a5f4e17b2a144268fcd96a3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8d878347504b4df5a8a5032f4a4f1ac4":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"24cdbd1a46464d35a219b447a524b46b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"65b4e31e4ab94e89b7ff54ec7a96b8dd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"df82a18287ed453c97c53044212bec69":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6012bdc538d54d568730b7fdee1be209","IPY_MODEL_42308a89abeb4719b8504139cfe8fc95","IPY_MODEL_fb46570775f54c24a11dd4757b693df7"],"layout":"IPY_MODEL_c9305207429f4a9eb2b8d3b6f57fa92f"}},"6012bdc538d54d568730b7fdee1be209":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ede23750796b43f988d5de88985d931a","placeholder":"​","style":"IPY_MODEL_6bced419a6f149d89bd9da234f6df382","value":"Pre. tgt. for `dev`:  91%"}},"42308a89abeb4719b8504139cfe8fc95":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_727258ac79da42848eaa83dfc113f97e","max":171,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5771410fffaf427fb2bcac52d72e6625","value":171}},"fb46570775f54c24a11dd4757b693df7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bf4a824ec0fd434cb31dbea5d94bb671","placeholder":"​","style":"IPY_MODEL_edfcd670596b4f0da321783304d00491","value":" 155/171 [00:00&lt;00:00, 200.69it/s]"}},"c9305207429f4a9eb2b8d3b6f57fa92f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"100%"}},"ede23750796b43f988d5de88985d931a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6bced419a6f149d89bd9da234f6df382":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"727258ac79da42848eaa83dfc113f97e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5771410fffaf427fb2bcac52d72e6625":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"bf4a824ec0fd434cb31dbea5d94bb671":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"edfcd670596b4f0da321783304d00491":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"956df583d75042cf809e0a6edb57a733":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_775d3546995847768f7b6a1f62d71b44","IPY_MODEL_1cc83d7481aa4925ab55b76c420c4176","IPY_MODEL_33bac986d8d846c8b1868dc16b1101e4"],"layout":"IPY_MODEL_f02c20680d3642279a1cdf9b0b0a4001"}},"775d3546995847768f7b6a1f62d71b44":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_181e415664d44dc4a1fa36f3f8d67d5b","placeholder":"​","style":"IPY_MODEL_49d35756f2bf420e9e9ef35c3f0a4f3d","value":"Pre. tgt. for `test`:  98%"}},"1cc83d7481aa4925ab55b76c420c4176":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_5c97baf71b674557a7ec2f76481b20b7","max":583,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b4c32e952aad4d3d94c2f222387fbd23","value":583}},"33bac986d8d846c8b1868dc16b1101e4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9378114855a042c5a9605dc4f2269676","placeholder":"​","style":"IPY_MODEL_a219ffa7bb844038a23dcf5da85b3166","value":" 574/583 [00:03&lt;00:00, 217.38it/s]"}},"f02c20680d3642279a1cdf9b0b0a4001":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"100%"}},"181e415664d44dc4a1fa36f3f8d67d5b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"49d35756f2bf420e9e9ef35c3f0a4f3d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5c97baf71b674557a7ec2f76481b20b7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b4c32e952aad4d3d94c2f222387fbd23":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9378114855a042c5a9605dc4f2269676":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a219ffa7bb844038a23dcf5da85b3166":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"84887bf942d04543a4ade9615f5bcd0d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7361ecabff63463b843ca00cc768977e","IPY_MODEL_deb768add23e4ed9b0ad2957e03c635d","IPY_MODEL_190fe3a474bd4e6da9fb1a77dfb5f79d"],"layout":"IPY_MODEL_2c1da913cb584a8eae04cc780c5e781c"}},"7361ecabff63463b843ca00cc768977e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0171ddb93cab4cedab6ca8b53ad7a6eb","placeholder":"​","style":"IPY_MODEL_8a44b39e118447bd86a1a912b56355ea","value":"Pre. tgt. for `train`: 100%"}},"deb768add23e4ed9b0ad2957e03c635d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_1394c1560de14c14a88a96563b9f0756","max":1530,"min":0,"orientation":"horizontal","style":"IPY_MODEL_bc29ffa700dc4fb88590431461781c90","value":1530}},"190fe3a474bd4e6da9fb1a77dfb5f79d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_85671aea0aaf40bf8784f4e3f4c2ee35","placeholder":"​","style":"IPY_MODEL_4fd76899dc8441c785a189ee8a6d5fdc","value":" 1525/1530 [00:09&lt;00:00, 137.76it/s]"}},"2c1da913cb584a8eae04cc780c5e781c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"100%"}},"0171ddb93cab4cedab6ca8b53ad7a6eb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8a44b39e118447bd86a1a912b56355ea":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1394c1560de14c14a88a96563b9f0756":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bc29ffa700dc4fb88590431461781c90":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"85671aea0aaf40bf8784f4e3f4c2ee35":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4fd76899dc8441c785a189ee8a6d5fdc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"66dcf9080aa34c7b9d5bcaad83932c2b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ea41370d025747e39c75807e6bc10c3c","IPY_MODEL_4394783393bd4102b0f4f68b6e3da2a8","IPY_MODEL_3f1a78dcf3534612a37cf7cc3ba90006"],"layout":"IPY_MODEL_445ac39f572b4ed485933715d1ce3d15"}},"ea41370d025747e39c75807e6bc10c3c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3384668a83b1468698f22e2c1617cedd","placeholder":"​","style":"IPY_MODEL_f1dd49ed53d94b3986998bf8105e52ab","value":"Test: 100%"}},"4394783393bd4102b0f4f68b6e3da2a8":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_44207528c88c46b3a9e8be0b8b70647f","max":195,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5bf3370b83634a088a1b94c6db2c2b0c","value":195}},"3f1a78dcf3534612a37cf7cc3ba90006":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2115448e2a2240f680f64a2b06dce33f","placeholder":"​","style":"IPY_MODEL_fdb3fcf3055c4ea2af10965d65921839","value":" 195/195 [02:39&lt;00:00,  1.50it/s]"}},"445ac39f572b4ed485933715d1ce3d15":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"100%"}},"3384668a83b1468698f22e2c1617cedd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f1dd49ed53d94b3986998bf8105e52ab":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"44207528c88c46b3a9e8be0b8b70647f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5bf3370b83634a088a1b94c6db2c2b0c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2115448e2a2240f680f64a2b06dce33f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fdb3fcf3055c4ea2af10965d65921839":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9f2b26b4757e454ab40f93877cad81a0":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_372630e0685d44d8979f93d4905376fa","IPY_MODEL_0f1f35b9f86440d19cefe8b3ae97f744","IPY_MODEL_480563d324cf4ad99d071640c4a5c521"],"layout":"IPY_MODEL_470ef326b180487f900ebb459cc57549"}},"372630e0685d44d8979f93d4905376fa":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_635d3b539c26402a9d59454eb29d45a4","placeholder":"​","style":"IPY_MODEL_4b2509933a2d4d4b90698c7990d51bd1","value":"Pre. tgt. for `dev`:  85%"}},"0f1f35b9f86440d19cefe8b3ae97f744":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_2fe2fd7602cc4c5fbd1d1eaa018c6f29","max":112,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c36f0d683d3442c6933f4bfc2a7284fe","value":112}},"480563d324cf4ad99d071640c4a5c521":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b3c3a36404624f4baa999635ca725f09","placeholder":"​","style":"IPY_MODEL_b3b59b6fb2334f89acf2ef85df97bb97","value":" 95/112 [00:00&lt;00:00, 345.39it/s]"}},"470ef326b180487f900ebb459cc57549":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"100%"}},"635d3b539c26402a9d59454eb29d45a4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4b2509933a2d4d4b90698c7990d51bd1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2fe2fd7602cc4c5fbd1d1eaa018c6f29":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c36f0d683d3442c6933f4bfc2a7284fe":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b3c3a36404624f4baa999635ca725f09":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b3b59b6fb2334f89acf2ef85df97bb97":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"af3814ddde6941a193ee24444b637386":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3030759fc8cd4810a85078eac9412794","IPY_MODEL_f69ef85d0b614f5d99ae879fe94cf2a5","IPY_MODEL_ead94b8f524a476ab7c23fb09f3e940b"],"layout":"IPY_MODEL_d398b87346cb41e79ff6a5d9a315494a"}},"3030759fc8cd4810a85078eac9412794":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e8a498ee1d5f4658892ef5b3859d3667","placeholder":"​","style":"IPY_MODEL_566c77fb1e9643cc9c0bee13843bc258","value":"Pre. tgt. for `test`:  87%"}},"f69ef85d0b614f5d99ae879fe94cf2a5":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_00d2e5e985c144348ee7133e5f56a534","max":90,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9f43132d736245ff944ffe4e17d58f27","value":90}},"ead94b8f524a476ab7c23fb09f3e940b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cbc7a9f3e765420ea77283d1f0048629","placeholder":"​","style":"IPY_MODEL_a500490161e642b19351998265e096e4","value":" 78/90 [00:00&lt;00:00, 259.78it/s]"}},"d398b87346cb41e79ff6a5d9a315494a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"100%"}},"e8a498ee1d5f4658892ef5b3859d3667":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"566c77fb1e9643cc9c0bee13843bc258":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"00d2e5e985c144348ee7133e5f56a534":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9f43132d736245ff944ffe4e17d58f27":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"cbc7a9f3e765420ea77283d1f0048629":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a500490161e642b19351998265e096e4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"143e0b3df5be419797f33d454357929d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0c63b536f74b4164a53b6b013ae38c1d","IPY_MODEL_37e6d1fe8f0446cab9c43ae58cb9806e","IPY_MODEL_5c4419e1e12645d2ba6af1609f3c3fe1"],"layout":"IPY_MODEL_e7852749a1a44eef9d30c63bc18cd602"}},"0c63b536f74b4164a53b6b013ae38c1d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b177da5c70284aec9efdf4ad415cffaa","placeholder":"​","style":"IPY_MODEL_f884e047559d49ef9d333667eb3beca6","value":"Pre. tgt. for `train`:  98%"}},"37e6d1fe8f0446cab9c43ae58cb9806e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_497d931c2028441a80e009390466af6f","max":366,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d2192524a0684eba8b3cf3a07065792e","value":366}},"5c4419e1e12645d2ba6af1609f3c3fe1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_719d05a3892c491193132f1834a9549c","placeholder":"​","style":"IPY_MODEL_c10e9809bc0242279e3b55b4303d69f6","value":" 357/366 [00:01&lt;00:00, 268.43it/s]"}},"e7852749a1a44eef9d30c63bc18cd602":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"100%"}},"b177da5c70284aec9efdf4ad415cffaa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f884e047559d49ef9d333667eb3beca6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"497d931c2028441a80e009390466af6f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d2192524a0684eba8b3cf3a07065792e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"719d05a3892c491193132f1834a9549c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c10e9809bc0242279e3b55b4303d69f6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"38b976bb7a274cc386cb06eeab958fa5":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ab81478d1f994a0aae8a87641d6de590","IPY_MODEL_c377051749244fd2b7ef63b932430e0e","IPY_MODEL_e4903f5b18b9477c88b39b2c8accb144"],"layout":"IPY_MODEL_2089b8af4165443fa1572dbf2810349f"}},"ab81478d1f994a0aae8a87641d6de590":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_40aa11815b61440d878392cf2cc6d386","placeholder":"​","style":"IPY_MODEL_f8e791ed80f64b0eb3432e2d3f73cfaf","value":"Test: 100%"}},"c377051749244fd2b7ef63b932430e0e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_ed380696fe474220bfd530b7c802626d","max":122,"min":0,"orientation":"horizontal","style":"IPY_MODEL_df8ee2f2ca0e4add88859923c543336c","value":122}},"e4903f5b18b9477c88b39b2c8accb144":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e23f1be560f54418be15b5b83edbde82","placeholder":"​","style":"IPY_MODEL_71f6e328edab4b92a3178c22cc57021c","value":" 122/122 [01:50&lt;00:00,  1.19it/s]"}},"2089b8af4165443fa1572dbf2810349f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"100%"}},"40aa11815b61440d878392cf2cc6d386":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f8e791ed80f64b0eb3432e2d3f73cfaf":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ed380696fe474220bfd530b7c802626d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"df8ee2f2ca0e4add88859923c543336c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e23f1be560f54418be15b5b83edbde82":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"71f6e328edab4b92a3178c22cc57021c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7I-xZzsveUMA","executionInfo":{"status":"ok","timestamp":1651160808587,"user_tz":-420,"elapsed":117692,"user":{"displayName":"Duy Hoang","userId":"17457647490907439684"}},"outputId":"fca43f6f-d03d-4290-a23c-2fd830a504c2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["!pip install fastNLP\n","!pip install transformers==3.4.0\n","!pip install pytorch==1.7.1\n","!pip install fitlog"],"metadata":{"id":"S9qzfxSwkTtx","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1651160828697,"user_tz":-420,"elapsed":20132,"user":{"displayName":"Duy Hoang","userId":"17457647490907439684"}},"outputId":"cab48bb6-e0eb-412a-f455-5e57d0dda5f6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting fastNLP\n","  Downloading FastNLP-0.7.0.tar.gz (295 kB)\n","\u001b[?25l\r\u001b[K     |█                               | 10 kB 17.2 MB/s eta 0:00:01\r\u001b[K     |██▏                             | 20 kB 10.3 MB/s eta 0:00:01\r\u001b[K     |███▎                            | 30 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |████▍                           | 40 kB 3.7 MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 51 kB 3.7 MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 61 kB 4.4 MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 71 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 81 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 92 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 102 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 112 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 122 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 133 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 143 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 153 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 163 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 174 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 184 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 194 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 204 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 215 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 225 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 235 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 245 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 256 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 266 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 276 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 286 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 295 kB 4.3 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.14.2 in /usr/local/lib/python3.7/dist-packages (from fastNLP) (1.21.6)\n","Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from fastNLP) (1.11.0+cu113)\n","Requirement already satisfied: tqdm>=4.28.1 in /usr/local/lib/python3.7/dist-packages (from fastNLP) (4.64.0)\n","Requirement already satisfied: prettytable>=0.7.2 in /usr/local/lib/python3.7/dist-packages (from fastNLP) (3.2.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from fastNLP) (2.23.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from fastNLP) (2019.12.20)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prettytable>=0.7.2->fastNLP) (0.2.5)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from prettytable>=0.7.2->fastNLP) (4.11.3)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.0.0->fastNLP) (4.2.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->prettytable>=0.7.2->fastNLP) (3.8.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->fastNLP) (2021.10.8)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->fastNLP) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->fastNLP) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->fastNLP) (2.10)\n","Building wheels for collected packages: fastNLP\n","  Building wheel for fastNLP (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for fastNLP: filename=FastNLP-0.7.0-py3-none-any.whl size=364746 sha256=768d472da84af5ac2e17990a6c75eef8aea4cc216200056e8a7795f27ca722b3\n","  Stored in directory: /root/.cache/pip/wheels/eb/80/db/f206d6f4481007868937e789999822fc879aad6e44ddcbcafa\n","Successfully built fastNLP\n","Installing collected packages: fastNLP\n","Successfully installed fastNLP-0.7.0\n","Collecting transformers==3.4.0\n","  Downloading transformers-3.4.0-py3-none-any.whl (1.3 MB)\n","\u001b[K     |████████████████████████████████| 1.3 MB 4.3 MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==3.4.0) (2.23.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==3.4.0) (2019.12.20)\n","Collecting sentencepiece!=0.1.92\n","  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n","\u001b[K     |████████████████████████████████| 1.2 MB 39.4 MB/s \n","\u001b[?25hCollecting tokenizers==0.9.2\n","  Downloading tokenizers-0.9.2-cp37-cp37m-manylinux1_x86_64.whl (2.9 MB)\n","\u001b[K     |████████████████████████████████| 2.9 MB 37.2 MB/s \n","\u001b[?25hCollecting sacremoses\n","  Downloading sacremoses-0.0.49-py3-none-any.whl (895 kB)\n","\u001b[K     |████████████████████████████████| 895 kB 44.3 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==3.4.0) (4.64.0)\n","Requirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from transformers==3.4.0) (3.17.3)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers==3.4.0) (1.21.6)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==3.4.0) (21.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==3.4.0) (3.6.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==3.4.0) (3.0.8)\n","Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf->transformers==3.4.0) (1.15.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.4.0) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.4.0) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.4.0) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.4.0) (2021.10.8)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.4.0) (1.1.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.4.0) (7.1.2)\n","Installing collected packages: tokenizers, sentencepiece, sacremoses, transformers\n","Successfully installed sacremoses-0.0.49 sentencepiece-0.1.96 tokenizers-0.9.2 transformers-3.4.0\n","\u001b[31mERROR: Could not find a version that satisfies the requirement pytorch==1.7.1 (from versions: 0.1.2, 1.0.2)\u001b[0m\n","\u001b[31mERROR: No matching distribution found for pytorch==1.7.1\u001b[0m\n","Collecting fitlog\n","  Downloading fitlog-0.9.13.tar.gz (925 kB)\n","\u001b[K     |████████████████████████████████| 925 kB 3.5 MB/s \n","\u001b[?25hRequirement already satisfied: docopt>=0.6.2 in /usr/local/lib/python3.7/dist-packages (from fitlog) (0.6.2)\n","Requirement already satisfied: flask>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from fitlog) (1.1.4)\n","Requirement already satisfied: numpy>=1.16.4 in /usr/local/lib/python3.7/dist-packages (from fitlog) (1.21.6)\n","Collecting gitpython>=3.1.2\n","  Downloading GitPython-3.1.27-py3-none-any.whl (181 kB)\n","\u001b[K     |████████████████████████████████| 181 kB 46.3 MB/s \n","\u001b[?25hRequirement already satisfied: itsdangerous<2.0,>=0.24 in /usr/local/lib/python3.7/dist-packages (from flask>=1.0.2->fitlog) (1.1.0)\n","Requirement already satisfied: Werkzeug<2.0,>=0.15 in /usr/local/lib/python3.7/dist-packages (from flask>=1.0.2->fitlog) (1.0.1)\n","Requirement already satisfied: Jinja2<3.0,>=2.10.1 in /usr/local/lib/python3.7/dist-packages (from flask>=1.0.2->fitlog) (2.11.3)\n","Requirement already satisfied: click<8.0,>=5.1 in /usr/local/lib/python3.7/dist-packages (from flask>=1.0.2->fitlog) (7.1.2)\n","Collecting gitdb<5,>=4.0.1\n","  Downloading gitdb-4.0.9-py3-none-any.whl (63 kB)\n","\u001b[K     |████████████████████████████████| 63 kB 1.8 MB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from gitpython>=3.1.2->fitlog) (4.2.0)\n","Collecting smmap<6,>=3.0.1\n","  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2<3.0,>=2.10.1->flask>=1.0.2->fitlog) (2.0.1)\n","Building wheels for collected packages: fitlog\n","  Building wheel for fitlog (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for fitlog: filename=fitlog-0.9.13-py3-none-any.whl size=967495 sha256=b5f0e1d0107259a3b1c7cc5b50cffbd8ad85d3060421baf9e24b78b2336f5409\n","  Stored in directory: /root/.cache/pip/wheels/7d/95/d4/a1a752c27fad922c452674b431fb58417ac6de1a530c8a6d05\n","Successfully built fitlog\n","Installing collected packages: smmap, gitdb, gitpython, fitlog\n","Successfully installed fitlog-0.9.13 gitdb-4.0.9 gitpython-3.1.27 smmap-5.0.0\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","import glob\n","from tqdm import tqdm\n","import re\n","import itertools\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import f1_score\n","from sklearn.metrics import confusion_matrix\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from sklearn.metrics import recall_score,f1_score,precision_score,accuracy_score\n","import torch\n","from torch import nn"],"metadata":{"id":"G7gO_HpreZuq"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Laptop-ACOS"],"metadata":{"id":"im-ufjT0g6_L"}},{"cell_type":"code","source":["def adJusttab(input_file, output_file):\n","    lines_seen = set()  ### holds lines already seen\n","    outfile = open(output_file, \"w\", encoding='latin-1')\n","    for line in open(input_file, \"r\", encoding='latin-1'):\n","        arr = line.split(\"\\t\")\n","        arr[0 : 2] = ['\\t'.join(arr[0 : 2])]\n","        newline =' '.join(arr)\n","        outfile.write(newline)\n","    outfile.close()"],"metadata":{"id":"oolcZUHk1ClI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["adJusttab(\"/content/drive/MyDrive/Sentiment Analysis/data/Laptop-ACOS/laptop_quad_dev.tsv\", \"/content/drive/MyDrive/Sentiment Analysis/data/Laptop-ACOS/laptop_quad_dev_adjusted.tsv\")"],"metadata":{"id":"gtiXrx492CDt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["adJusttab(\"/content/drive/MyDrive/Sentiment Analysis/data/Laptop-ACOS/laptop_quad_train.tsv\", \"/content/drive/MyDrive/Sentiment Analysis/data/Laptop-ACOS/laptop_quad_train_adjusted.tsv\")"],"metadata":{"id":"3s5pVxss2eq0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["adJusttab(\"/content/drive/MyDrive/Sentiment Analysis/data/Laptop-ACOS/laptop_quad_test.tsv\", \"/content/drive/MyDrive/Sentiment Analysis/data/Laptop-ACOS/laptop_quad_test_adjusted.tsv\")"],"metadata":{"id":"AS9XYEsfDhxi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dev_dataframe = pd.read_csv(\"/content/drive/MyDrive/Sentiment Analysis/data/Laptop-ACOS/laptop_quad_dev_adjusted.tsv\", sep='\\t',on_bad_lines='skip',names=[\"text\",\"label\"])\n","test_dataframe = pd.read_csv(\"/content/drive/MyDrive/Sentiment Analysis/data/Laptop-ACOS/laptop_quad_test_adjusted.tsv\", sep='\\t',on_bad_lines='skip',names=[\"text\",\"label\"])\n","train_dataframe = pd.read_csv(\"/content/drive/MyDrive/Sentiment Analysis/data/Laptop-ACOS/laptop_quad_train_adjusted.tsv\", sep='\\t',on_bad_lines='skip',names=[\"text\",\"label\"])"],"metadata":{"id":"tqZ_evhKg1cu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(train_dataframe)"],"metadata":{"id":"58eOCiIWhNFf"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Restaurant-ACOS"],"metadata":{"id":"MQwocvOY5EEi"}},{"cell_type":"code","source":["adJusttab(\"/content/drive/MyDrive/Sentiment Analysis/data/Restaurant-ACOS/rest16_quad_dev.tsv\", \"/content/drive/MyDrive/Sentiment Analysis/data/Restaurant-ACOS/rest16_quad_dev_adjusted.tsv\")"],"metadata":{"id":"p_aHU5ae5J_f"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["adJusttab(\"/content/drive/MyDrive/Sentiment Analysis/data/Restaurant-ACOS/rest16_quad_test.tsv\", \"/content/drive/MyDrive/Sentiment Analysis/data/Restaurant-ACOS/rest16_quad_test_adjusted.tsv\")"],"metadata":{"id":"ygAW5Zyb5J_g"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["adJusttab(\"/content/drive/MyDrive/Sentiment Analysis/data/Restaurant-ACOS/rest16_quad_train.tsv\", \"/content/drive/MyDrive/Sentiment Analysis/data/Restaurant-ACOS/rest16_quad_train_adjusted.tsv\")"],"metadata":{"id":"6t1c8mPI5J_g"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dev_dataframe = pd.read_csv(\"/content/drive/MyDrive/Sentiment Analysis/data/Restaurant-ACOS/rest16_quad_dev_adjusted.tsv\", sep='\\t',names=[\"text\",\"label\"])\n","test_dataframe = pd.read_csv(\"/content/drive/MyDrive/Sentiment Analysis/data/Restaurant-ACOS/rest16_quad_test_adjusted.tsv\", sep='\\t',names=[\"text\",\"label\"])\n","train_dataframe = pd.read_csv(\"/content/drive/MyDrive/Sentiment Analysis/data/Restaurant-ACOS/rest16_quad_train_adjusted.tsv\", sep='\\t',names=[\"text\",\"label\"])"],"metadata":{"id":"FUvv-oG15J_g"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(train_dataframe)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1649953802816,"user_tz":-420,"elapsed":271,"user":{"displayName":"Duy Hoang","userId":"17457647490907439684"}},"outputId":"bb99f458-5297-483f-b826-a5525db1df28","id":"p07kqShB5J_h"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["                                                   text  \\\n","0     judging from previous posts this used to be a ...   \n","1     we , there were four of us , arrived at noon -...   \n","2     they never brought us complimentary noodles , ...   \n","3     the food was lousy - too sweet or too salty an...   \n","4     after all that , they complained to me about t...   \n","...                                                 ...   \n","1525  i ca n ' t believe that it was , but please pu...   \n","1526  the waitress came to check in on us every few ...   \n","1527  i could n ' t ignore the fact that she reach o...   \n","1528  she then put the check down without asking if ...   \n","1529  i wish i could like this place more , and i wi...   \n","\n","                                                  label  \n","0                      10,11 RESTAURANT#GENERAL 0 13,16  \n","1                         19,20 SERVICE#GENERAL 0 31,32  \n","2                         -1,-1 SERVICE#GENERAL 0 -1,-1  \n","3     1,2 FOOD#QUALITY 0 3,4 1,2 FOOD#QUALITY 0 5,7 ...  \n","4                           -1,-1 SERVICE#GENERAL 0 5,6  \n","...                                                 ...  \n","1525                      -1,-1 SERVICE#GENERAL 0 -1,-1  \n","1526                        1,2 SERVICE#GENERAL 0 -1,-1  \n","1527                      -1,-1 SERVICE#GENERAL 0 -1,-1  \n","1528                      -1,-1 SERVICE#GENERAL 0 -1,-1  \n","1529  6,7 RESTAURANT#GENERAL 0 -1,-1 16,17 SERVICE#G...  \n","\n","[1530 rows x 2 columns]\n"]}]},{"cell_type":"markdown","source":["#Labels"],"metadata":{"id":"YbqKcU-HwxFP"}},{"cell_type":"code","source":["laptop_obj =['<<MULTIMEDIA_DEVICES>>', '<<OS>>', '<<SHIPPING>>', '<<GRAPHICS>>', '<<CPU>>', '<<COMPANY>>', '<<MEMORY>>', '<<POWER_SUPPLY>>', '<<SOFTWARE>>', '<<FANS&COOLING>>', '<<BATTERY>>', '<<HARD_DISC>>', '<<MOUSE>>', '<<LAPTOP>>', '<<PORTS>>', '<<KEYBOARD>>', '<<SUPPORT>>', '<<OPTICAL_DRIVES>>', '<<DISPLAY>>', '<<MOTHERBOARD>>', '<<HARDWARE>>', '<<Out_Of_Scope>>', '<<WARRANTY>>']\n","laptop_catergory =['<<PRICE>>', '<<QUALITY>>', '<<OPERATION_PERFORMANCE>>', '<<DESIGN_FEATURES>>', '<<CONNECTIVITY>>', '<<USABILITY>>', '<<GENERAL>>', '<<PORTABILITY>>', '<<MISCELLANEOUS>>']\n","laptop_obj_key = ['MULTIMEDIA_DEVICES', 'OS', 'SHIPPING', 'GRAPHICS', 'CPU', 'COMPANY', 'MEMORY', 'POWER_SUPPLY', 'SOFTWARE', 'FANS&COOLING', 'BATTERY', 'HARD_DISC', 'MOUSE', 'LAPTOP', 'PORTS', 'KEYBOARD', 'SUPPORT', 'OPTICAL_DRIVES', 'DISPLAY', 'MOTHERBOARD', 'HARDWARE', 'Out_Of_Scope', 'WARRANTY']\n","laptop_catergory_key = ['PRICE', 'QUALITY', 'OPERATION_PERFORMANCE', 'DESIGN_FEATURES', 'CONNECTIVITY', 'USABILITY', 'GENERAL', 'PORTABILITY', 'MISCELLANEOUS']\n"],"metadata":{"id":"ur1HXPDMclxI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["restaurant_obj =['<<RESTAURANT>>', '<<SERVICE>>', '<<FOOD>>', '<<DRINKS>>', '<<AMBIENCE>>', '<<LOCATION>>']\n","restaurant_catergory =['<<GENERAL>>', '<<QUALITY>>', '<<STYLE_OPTIONS>>', '<<PRICES>>', '<<MISCELLANEOUS>>']\n","restaurant_obj_key =['RESTAURANT', 'SERVICE', 'FOOD', 'DRINKS', 'AMBIENCE', 'LOCATION']\n","restaurant_catergory_key =['GENERAL', 'QUALITY', 'STYLE_OPTIONS', 'PRICES', 'MISCELLANEOUS']\n"],"metadata":{"id":"bBpp0tCii4N0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["restaurant_obj_dict = dict(zip(restaurant_obj_key, restaurant_obj))\n","restaurant_catergory_dict = dict(zip(restaurant_catergory_key, restaurant_catergory))\n","laptop_obj_dict = dict(zip(laptop_obj_key, laptop_obj))\n","laptop_catergory_dict = dict(zip(laptop_catergory_key, laptop_catergory))\n"],"metadata":{"id":"0lmWnXtFtYud"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Convert ACOS data to JSON"],"metadata":{"id":"5aRhKFHQ9yXY"}},{"cell_type":"code","source":["def labelConversion(label):\n","    ret = []\n","    lstlabel = label.split(\" \")\n","    for i in range(0,len(lstlabel)):\n","        if i%4==0 or i%4==3:\n","            ret.extend(lstlabel[i].split(\",\"))\n","        else:\n","            ret.append(lstlabel[i])\n","    return ret"],"metadata":{"id":"FK-XtR_rMsKQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\"\"\"words: List[str]\n","        aspects: [{\n","            'index': int\n","            'from': int\n","            'to': int\n","            'polarity': str\n","            'cat_obj':str\n","            'category':str\n","            'term': List[str]\n","        }],\n","        opinions: [{\n","            'index': int\n","            'from': int\n","            'to': int\n","            'term': List[str]\n","        }]\"\"\"\n","import json\n","def fromACOSToJSON(path):\n","    lst = []\n","    lst_aspect = []\n","    lst_opinion = []\n","    dict_templat = {}\n","    dict_template_aspect = {}\n","    dict_template_opinion = {}\n","    polarity = [\"NEG\",\"NEU\",\"POS\"]\n","    dev_dataframe = pd.read_csv(path, sep='\\t',on_bad_lines='skip',names=[\"text\",\"label\"])\n","    for i in range(0,len(dev_dataframe)):\n","        word = \"<<null>> \"+dev_dataframe.iloc[i][\"text\"]\n","        word.translate({\"/' \":\"'\"})\n","        dict_templat[\"raw_words\"] = word\n","        dict_templat[\"words\"] = word.split(\" \")\n","        labels = labelConversion(dev_dataframe.iloc[i][\"label\"])\n","        amount = int(len(labels)/6)\n","        for i in range(amount):\n","            dict_template_aspect[\"index\"] = i\n","            dict_template_opinion[\"index\"] = i\n","            pos = i*6\n","            if int(labels[pos])<0:\n","                dict_template_aspect[\"from\"] = 0\n","                dict_template_aspect[\"to\"] = 1\n","            else:\n","                dict_template_aspect[\"from\"] = int(labels[pos])+1\n","                dict_template_aspect[\"to\"] = int(labels[pos+1])+1\n","            if dict_template_aspect[\"from\"] == dict_template_aspect[\"to\"]:\n","                dict_template_aspect[\"to\"]+=1\n","            cat1,cat2 =  labels[pos+2].split(\"#\")\n","            dict_template_aspect[\"cat_obj\"] = cat1\n","            dict_template_aspect[\"category\"] = cat2\n","            dict_template_aspect[\"term\"] = dict_templat[\"words\"][dict_template_aspect[\"from\"]:dict_template_aspect[\"to\"]] \n","            dict_template_aspect[\"polarity\"] = polarity[int(labels[pos+3])]\n","            if int(labels[pos+4])<0:\n","                dict_template_opinion[\"from\"] = 0\n","                dict_template_opinion[\"to\"] = 1\n","            else:\n","                dict_template_opinion[\"from\"] = int(labels[pos+4])+1\n","                dict_template_opinion[\"to\"] = int(labels[pos+5])+1\n","            if dict_template_opinion[\"from\"] == dict_template_opinion[\"to\"]:\n","                dict_template_opinion[\"to\"]+=1\n","            dict_template_opinion[\"term\"] = dict_templat[\"words\"][dict_template_opinion[\"from\"]:dict_template_opinion[\"to\"]]\n","            lst_aspect.append(dict_template_aspect.copy())\n","            lst_opinion.append(dict_template_opinion.copy())\n","            dict_template_aspect={}\n","            dict_template_opinion={}\n","        dict_templat[\"aspects\"]=lst_aspect.copy()\n","        dict_templat[\"opinions\"]=lst_opinion.copy()\n","        lst_aspect = []\n","        lst_opinion = []\n","        lst.append(dict_templat.copy())\n","        dict_templat={}\n","    return json.dumps(lst)\n"],"metadata":{"id":"DrVgonN493EM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["json_object = fromACOSToJSON(\"/content/drive/MyDrive/Sentiment Analysis/data/Restaurant-ACOS/rest16_quad_dev_adjusted.tsv\")\n","with open(\"/content/drive/MyDrive/Sentiment Analysis/data/Restaurant-ACOS/json/dev_convert.json\", \"w\") as outfile:\n","    outfile.write(json_object)"],"metadata":{"id":"HFYiPtnTZ9Lj","colab":{"base_uri":"https://localhost:8080/","height":321},"executionInfo":{"status":"error","timestamp":1650797345850,"user_tz":-420,"elapsed":36,"user":{"displayName":"Duy Hoang","userId":"17457647490907439684"}},"outputId":"9a8abaff-8988-4f7b-bfde-8aef5d475022"},"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-8-e21fc60507b1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mjson_object\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfromACOSToJSON\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/MyDrive/Sentiment Analysis/data/Restaurant-ACOS/rest16_quad_dev_adjusted.tsv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/MyDrive/Sentiment Analysis/data/Restaurant-ACOS/json/dev_convert.json\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"w\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0moutfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0moutfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_object\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-7-efdc0b1d80d5>\u001b[0m in \u001b[0;36mfromACOSToJSON\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mdict_template_opinion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mpolarity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"NEG\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"NEU\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"POS\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0mdev_dataframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'\\t'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mon_bad_lines\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'skip'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"text\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"label\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdev_dataframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mword\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"<<null>> \"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mdev_dataframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"text\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"]}]},{"cell_type":"code","source":["json_object =fromACOSToJSON(\"/content/drive/MyDrive/Sentiment Analysis/data/Restaurant-ACOS/rest16_quad_test_adjusted.tsv\")\n","with open(\"/content/drive/MyDrive/Sentiment Analysis/data/Restaurant-ACOS/json/test_convert.json\", \"w\") as outfile:\n","    outfile.write(json_object)"],"metadata":{"id":"EPU_Cj_Fuji8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["json_object =fromACOSToJSON(\"/content/drive/MyDrive/Sentiment Analysis/data/Restaurant-ACOS/rest16_quad_train_adjusted.tsv\")\n","with open(\"/content/drive/MyDrive/Sentiment Analysis/data/Restaurant-ACOS/json/train_convert.json\", \"w\") as outfile:\n","    outfile.write(json_object)"],"metadata":{"id":"8FIKkqWquj7N"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["l = ['MULTIMEDIA_DEVICES#PRICE', 'OS#QUALITY', 'SHIPPING#QUALITY', 'GRAPHICS#OPERATION_PERFORMANCE', 'CPU#OPERATION_PERFORMANCE', \n","        'COMPANY#DESIGN_FEATURES', 'MEMORY#OPERATION_PERFORMANCE', 'SHIPPING#PRICE', 'POWER_SUPPLY#CONNECTIVITY', 'SOFTWARE#USABILITY', \n","        'FANS&COOLING#GENERAL', 'GRAPHICS#DESIGN_FEATURES', 'BATTERY#GENERAL', 'HARD_DISC#USABILITY', 'FANS&COOLING#DESIGN_FEATURES', \n","        'MEMORY#DESIGN_FEATURES', 'MOUSE#USABILITY', 'CPU#GENERAL', 'LAPTOP#QUALITY', 'POWER_SUPPLY#GENERAL', 'PORTS#QUALITY', \n","        'KEYBOARD#PORTABILITY', 'SUPPORT#DESIGN_FEATURES', 'MULTIMEDIA_DEVICES#USABILITY', 'MOUSE#GENERAL', 'KEYBOARD#MISCELLANEOUS', \n","        'MULTIMEDIA_DEVICES#DESIGN_FEATURES', 'OS#MISCELLANEOUS', 'LAPTOP#MISCELLANEOUS', 'SOFTWARE#PRICE', 'FANS&COOLING#OPERATION_PERFORMANCE', \n","        'MEMORY#QUALITY', 'OPTICAL_DRIVES#OPERATION_PERFORMANCE', 'HARD_DISC#GENERAL', 'MEMORY#GENERAL', 'DISPLAY#OPERATION_PERFORMANCE', \n","        'MULTIMEDIA_DEVICES#GENERAL', 'LAPTOP#GENERAL', 'MOTHERBOARD#QUALITY', 'LAPTOP#PORTABILITY', 'KEYBOARD#PRICE', 'SUPPORT#OPERATION_PERFORMANCE', \n","        'GRAPHICS#GENERAL', 'MOTHERBOARD#OPERATION_PERFORMANCE', 'DISPLAY#GENERAL', 'BATTERY#QUALITY', 'LAPTOP#USABILITY', 'LAPTOP#DESIGN_FEATURES', \n","        'PORTS#CONNECTIVITY', 'HARDWARE#QUALITY', 'SUPPORT#GENERAL', 'MOTHERBOARD#GENERAL', 'PORTS#USABILITY', 'KEYBOARD#QUALITY', 'GRAPHICS#USABILITY', \n","        'HARD_DISC#PRICE', 'OPTICAL_DRIVES#USABILITY', 'MULTIMEDIA_DEVICES#CONNECTIVITY', 'HARDWARE#DESIGN_FEATURES', 'MEMORY#USABILITY', \n","        'SHIPPING#GENERAL', 'CPU#PRICE', 'Out_Of_Scope#DESIGN_FEATURES', 'MULTIMEDIA_DEVICES#QUALITY', 'OS#PRICE', 'SUPPORT#QUALITY', \n","        'OPTICAL_DRIVES#GENERAL', 'HARDWARE#USABILITY', 'DISPLAY#DESIGN_FEATURES', 'PORTS#GENERAL', 'COMPANY#OPERATION_PERFORMANCE', \n","        'COMPANY#GENERAL', 'Out_Of_Scope#GENERAL', 'KEYBOARD#DESIGN_FEATURES', 'Out_Of_Scope#OPERATION_PERFORMANCE', \n","        'OPTICAL_DRIVES#DESIGN_FEATURES', 'LAPTOP#OPERATION_PERFORMANCE', 'KEYBOARD#USABILITY', 'DISPLAY#USABILITY', 'POWER_SUPPLY#QUALITY', \n","        'HARD_DISC#DESIGN_FEATURES', 'DISPLAY#QUALITY', 'MOUSE#DESIGN_FEATURES', 'COMPANY#QUALITY', 'HARDWARE#GENERAL', 'COMPANY#PRICE', \n","        'MULTIMEDIA_DEVICES#OPERATION_PERFORMANCE', 'KEYBOARD#OPERATION_PERFORMANCE', 'SOFTWARE#PORTABILITY', 'HARD_DISC#OPERATION_PERFORMANCE', \n","        'BATTERY#DESIGN_FEATURES', 'CPU#QUALITY', 'WARRANTY#GENERAL', 'OS#DESIGN_FEATURES', 'OS#OPERATION_PERFORMANCE', 'OS#USABILITY', \n","        'SOFTWARE#GENERAL', 'SUPPORT#PRICE', 'SHIPPING#OPERATION_PERFORMANCE', 'DISPLAY#PRICE', 'LAPTOP#PRICE', 'OS#GENERAL', 'HARDWARE#PRICE', \n","        'SOFTWARE#DESIGN_FEATURES', 'HARD_DISC#MISCELLANEOUS', 'PORTS#PORTABILITY', 'FANS&COOLING#QUALITY', 'BATTERY#OPERATION_PERFORMANCE', \n","        'CPU#DESIGN_FEATURES', 'PORTS#OPERATION_PERFORMANCE', 'SOFTWARE#OPERATION_PERFORMANCE', 'KEYBOARD#GENERAL', 'SOFTWARE#QUALITY', \n","        'LAPTOP#CONNECTIVITY', 'POWER_SUPPLY#DESIGN_FEATURES', 'HARDWARE#OPERATION_PERFORMANCE', 'WARRANTY#QUALITY', 'HARD_DISC#QUALITY', \n","        'POWER_SUPPLY#OPERATION_PERFORMANCE', 'PORTS#DESIGN_FEATURES', 'Out_Of_Scope#USABILITY']"],"metadata":{"id":"auaXEPadCkzQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["obj =[]\n","aspect= []\n","for i in l:\n","    check = i.split(\"#\")\n","    if check[0] not in obj:\n","        obj.append(check[0]) \n","    if check[1] not in aspect:\n","        aspect.append(check[1]) "],"metadata":{"id":"qjggXwnfK7nj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(obj)\n","print(aspect)"],"metadata":{"id":"xmvfAlf-Dl47"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Implicit/Explicit Test set"],"metadata":{"id":"BWeNjY13jF5C"}},{"cell_type":"code","source":["import json\n","def IEPartitioner(path):\n","    base = json.loads(open(path, \"r\").read())\n","    IAIO = []\n","    IAEO = []\n","    EAIO = []\n","    EAEO = []\n","    IAIO_template = {}\n","    IAEO_template = {}\n","    EAIO_template = {}\n","    EAEO_template = {}\n","    for i in base:\n","        IAIO_template = i.copy()\n","        IAEO_template = i.copy()\n","        EAIO_template = i.copy()\n","        EAEO_template = i.copy()\n","        IAIO_template[\"aspects\"],IAIO_template[\"opinions\"] = [],[]\n","        IAEO_template[\"aspects\"],IAEO_template[\"opinions\"] = [],[]\n","        EAIO_template[\"aspects\"],EAIO_template[\"opinions\"] = [],[]\n","        EAEO_template[\"aspects\"],EAEO_template[\"opinions\"] = [],[]\n","        for k in range(0,len(i[\"aspects\"])):\n","            if i[\"aspects\"][k][\"from\"]==0:\n","                if i[\"opinions\"][k][\"from\"]==0:\n","                    IAIO_template[\"aspects\"].append(i[\"aspects\"][k])\n","                    IAIO_template[\"opinions\"].append(i[\"opinions\"][k])\n","                else:\n","                    IAEO_template[\"aspects\"].append(i[\"aspects\"][k])\n","                    IAEO_template[\"opinions\"].append(i[\"opinions\"][k])\n","            else:\n","                if i[\"opinions\"][k][\"from\"]==0:\n","                    EAIO_template[\"aspects\"].append(i[\"aspects\"][k])\n","                    EAIO_template[\"opinions\"].append(i[\"opinions\"][k])\n","                else:\n","                    EAEO_template[\"aspects\"].append(i[\"aspects\"][k])\n","                    EAEO_template[\"opinions\"].append(i[\"opinions\"][k])\n","        if(len(IAIO_template[\"aspects\"])>0):\n","            IAIO.append(IAIO_template.copy())\n","        if(len(IAEO_template[\"aspects\"])>0):\n","            IAEO.append(IAEO_template.copy())\n","        if(len(EAIO_template[\"aspects\"])>0):\n","            EAIO.append(EAIO_template.copy())\n","        if(len(EAEO_template[\"aspects\"])>0):\n","            EAEO.append(EAEO_template.copy())  \n","        IAIO_template = {}\n","        IAEO_template = {}\n","        EAIO_template = {}\n","        EAEO_template = {}\n","    return json.dumps(IAIO),json.dumps(IAEO),json.dumps(EAIO),json.dumps(EAEO)\n","IAIO,IAEO,EAIO,EAEO = IEPartitioner(\"/content/drive/MyDrive/Sentiment Analysis/data/Restaurant-ACOS/json/test_convert.json\")"],"metadata":{"id":"nbIobibajFQF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["with open(\"/content/drive/MyDrive/Sentiment Analysis/data/Restaurant-ACOS/json/Implicit Explicit/IAIO.json\", \"w\") as outfile:\n","    outfile.write(IAIO)\n","with open(\"/content/drive/MyDrive/Sentiment Analysis/data/Restaurant-ACOS/json/Implicit Explicit/IAEO.json\", \"w\") as outfile:\n","    outfile.write(IAEO)\n","with open(\"/content/drive/MyDrive/Sentiment Analysis/data/Restaurant-ACOS/json/Implicit Explicit/EAIO.json\", \"w\") as outfile:\n","    outfile.write(EAIO)\n","with open(\"/content/drive/MyDrive/Sentiment Analysis/data/Restaurant-ACOS/json/Implicit Explicit/EAEO.json\", \"w\") as outfile:\n","    outfile.write(EAEO)"],"metadata":{"id":"TnA5KZ7asLxD"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Data pipeline"],"metadata":{"id":"dCtAWimziVXR"}},{"cell_type":"code","source":["from fastNLP.io import Pipe, DataBundle, Loader\n","import os\n","import json\n","from fastNLP import DataSet, Instance\n","from transformers import AutoTokenizer\n","import numpy as np\n","from itertools import chain\n","from functools import cmp_to_key\n","\n","\n","def cmp_aspect(v1, v2):\n","    if v1[0]['from']==v2[0]['from']:\n","        return v1[1]['from'] - v2[1]['from']\n","    return v1[0]['from'] - v2[0]['from']\n","\n","def cmp_opinion(v1, v2):\n","    if v1[1]['from']==v2[1]['from']:\n","        return v1[0]['from'] - v2[0]['from']\n","    return v1[1]['from'] - v2[1]['from']\n","\n","\n","class BartBPEABSAPipe(Pipe):\n","    def __init__(self, tokenizer='facebook/bart-base', opinion_first=False):\n","        super(BartBPEABSAPipe, self).__init__()\n","        self.tokenizer = AutoTokenizer.from_pretrained(tokenizer)\n","        self.tokenizer.add_tokens(\"<<null>>\")\n","        self.mapping = restaurant_obj_dict\n","        self.mapping.update(restaurant_catergory_dict)\n","        self.mapping.update({  # so that the label word can be initialized in a better embedding.\n","            'POS': '<<positive>>',\n","            'NEG': '<<negative>>',\n","            'NEU': '<<neutral>>'\n","        })\n","        self.opinion_first = opinion_first  # 是否先生成opinion\n","        cur_num_tokens = self.tokenizer.vocab_size\n","        self.cur_num_token = cur_num_tokens\n","  \n","        tokens_to_add = sorted(list(self.mapping.values()), key=lambda x:len(x), reverse=True)\n","        unique_no_split_tokens = self.tokenizer.unique_no_split_tokens\n","        sorted_add_tokens = sorted(list(tokens_to_add), key=lambda x:len(x), reverse=True)\n","        for tok in sorted_add_tokens:\n","            assert self.tokenizer.convert_tokens_to_ids([tok])[0]==self.tokenizer.unk_token_id\n","        self.tokenizer.unique_no_split_tokens = unique_no_split_tokens + sorted_add_tokens\n","        self.tokenizer.add_tokens(sorted_add_tokens)\n","        \n","        self.mapping2id = {}\n","        self.mapping2targetid = {}\n","\n","        for key, value in self.mapping.items():\n","            key_id = self.tokenizer.convert_tokens_to_ids(self.tokenizer.tokenize(value))\n","            assert len(key_id) == 1, value\n","            assert key_id[0] >= cur_num_tokens\n","            self.mapping2id[key] = key_id[0]\n","            self.mapping2targetid[key] = len(self.mapping2targetid)\n","\n","    def process(self, data_bundle: DataBundle) -> DataBundle:\n","        \"\"\"\n","        words: List[str]\n","        aspects: [{\n","            'index': int\n","            'from': int\n","            'to': int\n","            'polarity': str\n","            'cat_obj':str\n","            'category':str\n","            'term': List[str]\n","        }],\n","        opinions: [{\n","            'index': int\n","            'from': int\n","            'to': int\n","            'term': List[str]\n","        }]\n","        输出为[o_s, o_e, a_s, a_e, c]或者[a_s, a_e, o_s, o_e, c]\n","        :param data_bundle:\n","        :return:\n","        \"\"\"\n","        target_shift = len(self.mapping) + 2  # 是由于第一位是sos，紧接着是eos, 然后是\n","\n","        def prepare_target(ins):\n","            raw_words = ins['raw_words']\n","            word_bpes = [[self.tokenizer.bos_token_id]]\n","            for word in raw_words:\n","                bpes = self.tokenizer.tokenize(word, add_prefix_space=True)\n","                bpes = self.tokenizer.convert_tokens_to_ids(bpes)\n","                word_bpes.append(bpes)\n","            word_bpes.append([self.tokenizer.eos_token_id])\n","\n","            lens = list(map(len, word_bpes))\n","            cum_lens = np.cumsum(list(lens)).tolist()\n","            target = [0]  # 特殊的开始\n","            target_spans = []\n","            _word_bpes = list(chain(*word_bpes))\n","\n","            aspects_opinions = [(a, o) for a, o in zip(ins['aspects'], ins['opinions'])]\n","            if self.opinion_first:\n","                aspects_opinions = sorted(aspects_opinions, key=cmp_to_key(cmp_opinion))\n","            else:\n","                aspects_opinions = sorted(aspects_opinions, key=cmp_to_key(cmp_aspect))\n","\n","            for aspects, opinions in aspects_opinions:  # 预测bpe的start\n","                assert aspects['index'] == opinions['index']\n","                a_start_bpe = cum_lens[aspects['from']]  # 因为有一个sos shift\n","                a_end_bpe = cum_lens[aspects['to']-1]  # 这里由于之前是开区间，刚好取到最后一个word的开头\n","                o_start_bpe = cum_lens[opinions['from']]  # 因为有一个sos shift\n","                o_end_bpe = cum_lens[opinions['to']-1]  # 因为有一个sos shift\n","                # 这里需要evaluate是否是对齐的\n","                for idx, word in zip((o_start_bpe, o_end_bpe, a_start_bpe, a_end_bpe),\n","                                     (opinions['term'][0], opinions['term'][-1], aspects['term'][0], aspects['term'][-1])):\n","                    assert _word_bpes[idx] == self.tokenizer.convert_tokens_to_ids(self.tokenizer.tokenize(word, add_prefix_space=True)[:1])[0] or \\\n","                           _word_bpes[idx] == self.tokenizer.convert_tokens_to_ids(self.tokenizer.tokenize(word, add_prefix_space=True)[-1:])[0]\n","\n","                if self.opinion_first:\n","                    target_spans.append([o_start_bpe+target_shift, o_end_bpe+target_shift,\n","                                         a_start_bpe+target_shift, a_end_bpe+target_shift,\n","                                         self.mapping2targetid[aspects['cat_obj']]+2,\n","                                         self.mapping2targetid[aspects['category']]+2])\n","                else:\n","                    target_spans.append([a_start_bpe+target_shift, a_end_bpe+target_shift,\n","                                         self.mapping2targetid[aspects['cat_obj']]+2,\n","                                         self.mapping2targetid[aspects['category']]+2,\n","                                         o_start_bpe+target_shift, o_end_bpe+target_shift])\n","                target_spans[-1].append(self.mapping2targetid[aspects['polarity']]+2)   # 前面有sos和eos\n","                target_spans[-1] = tuple(target_spans[-1])\n","            target.extend(list(chain(*target_spans)))\n","            target.append(1)  # append 1是由于特殊的eos\n","\n","            return {'tgt_tokens': target, 'target_span': target_spans, 'src_tokens': list(chain(*word_bpes))}\n","\n","        data_bundle.apply_more(prepare_target, use_tqdm=True, tqdm_desc='Pre. tgt.')\n","\n","        data_bundle.set_ignore_type('target_span')\n","        data_bundle.set_pad_val('tgt_tokens', 1)  # 设置为eos所在的id\n","        data_bundle.set_pad_val('src_tokens', self.tokenizer.pad_token_id)\n","\n","        data_bundle.apply_field(lambda x: len(x), field_name='src_tokens', new_field_name='src_seq_len')\n","        data_bundle.apply_field(lambda x: len(x), field_name='tgt_tokens', new_field_name='tgt_seq_len')\n","        data_bundle.set_input('tgt_tokens', 'src_tokens', 'src_seq_len', 'tgt_seq_len')\n","        data_bundle.set_target('tgt_tokens', 'tgt_seq_len', 'target_span')\n","\n","        return data_bundle\n","\n","    def process_from_file(self, paths, demo=False) -> DataBundle:\n","        \"\"\"\n","        :param paths: 支持路径类型参见 :class:`fastNLP.io.loader.ConllLoader` 的load函数。\n","        :return: DataBundle\n","        \"\"\"\n","        # 读取数据\n","        data_bundle = ABSALoader(demo=demo).load(paths)\n","        data_bundle = self.process(data_bundle)\n","\n","        return data_bundle\n","\n","\n","class ABSALoader(Loader):\n","    def __init__(self, demo=False):\n","        super().__init__()\n","        self.demo = demo\n","\n","    def _load(self, path):\n","        with open(path, 'r', encoding='utf-8') as f:\n","            data = json.load(f)\n","        ds = DataSet()\n","        for ins in data:\n","            tokens = ins['words']\n","            aspects = ins['aspects']\n","            opinions = ins['opinions']\n","            assert len(aspects)==len(opinions)\n","            ins = Instance(raw_words=tokens, aspects=aspects, opinions=opinions)\n","            ds.append(ins)\n","            if self.demo and len(ds)>30:\n","                break\n","        return ds\n","\n"],"metadata":{"id":"Z3rcZPOhhJKB"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# BART code"],"metadata":{"id":"HcuQh7sVUPq5"}},{"cell_type":"code","source":["# Copyright 2020 The Facebook AI Research Team Authors and The HuggingFace Inc. team.\n","#\n","# Licensed under the Apache License, Version 2.0 (the \"License\");\n","# you may not use this file except in compliance with the License.\n","# You may obtain a copy of the License at\n","#\n","#     http://www.apache.org/licenses/LICENSE-2.0\n","#\n","# Unless required by applicable law or agreed to in writing, software\n","# distributed under the License is distributed on an \"AS IS\" BASIS,\n","# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","# See the License for the specific language governing permissions and\n","# limitations under the License.\n","\"\"\"PyTorch BART model, ported from the fairseq repo.\"\"\"\n","import math\n","import random\n","import warnings\n","from typing import Dict, List, Optional, Tuple\n","\n","import numpy as np\n","import torch\n","import torch.nn.functional as F\n","from torch import Tensor, nn\n","from torch.nn import CrossEntropyLoss\n","\n","from transformers.modeling_bart import *\n","\n","logger = logging.get_logger(__name__)\n","\n","_CONFIG_FOR_DOC = \"BartConfig\"\n","_TOKENIZER_FOR_DOC = \"BartTokenizer\"\n","\n","BART_PRETRAINED_MODEL_ARCHIVE_LIST = [\n","    \"facebook/bart-base\",\n","    \"facebook/bart-large\",\n","    \"facebook/bart-large-mnli\",\n","    \"facebook/bart-large-cnn\",\n","    \"facebook/bart-large-xsum\",\n","    \"facebook/mbart-large-en-ro\",\n","]\n","# This list is incomplete. See all BART models at https://huggingface.co/models?filter=bart\n","\n","\n","BART_START_DOCSTRING = r\"\"\"\n","    This model inherits from :class:`~transformers.PreTrainedModel`. Check the superclass documentation for the generic\n","    methods the library implements for all its model (such as downloading or saving, resizing the input embeddings,\n","    pruning heads etc.)\n","    This model is also a PyTorch `torch.nn.Module <https://pytorch.org/docs/stable/nn.html#torch.nn.Module>`__ subclass.\n","    Use it as a regular PyTorch Module and refer to the PyTorch documentation for all matter related to general\n","    usage and behavior.\n","    Parameters:\n","        config (:class:`~transformers.BartConfig`): Model configuration class with all the parameters of the model.\n","            Initializing with a config file does not load the weights associated with the model, only the configuration.\n","            Check out the :meth:`~transformers.PreTrainedModel.from_pretrained` method to load the model weights.\n","\"\"\"\n","\n","BART_GENERATION_EXAMPLE = r\"\"\"\n","    Summarization example::\n","        >>> from transformers import BartTokenizer, BartForConditionalGeneration, BartConfig\n","        >>> # see ``examples/summarization/bart/run_eval.py`` for a longer example\n","        >>> model = BartForConditionalGeneration.from_pretrained('facebook/bart-large-cnn')\n","        >>> tokenizer = BartTokenizer.from_pretrained('facebook/bart-large-cnn')\n","        >>> ARTICLE_TO_SUMMARIZE = \"My friends are cool but they eat too many carbs.\"\n","        >>> inputs = tokenizer([ARTICLE_TO_SUMMARIZE], max_length=1024, return_tensors='pt')\n","        >>> # Generate Summary\n","        >>> summary_ids = model.generate(inputs['input_ids'], num_beams=4, max_length=5, early_stopping=True)\n","        >>> print([tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=False) for g in summary_ids])\n","\"\"\"\n","\n","BART_INPUTS_DOCSTRING = r\"\"\"\n","    Args:\n","        input_ids (:obj:`torch.LongTensor` of shape :obj:`(batch_size, sequence_length)`):\n","            Indices of input sequence tokens in the vocabulary. Padding will be ignored by default should you provide\n","            it.\n","            Indices can be obtained using :class:`~transformers.BartTokenizer`.\n","            See :meth:`transformers.PreTrainedTokenizer.encode` and\n","            :meth:`transformers.PreTrainedTokenizer.__call__` for details.\n","            `What are input IDs? <../glossary.html#input-ids>`__\n","        attention_mask (:obj:`torch.Tensor` of shape :obj:`(batch_size, sequence_length)`, `optional`):\n","            Mask to avoid performing attention on padding token indices.\n","            Mask values selected in ``[0, 1]``:\n","            - 1 for tokens that are **not masked**,\n","            - 0 for tokens that are **masked**.\n","            `What are attention masks? <../glossary.html#attention-mask>`__\n","        decoder_input_ids (:obj:`torch.LongTensor` of shape :obj:`(batch_size, target_sequence_length)`, `optional`):\n","            Provide for translation and summarization training. By default, the model will create this tensor by\n","            shifting the :obj:`input_ids` to the right, following the paper.\n","        decoder_attention_mask (:obj:`torch.BoolTensor` of shape :obj:`(batch_size, tgt_seq_len)`, `optional`):\n","            Default behavior: generate a tensor that ignores pad tokens in :obj:`decoder_input_ids`. Causal mask will\n","            also be used by default.\n","            If you want to change padding behavior, you should read :func:`modeling_bart._prepare_decoder_inputs` and\n","            modify to your needs. See diagram 1 in `the paper <https://arxiv.org/abs/1910.13461>`__ for more\n","            information on the default strategy.\n","        encoder_outputs (:obj:`tuple(tuple(torch.FloatTensor)`, `optional`):\n","            Tuple consists of (:obj:`last_hidden_state`, `optional`: :obj:`hidden_states`, `optional`: :obj:`attentions`)\n","            :obj:`last_hidden_state` of shape :obj:`(batch_size, sequence_length, hidden_size)`, `optional`) is a\n","            sequence of hidden-states at the output of the last layer of the encoder. Used in the cross-attention of\n","            the decoder.\n","        past_key_values (:obj:`tuple(tuple(torch.FloatTensor))` of length :obj:`config.n_layers` with each tuple having 4 tensors of shape :obj:`(batch_size, num_heads, sequence_length - 1, embed_size_per_head)`):\n","            Contains precomputed key and value hidden-states of the attention blocks. Can be used to speed up decoding.\n","            If :obj:`past_key_values` are used, the user can optionally input only the last\n","            ``decoder_input_ids`` (those that don't have their past key value states given to this model) of shape\n","            :obj:`(batch_size, 1)` instead of all ``decoder_input_ids`` of shape :obj:`(batch_size, sequence_length)`.\n","        use_cache (:obj:`bool`, `optional`):\n","            If set to :obj:`True`, :obj:`past_key_values` key value states are returned and can be used to speed up\n","            decoding (see :obj:`past_key_values`).\n","        output_attentions (:obj:`bool`, `optional`):\n","            Whether or not to return the attentions tensors of all attention layers. See ``attentions`` under returned\n","            tensors for more detail.\n","        output_hidden_states (:obj:`bool`, `optional`):\n","            Whether or not to return the hidden states of all layers. See ``hidden_states`` under returned tensors for\n","            more detail.\n","        return_dict (:obj:`bool`, `optional`):\n","            Whether or not to return a :class:`~transformers.file_utils.ModelOutput` instead of a plain tuple.\n","\"\"\"\n","\n","\n","def invert_mask(attention_mask):\n","    \"\"\"Turns 1->0, 0->1, False->True, True-> False\"\"\"\n","    assert attention_mask.dim() == 2\n","    return attention_mask.eq(0)\n","\n","\n","def _prepare_bart_decoder_inputs(\n","        config, input_ids, decoder_input_ids=None, decoder_padding_mask=None, causal_mask_dtype=torch.float32\n","):\n","    \"\"\"Prepare masks that ignore padding tokens in the decoder and a causal mask for the decoder if\n","    none are provided. This mimics the default behavior in fairseq. To override it pass in masks.\n","    Note: this is not called during generation\n","    \"\"\"\n","    pad_token_id = config.pad_token_id\n","    if decoder_input_ids is None:\n","        decoder_input_ids = shift_tokens_right(input_ids, pad_token_id)\n","    bsz, tgt_len = decoder_input_ids.size()\n","    if decoder_padding_mask is None:\n","        decoder_padding_mask = make_padding_mask(decoder_input_ids, pad_token_id)\n","    else:\n","        decoder_padding_mask = invert_mask(decoder_padding_mask)\n","    if decoder_padding_mask is not None and decoder_padding_mask.shape[1] > 1:\n","        # never mask leading token, even if it is pad\n","        decoder_padding_mask[:, 0] = decoder_padding_mask[:, 1]\n","    tmp = fill_with_neg_inf(torch.zeros(tgt_len, tgt_len))\n","    mask = torch.arange(tmp.size(-1))\n","    tmp.masked_fill_(mask < (mask + 1).view(tmp.size(-1), 1), 0)\n","    causal_mask = tmp.to(dtype=causal_mask_dtype, device=decoder_input_ids.device)\n","    return decoder_input_ids, decoder_padding_mask, causal_mask\n","\n","\n","class PretrainedBartModel(PreTrainedModel):\n","    config_class = BartConfig\n","    base_model_prefix = \"model\"\n","\n","    def _init_weights(self, module):\n","        std = self.config.init_std\n","        if isinstance(module, nn.Linear):\n","            module.weight.data.normal_(mean=0.0, std=std)\n","            if module.bias is not None:\n","                module.bias.data.zero_()\n","        elif isinstance(module, SinusoidalPositionalEmbedding):\n","            pass\n","        elif isinstance(module, nn.Embedding):\n","            module.weight.data.normal_(mean=0.0, std=std)\n","            if module.padding_idx is not None:\n","                module.weight.data[module.padding_idx].zero_()\n","\n","    @property\n","    def dummy_inputs(self):\n","        pad_token = self.config.pad_token_id\n","        input_ids = torch.tensor([[0, 6, 10, 4, 2], [0, 8, 12, 2, pad_token]], device=self.device)\n","        dummy_inputs = {\n","            \"attention_mask\": input_ids.ne(pad_token),\n","            \"input_ids\": input_ids,\n","        }\n","        return dummy_inputs\n","\n","\n","def _make_linear_from_emb(emb):\n","    vocab_size, emb_size = emb.weight.shape\n","    lin_layer = nn.Linear(vocab_size, emb_size, bias=False)\n","    lin_layer.weight.data = emb.weight.data\n","    return lin_layer\n","\n","\n","# Helper Functions, mostly for making masks\n","def _check_shapes(shape_1, shape2):\n","    if shape_1 != shape2:\n","        raise AssertionError(\"shape mismatch: {} != {}\".format(shape_1, shape2))\n","\n","\n","def shift_tokens_right(input_ids, pad_token_id):\n","    \"\"\"Shift input ids one token to the right, and wrap the last non pad token (usually <eos>).\"\"\"\n","    prev_output_tokens = input_ids.clone()\n","    index_of_eos = (input_ids.ne(pad_token_id).sum(dim=1) - 1).unsqueeze(-1)\n","    prev_output_tokens[:, 0] = input_ids.gather(1, index_of_eos).squeeze()\n","    prev_output_tokens[:, 1:] = input_ids[:, :-1]\n","    return prev_output_tokens\n","\n","\n","def make_padding_mask(input_ids, padding_idx=1):\n","    \"\"\"True for pad tokens\"\"\"\n","    padding_mask = input_ids.eq(padding_idx)\n","    if not padding_mask.any():\n","        padding_mask = None\n","    return padding_mask\n","\n","\n","# Helper Modules\n","\n","\n","class EncoderLayer(nn.Module):\n","    def __init__(self, config: BartConfig):\n","        super().__init__()\n","        self.embed_dim = config.d_model\n","        self.self_attn = Attention(self.embed_dim, config.encoder_attention_heads, dropout=config.attention_dropout)\n","        self.normalize_before = config.normalize_before\n","        self.self_attn_layer_norm = LayerNorm(self.embed_dim)\n","        self.dropout = config.dropout\n","        self.activation_fn = ACT2FN[config.activation_function]\n","        self.activation_dropout = config.activation_dropout\n","        self.fc1 = nn.Linear(self.embed_dim, config.encoder_ffn_dim)\n","        self.fc2 = nn.Linear(config.encoder_ffn_dim, self.embed_dim)\n","        self.final_layer_norm = LayerNorm(self.embed_dim)\n","\n","    def forward(self, x, encoder_padding_mask, output_attentions=False):\n","        \"\"\"\n","        Args:\n","            x (Tensor): input to the layer of shape `(seq_len, batch, embed_dim)`\n","            encoder_padding_mask (ByteTensor): binary ByteTensor of shape\n","                `(batch, src_len)` where padding elements are indicated by ``1``.\n","            for t_tgt, t_src is excluded (or masked out), =0 means it is\n","            included in attention\n","        Returns:\n","            encoded output of shape `(seq_len, batch, embed_dim)`\n","        \"\"\"\n","        residual = x\n","        if self.normalize_before:\n","            x = self.self_attn_layer_norm(x)\n","        x, attn_weights = self.self_attn(\n","            query=x, key=x, key_padding_mask=encoder_padding_mask, output_attentions=output_attentions\n","        )\n","        x = F.dropout(x, p=self.dropout, training=self.training)\n","        x = residual + x\n","        if not self.normalize_before:\n","            x = self.self_attn_layer_norm(x)\n","\n","        residual = x\n","        if self.normalize_before:\n","            x = self.final_layer_norm(x)\n","        x = self.activation_fn(self.fc1(x))\n","        x = F.dropout(x, p=self.activation_dropout, training=self.training)\n","        x = self.fc2(x)\n","        x = F.dropout(x, p=self.dropout, training=self.training)\n","        x = residual + x\n","        if not self.normalize_before:\n","            x = self.final_layer_norm(x)\n","        if torch.isinf(x).any() or torch.isnan(x).any():\n","            clamp_value = torch.finfo(x.dtype).max - 1000\n","            x = torch.clamp(x, min=-clamp_value, max=clamp_value)\n","        return x, attn_weights\n","\n","\n","class BartEncoder(nn.Module):\n","    \"\"\"\n","    Transformer encoder consisting of *config.encoder_layers* self attention layers. Each layer\n","    is a :class:`EncoderLayer`.\n","    Args:\n","        config: BartConfig\n","    \"\"\"\n","\n","    def __init__(self, config: BartConfig, embed_tokens):\n","        super().__init__()\n","\n","        self.dropout = config.dropout\n","        self.layerdrop = config.encoder_layerdrop\n","\n","        embed_dim = embed_tokens.embedding_dim\n","        self.embed_scale = math.sqrt(embed_dim) if config.scale_embedding else 1.0\n","        self.padding_idx = embed_tokens.padding_idx\n","        self.max_source_positions = config.max_position_embeddings\n","\n","        self.embed_tokens = embed_tokens\n","        if config.static_position_embeddings:\n","            self.embed_positions = SinusoidalPositionalEmbedding(\n","                config.max_position_embeddings, embed_dim, self.padding_idx\n","            )\n","        else:\n","            self.embed_positions = LearnedPositionalEmbedding(\n","                config.max_position_embeddings,\n","                embed_dim,\n","                self.padding_idx,\n","                config.extra_pos_embeddings,\n","            )\n","        self.layers = nn.ModuleList([EncoderLayer(config) for _ in range(config.encoder_layers)])\n","        self.layernorm_embedding = LayerNorm(embed_dim) if config.normalize_embedding else nn.Identity()\n","        # mbart has one extra layer_norm\n","        self.layer_norm = LayerNorm(config.d_model) if config.add_final_layer_norm else None\n","\n","    def forward(\n","            self, input_ids, attention_mask=None, output_attentions=False, output_hidden_states=False, return_dict=False\n","    ):\n","        \"\"\"\n","        Args:\n","            input_ids (LongTensor): tokens in the source language of shape\n","                `(batch, src_len)`\n","            attention_mask (torch.LongTensor): indicating which indices are padding tokens.\n","        Returns:\n","            BaseModelOutput or Tuple comprised of:\n","                - **x** (Tensor): the last encoder layer's output of\n","                  shape `(src_len, batch, embed_dim)`\n","                - **encoder_states** (tuple(torch.FloatTensor)): all intermediate\n","                  hidden states of shape `(src_len, batch, embed_dim)`.\n","                  Only populated if *output_hidden_states:* is True.\n","                - **all_attentions** (tuple(torch.FloatTensor)): Attention weights for each layer.\n","                During training might not be of length n_layers because of layer dropout.\n","        \"\"\"\n","        # check attention mask and invert\n","        if attention_mask is not None:\n","            attention_mask = invert_mask(attention_mask)\n","\n","        inputs_embeds = self.embed_tokens(input_ids) * self.embed_scale\n","        embed_pos = self.embed_positions(input_ids)\n","        x = inputs_embeds + embed_pos\n","        x = self.layernorm_embedding(x)\n","        x = F.dropout(x, p=self.dropout, training=self.training)\n","\n","        # B x T x C -> T x B x C\n","        x = x.transpose(0, 1)\n","\n","        encoder_states = [] if output_hidden_states else None\n","        all_attentions = () if output_attentions else None\n","        for encoder_layer in self.layers:\n","            if output_hidden_states:\n","                encoder_states.append(x)\n","            # add LayerDrop (see https://arxiv.org/abs/1909.11556 for description)\n","            dropout_probability = random.uniform(0, 1)\n","            if self.training and (dropout_probability < self.layerdrop):  # skip the layer\n","                attn = None\n","            else:\n","                x, attn = encoder_layer(x, attention_mask, output_attentions=output_attentions)\n","\n","            if output_attentions:\n","                all_attentions = all_attentions + (attn,)\n","\n","        if self.layer_norm:\n","            x = self.layer_norm(x)\n","        if output_hidden_states:\n","            encoder_states.append(x)\n","            # T x B x C -> B x T x C\n","            encoder_states = tuple(hidden_state.transpose(0, 1) for hidden_state in encoder_states)\n","\n","        # T x B x C -> B x T x C\n","        x = x.transpose(0, 1)\n","\n","        if not return_dict:\n","            return tuple(v for v in [x, encoder_states, all_attentions] if v is not None)\n","        return BaseModelOutput(last_hidden_state=x, hidden_states=encoder_states, attentions=all_attentions)\n","\n","\n","class DecoderLayer(nn.Module):\n","    def __init__(self, config: BartConfig):\n","        super().__init__()\n","        self.embed_dim = config.d_model\n","\n","        self.self_attn = Attention(\n","            embed_dim=self.embed_dim,\n","            num_heads=config.decoder_attention_heads,\n","            dropout=config.attention_dropout,\n","        )\n","        self.dropout = config.dropout\n","        self.activation_fn = ACT2FN[config.activation_function]\n","        self.activation_dropout = config.activation_dropout\n","        self.normalize_before = config.normalize_before\n","\n","        self.self_attn_layer_norm = LayerNorm(self.embed_dim)\n","        self.encoder_attn = Attention(\n","            self.embed_dim,\n","            config.decoder_attention_heads,\n","            dropout=config.attention_dropout,\n","            encoder_decoder_attention=True,\n","        )\n","        self.encoder_attn_layer_norm = LayerNorm(self.embed_dim)\n","        self.fc1 = nn.Linear(self.embed_dim, config.decoder_ffn_dim)\n","        self.fc2 = nn.Linear(config.decoder_ffn_dim, self.embed_dim)\n","        self.final_layer_norm = LayerNorm(self.embed_dim)\n","\n","    def forward(\n","            self,\n","            x,\n","            encoder_hidden_states,\n","            encoder_attn_mask=None,\n","            layer_state=None,\n","            causal_mask=None,\n","            decoder_padding_mask=None,\n","            output_attentions=False,\n","    ):\n","        residual = x\n","\n","        if layer_state is None:\n","            layer_state = {}\n","        if self.normalize_before:\n","            x = self.self_attn_layer_norm(x)\n","        # Self Attention\n","\n","        x, self_attn_weights = self.self_attn(\n","            query=x,\n","            key=x,\n","            layer_state=layer_state,  # adds keys to layer state\n","            key_padding_mask=decoder_padding_mask,\n","            attn_mask=causal_mask,\n","            output_attentions=output_attentions,\n","        )\n","        x = F.dropout(x, p=self.dropout, training=self.training)\n","        x = residual + x\n","        if not self.normalize_before:\n","            x = self.self_attn_layer_norm(x)\n","\n","        # Cross attention\n","        residual = x\n","        assert self.encoder_attn.cache_key != self.self_attn.cache_key\n","        if self.normalize_before:\n","            x = self.encoder_attn_layer_norm(x)\n","        x, _ = self.encoder_attn(\n","            query=x,\n","            key=encoder_hidden_states,\n","            key_padding_mask=encoder_attn_mask,\n","            layer_state=layer_state,  # mutates layer state\n","        )\n","        x = F.dropout(x, p=self.dropout, training=self.training)\n","        x = residual + x\n","        if not self.normalize_before:\n","            x = self.encoder_attn_layer_norm(x)\n","\n","        # Fully Connected\n","        residual = x\n","        if self.normalize_before:\n","            x = self.final_layer_norm(x)\n","        x = self.activation_fn(self.fc1(x))\n","        x = F.dropout(x, p=self.activation_dropout, training=self.training)\n","        x = self.fc2(x)\n","        x = F.dropout(x, p=self.dropout, training=self.training)\n","        x = residual + x\n","        if not self.normalize_before:\n","            x = self.final_layer_norm(x)\n","        return (\n","            x,\n","            self_attn_weights,\n","            layer_state,\n","        )  # just self_attn weights for now, following t5, layer_state = cache for decoding\n","\n","\n","class BartDecoder(nn.Module):\n","    \"\"\"\n","    Transformer decoder consisting of *config.decoder_layers* layers. Each layer\n","    is a :class:`DecoderLayer`.\n","    Args:\n","        config: BartConfig\n","        embed_tokens (torch.nn.Embedding): output embedding\n","    \"\"\"\n","\n","    def __init__(self, config: BartConfig, embed_tokens: nn.Embedding):\n","        super().__init__()\n","        self.dropout = config.dropout\n","        self.layerdrop = config.decoder_layerdrop\n","        self.do_blenderbot_90_layernorm = config.do_blenderbot_90_layernorm  # layernorm variant\n","        self.padding_idx = embed_tokens.padding_idx\n","        self.max_target_positions = config.max_position_embeddings\n","        self.embed_scale = math.sqrt(config.d_model) if config.scale_embedding else 1.0\n","        self.embed_tokens = embed_tokens\n","        if config.static_position_embeddings:\n","            self.embed_positions = SinusoidalPositionalEmbedding(\n","                config.max_position_embeddings, config.d_model, config.pad_token_id\n","            )\n","        else:\n","            self.embed_positions = LearnedPositionalEmbedding(\n","                config.max_position_embeddings,\n","                config.d_model,\n","                self.padding_idx,\n","                config.extra_pos_embeddings\n","            )\n","        self.layers = nn.ModuleList(\n","            [DecoderLayer(config) for _ in range(config.decoder_layers)]\n","        )  # type: List[DecoderLayer]\n","        self.layernorm_embedding = LayerNorm(config.d_model) if config.normalize_embedding else nn.Identity()\n","        self.layer_norm = LayerNorm(config.d_model) if config.add_final_layer_norm else None\n","        self.config = config\n","\n","    def set_position_embedding(self, special_tag_start_id, tag_first=True):\n","        if tag_first:\n","            embed_positions = DecoderLearnedPositionalEmbedding(\n","                self.config.max_position_embeddings,\n","                self.config.d_model,\n","                self.padding_idx,\n","                self.config.extra_pos_embeddings,\n","                special_tag_start_id\n","            )\n","        else:\n","            embed_positions = DecoderLearnedPositionalEmbedding2(\n","                self.config.max_position_embeddings,\n","                self.config.d_model,\n","                self.padding_idx,\n","                self.config.extra_pos_embeddings,\n","                special_tag_start_id\n","            )\n","\n","        embed_positions.weight.data = self.embed_positions.weight.data\n","        self.embed_positions = embed_positions\n","\n","    def forward(\n","            self,\n","            input_ids,\n","            encoder_hidden_states,\n","            encoder_padding_mask,\n","            decoder_padding_mask,\n","            decoder_causal_mask,\n","            past_key_values=None,\n","            use_cache=False,\n","            output_attentions=False,\n","            output_hidden_states=False,\n","            return_dict=False,\n","            use_pos_cache=False,\n","            **unused,\n","    ):\n","        \"\"\"\n","        Includes several features from \"Jointly Learning to Align and\n","        Translate with Transformer Models\" (Garg et al., EMNLP 2019).\n","        Args:\n","            input_ids (LongTensor): previous decoder outputs of shape\n","                `(batch, tgt_len)`, for teacher forcing\n","            encoder_hidden_states: output from the encoder, used for\n","                encoder-side attention\n","            encoder_padding_mask: for ignoring pad tokens\n","            past_key_values (dict or None): dictionary used for storing state during generation\n","        Returns:\n","            BaseModelOutputWithPast or tuple:\n","                - the decoder's features of shape `(batch, tgt_len, embed_dim)`\n","                - the cache\n","                - hidden states\n","                - attentions\n","        \"\"\"\n","        if \"decoder_cached_states\" in unused:\n","            warnings.warn(\n","                \"The `decoder_cached_states` argument is deprecated and will be removed in a future version, use `past_key_values` instead.\",\n","                FutureWarning,\n","            )\n","            past_key_values = unused.pop(\"decoder_cached_states\")\n","        if \"decoder_past_key_values\" in unused:\n","            warnings.warn(\n","                \"The `decoder_past_key_values` argument is deprecated and will be removed in a future version, use `past_key_values` instead.\",\n","                FutureWarning,\n","            )\n","            past_key_values = unused.pop(\"decoder_past_key_values\")\n","\n","        # check attention mask and invert\n","        if encoder_padding_mask is not None:\n","            encoder_padding_mask = invert_mask(encoder_padding_mask)\n","\n","        # embed positions\n","        positions = self.embed_positions(input_ids, use_cache=use_pos_cache)\n","\n","        if use_pos_cache:\n","            input_ids = input_ids[:, -1:]\n","            positions = positions[:, -1:]\n","\n","        x = self.embed_tokens(input_ids) * self.embed_scale\n","        if self.do_blenderbot_90_layernorm:\n","            x = self.layernorm_embedding(x)\n","            x += positions\n","        else:\n","            x += positions\n","            x = self.layernorm_embedding(x)\n","\n","        x = F.dropout(x, p=self.dropout, training=self.training)\n","\n","        # Convert to Bart output format: (seq_len, BS, model_dim) -> (BS, seq_len, model_dim)\n","        x = x.transpose(0, 1)\n","        encoder_hidden_states = encoder_hidden_states.transpose(0, 1)\n","\n","        # decoder layers\n","        all_hidden_states = () if output_hidden_states else None\n","        all_self_attns = () if output_attentions else None\n","        next_decoder_cache = []\n","        for idx, decoder_layer in enumerate(self.layers):\n","            # add LayerDrop (see https://arxiv.org/abs/1909.11556 for description)\n","            if output_hidden_states:\n","                all_hidden_states += (x,)\n","            dropout_probability = random.uniform(0, 1)\n","            if self.training and (dropout_probability < self.layerdrop):\n","                continue\n","\n","            layer_state = past_key_values[idx] if past_key_values is not None else None\n","\n","            x, layer_self_attn, layer_past = decoder_layer(\n","                x,\n","                encoder_hidden_states,\n","                encoder_attn_mask=encoder_padding_mask,\n","                decoder_padding_mask=decoder_padding_mask,\n","                layer_state=layer_state,\n","                causal_mask=decoder_causal_mask,\n","                output_attentions=output_attentions,\n","            )\n","\n","            if use_cache:\n","                next_decoder_cache.append(layer_past.copy())\n","\n","            if output_attentions:\n","                all_self_attns += (layer_self_attn,)\n","\n","        if self.layer_norm:  # if config.add_final_layer_norm (mBART)\n","            x = self.layer_norm(x)\n","\n","        # Convert to standard output format: (seq_len, BS, model_dim) -> (BS, seq_len, model_dim)\n","        if output_hidden_states:\n","            all_hidden_states = tuple(hidden_state.transpose(0, 1) for hidden_state in all_hidden_states)\n","        x = x.transpose(0, 1)\n","        encoder_hidden_states = encoder_hidden_states.transpose(0, 1)\n","\n","        next_cache = next_decoder_cache if use_cache else None\n","\n","        if not return_dict:\n","            return tuple(v for v in [x, next_cache, all_hidden_states, all_self_attns] if v is not None)\n","        return BaseModelOutputWithPast(\n","            last_hidden_state=x, past_key_values=next_cache, hidden_states=all_hidden_states, attentions=all_self_attns\n","        )\n","\n","\n","def _reorder_buffer(attn_cache, new_order):\n","    for k, input_buffer_k in attn_cache.items():\n","        if input_buffer_k is not None:\n","            attn_cache[k] = input_buffer_k.index_select(0, new_order)\n","    return attn_cache\n","\n","\n","class Attention(nn.Module):\n","    \"\"\"Multi-headed attention from 'Attention Is All You Need' paper\"\"\"\n","\n","    def __init__(\n","            self,\n","            embed_dim,\n","            num_heads,\n","            dropout=0.0,\n","            bias=True,\n","            encoder_decoder_attention=False,  # otherwise self_attention\n","    ):\n","        super().__init__()\n","        self.embed_dim = embed_dim\n","        self.num_heads = num_heads\n","        self.dropout = dropout\n","        self.head_dim = embed_dim // num_heads\n","        assert self.head_dim * num_heads == self.embed_dim, \"embed_dim must be divisible by num_heads\"\n","        self.scaling = self.head_dim ** -0.5\n","\n","        self.encoder_decoder_attention = encoder_decoder_attention\n","        self.k_proj = nn.Linear(embed_dim, embed_dim, bias=bias)\n","        self.v_proj = nn.Linear(embed_dim, embed_dim, bias=bias)\n","        self.q_proj = nn.Linear(embed_dim, embed_dim, bias=bias)\n","        self.out_proj = nn.Linear(embed_dim, embed_dim, bias=bias)\n","        self.cache_key = \"encoder_decoder\" if self.encoder_decoder_attention else \"self\"\n","\n","    def _shape(self, tensor, seq_len, bsz):\n","        return tensor.contiguous().view(seq_len, bsz * self.num_heads, self.head_dim).transpose(0, 1)\n","\n","    def forward(\n","            self,\n","            query,\n","            key: Optional[Tensor],\n","            key_padding_mask: Optional[Tensor] = None,\n","            layer_state: Optional[Dict[str, Optional[Tensor]]] = None,\n","            attn_mask: Optional[Tensor] = None,\n","            output_attentions=False,\n","    ) -> Tuple[Tensor, Optional[Tensor]]:\n","        \"\"\"Input shape: Time(SeqLen) x Batch x Channel\"\"\"\n","        static_kv: bool = self.encoder_decoder_attention\n","        tgt_len, bsz, embed_dim = query.size()\n","        assert embed_dim == self.embed_dim\n","        assert list(query.size()) == [tgt_len, bsz, embed_dim]\n","        # get here for encoder decoder cause of static_kv\n","        if layer_state is not None:  # reuse k,v and encoder_padding_mask\n","            saved_state = layer_state.get(self.cache_key, {})\n","            if \"prev_key\" in saved_state and static_kv:\n","                # previous time steps are cached - no need to recompute key and value if they are static\n","                key = None\n","        else:\n","            saved_state = None\n","            layer_state = {}\n","\n","        q = self.q_proj(query) * self.scaling\n","        if static_kv:\n","            if key is None:\n","                k = v = None\n","            else:\n","                k = self.k_proj(key)\n","                v = self.v_proj(key)\n","        else:\n","            k = self.k_proj(query)\n","            v = self.v_proj(query)\n","\n","        q = self._shape(q, tgt_len, bsz)\n","        if k is not None:\n","            k = self._shape(k, -1, bsz)\n","        if v is not None:\n","            v = self._shape(v, -1, bsz)\n","        if saved_state is not None:\n","            k, v, key_padding_mask = self._use_saved_state(k, v, saved_state, key_padding_mask, static_kv, bsz)\n","        # Update cache\n","        layer_state[self.cache_key] = {\n","            \"prev_key\": k.view(bsz, self.num_heads, -1, self.head_dim),\n","            \"prev_value\": v.view(bsz, self.num_heads, -1, self.head_dim),\n","            \"prev_key_padding_mask\": key_padding_mask if not static_kv else None,\n","        }\n","\n","        assert k is not None\n","        src_len = k.size(1)\n","        attn_weights = torch.bmm(q, k.transpose(1, 2))\n","        assert attn_weights.size() == (bsz * self.num_heads, tgt_len, src_len)\n","\n","        if attn_mask is not None:\n","            attn_weights = attn_weights.view(bsz, self.num_heads, tgt_len, src_len) + attn_mask\n","            attn_weights = attn_weights.view(bsz * self.num_heads, tgt_len, src_len)\n","\n","        # This is part of a workaround to get around fork/join parallelism not supporting Optional types.\n","        if key_padding_mask is not None and key_padding_mask.dim() == 0:\n","            key_padding_mask = None\n","        assert key_padding_mask is None or key_padding_mask.size()[:2] == (\n","            bsz,\n","            src_len,\n","        )\n","\n","        if key_padding_mask is not None:  # don't attend to padding symbols\n","            attn_weights = attn_weights.view(bsz, self.num_heads, tgt_len, src_len)\n","            reshaped = key_padding_mask.unsqueeze(1).unsqueeze(2)\n","            attn_weights = attn_weights.masked_fill(reshaped, float(\"-inf\"))\n","            attn_weights = attn_weights.view(bsz * self.num_heads, tgt_len, src_len)\n","        attn_weights = F.softmax(attn_weights, dim=-1)\n","        attn_probs = F.dropout(\n","            attn_weights,\n","            p=self.dropout,\n","            training=self.training,\n","        )\n","\n","        assert v is not None\n","        attn_output = torch.bmm(attn_probs, v)\n","        assert attn_output.size() == (bsz * self.num_heads, tgt_len, self.head_dim)\n","        attn_output = attn_output.transpose(0, 1).contiguous().view(tgt_len, bsz, embed_dim)\n","        attn_output = self.out_proj(attn_output)\n","        if output_attentions:\n","            attn_weights = attn_weights.view(bsz, self.num_heads, tgt_len, src_len)\n","        else:\n","            attn_weights = None\n","        return attn_output, attn_weights\n","\n","    def _use_saved_state(self, k, v, saved_state, key_padding_mask, static_kv, bsz):\n","        # saved states are stored with shape (bsz, num_heads, seq_len, head_dim)\n","        if \"prev_key\" in saved_state:\n","            _prev_key = saved_state[\"prev_key\"]\n","            assert _prev_key is not None\n","            prev_key = _prev_key.view(bsz * self.num_heads, -1, self.head_dim)\n","            if static_kv:\n","                k = prev_key\n","            else:\n","                assert k is not None\n","                k = torch.cat([prev_key, k], dim=1)\n","        if \"prev_value\" in saved_state:\n","            _prev_value = saved_state[\"prev_value\"]\n","            assert _prev_value is not None\n","            prev_value = _prev_value.view(bsz * self.num_heads, -1, self.head_dim)\n","            if static_kv:\n","                v = prev_value\n","            else:\n","                assert v is not None\n","                v = torch.cat([prev_value, v], dim=1)\n","        assert k is not None and v is not None\n","        prev_key_padding_mask: Optional[Tensor] = saved_state.get(\"prev_key_padding_mask\", None)\n","        if prev_key_padding_mask is not None:\n","            if static_kv:\n","                new_key_padding_mask = prev_key_padding_mask\n","            else:\n","                new_key_padding_mask = torch.cat([prev_key_padding_mask, key_padding_mask], dim=1)\n","        else:\n","            new_key_padding_mask = key_padding_mask\n","        return k, v, new_key_padding_mask\n","\n","\n","class BartClassificationHead(nn.Module):\n","    \"\"\"Head for sentence-level classification tasks.\"\"\"\n","\n","    # This can trivially be shared with RobertaClassificationHead\n","\n","    def __init__(\n","            self,\n","            input_dim,\n","            inner_dim,\n","            num_classes,\n","            pooler_dropout,\n","    ):\n","        super().__init__()\n","        self.dense = nn.Linear(input_dim, inner_dim)\n","        self.dropout = nn.Dropout(p=pooler_dropout)\n","        self.out_proj = nn.Linear(inner_dim, num_classes)\n","\n","    def forward(self, x):\n","        x = self.dropout(x)\n","        x = self.dense(x)\n","        x = torch.tanh(x)\n","        x = self.dropout(x)\n","        x = self.out_proj(x)\n","        return x\n","\n","\n","class LearnedPositionalEmbedding(nn.Embedding):\n","    \"\"\"\n","    This module learns positional embeddings up to a fixed maximum size.\n","    Padding ids are ignored by either offsetting based on padding_idx\n","    or by setting padding_idx to None and ensuring that the appropriate\n","    position ids are passed to the forward function.\n","    \"\"\"\n","\n","    def __init__(self, num_embeddings: int, embedding_dim: int, padding_idx: int, offset):\n","        # Bart is set up so that if padding_idx is specified then offset the embedding ids by 2\n","        # and adjust num_embeddings appropriately. Other models dont have this hack\n","        self.offset = offset\n","        assert padding_idx is not None\n","        num_embeddings += offset\n","        super().__init__(num_embeddings, embedding_dim, padding_idx=padding_idx)\n","\n","    def forward(self, input_ids, use_cache=False):\n","        \"\"\"Input is expected to be of size [bsz x seqlen].\"\"\"\n","        bsz, seq_len = input_ids.shape[:2]\n","        if use_cache:\n","            positions = input_ids.data.new(1, 1).fill_(seq_len - 1)  # called before slicing\n","        else:\n","            # starts at 0, ends at 1-seq_len\n","            positions = torch.arange(seq_len, dtype=torch.long, device=self.weight.device)\n","        return super().forward(positions + self.offset)\n","\n","\n","class DecoderLearnedPositionalEmbedding(nn.Embedding):\n","    \"\"\"\n","    主要修改是，position的是循环的\n","    This module learns positional embeddings up to a fixed maximum size.\n","    Padding ids are ignored by either offsetting based on padding_idx\n","    or by setting padding_idx to None and ensuring that the appropriate\n","    position ids are passed to the forward function.\n","    \"\"\"\n","\n","    def __init__(self, num_embeddings: int, embedding_dim: int, padding_idx: int, offset,\n","                 special_tag_start_id=None):\n","        # Bart is set up so that if padding_idx is specified then offset the embedding ids by 2\n","        # and adjust num_embeddings appropriately. Other models dont have this hack\n","        self.offset = offset\n","        assert padding_idx is not None\n","        num_embeddings += offset\n","        self.special_tag_start_id = special_tag_start_id  # 这个id之后的词是特殊词汇\n","        super().__init__(num_embeddings, embedding_dim, padding_idx=padding_idx)\n","\n","    def forward(self, input_ids, use_cache=False):\n","        \"\"\"Input is expected to be of size [bsz x seqlen].\"\"\"\n","        if self.special_tag_start_id is None or input_ids.size(1)<2:\n","            bsz, seq_len = input_ids.shape[:2]\n","            if use_cache:\n","                positions = input_ids.data.new(1, 1).fill_(seq_len - 1)  # called before slicing\n","            else:\n","                # starts at 0, ends at 1-seq_len\n","                positions = torch.arange(seq_len, dtype=torch.long, device=self.weight.device)\n","        else:\n","            # 实现的是每个位置重新开始position\n","            \"\"\"\n","                大概意思是，假设input_ids中假设大于4是特殊符号，那么输入是\n","                [[2, 4, 1, 2, 3, 5, 1],\n","                 [2, 5, 3, 3, 0, 0, 0]]时，输出为\n","                [[0, 1, 2, 3, 4, 1, 2],\n","                 [0, 1, 2, 3, 4, 5, 6] 每个大于4的位置都会重置\n","            \"\"\"\n","            _input_ids = input_ids[:, 1:]\n","            bsz, seq_len = _input_ids.shape[:2]\n","            special_tag_mask = _input_ids.ge(self.special_tag_start_id)  # bsz x max_len\n","            if special_tag_mask.sum()>0:\n","                num_masks = special_tag_mask.cumsum(dim=1).max()  # 表示最长的\n","                arange_indices = torch.arange(seq_len).to(_input_ids).expand_as(_input_ids)  # bsz x max_len\n","                special_tag_indice = arange_indices.masked_select(special_tag_mask)  # a vector只包含所有的special的indice\n","                indices = torch.arange(num_masks).to(_input_ids)[None].repeat(bsz, 1)  # bsz x mask_len\n","                mask = indices.lt(special_tag_mask.sum(dim=1, keepdim=True))\n","                indices = indices.masked_scatter(mask, special_tag_indice)\n","                _, inverted_indices = special_tag_mask.cumsum(dim=-1).unique(return_inverse=True)\n","\n","                inverted_indices = inverted_indices - inverted_indices[:, :1]\n","                inverted_indices = inverted_indices.masked_fill(inverted_indices.ge(indices.size(1)), max(indices.size(1)-1, 0))\n","                positions = indices.gather(index=inverted_indices, dim=1)\n","                positions = (arange_indices - positions) + 1\n","            else:\n","                positions = torch.arange(seq_len+1, dtype=torch.long, device=self.weight.device)[None]\n","\n","            if use_cache:\n","                positions = positions[:, -1:]\n","            else:\n","                positions = torch.cat([input_ids.new_zeros(bsz, 1), positions], dim=1)\n","\n","        return super().forward(positions + self.offset)\n","\n","\n","class DecoderLearnedPositionalEmbedding2(nn.Embedding):\n","    \"\"\"\n","    主要修改是，position的是循环的, 和上面的区别是tag所在的位置不同\n","    This module learns positional embeddings up to a fixed maximum size.\n","    Padding ids are ignored by either offsetting based on padding_idx\n","    or by setting padding_idx to None and ensuring that the appropriate\n","    position ids are passed to the forward function.\n","    \"\"\"\n","\n","    def __init__(self, num_embeddings: int, embedding_dim: int, padding_idx: int, offset,\n","                 special_tag_start_id=None):\n","        # Bart is set up so that if padding_idx is specified then offset the embedding ids by 2\n","        # and adjust num_embeddings appropriately. Other models dont have this hack\n","        self.offset = offset\n","        assert padding_idx is not None\n","        num_embeddings += offset\n","        self.special_tag_start_id = special_tag_start_id  # 这个id之后的词是特殊词汇\n","        super().__init__(num_embeddings, embedding_dim, padding_idx=padding_idx)\n","\n","    def forward(self, input_ids, use_cache=False):\n","        \"\"\"Input is expected to be of size [bsz x seqlen].\"\"\"\n","        if self.special_tag_start_id is None or input_ids.size(1)<2:\n","            bsz, seq_len = input_ids.shape[:2]\n","            if use_cache:\n","                positions = input_ids.data.new(1, 1).fill_(seq_len - 1)  # called before slicing\n","            else:\n","                # starts at 0, ends at 1-seq_len\n","                positions = torch.arange(seq_len, dtype=torch.long, device=self.weight.device)\n","        else:\n","            # 实现的是每个位置重新开始position\n","            \"\"\"\n","                大概意思是，假设input_ids中假设大于4是特殊符号，那么输入是\n","                [[2, 1, 2, 3, 4, 1, 5],\n","                 [2, 3, 3, 5, 0, 0, 0]]时，输出为\n","                [[0, 1, 2, 3, 4, 1, 2],\n","                 [0, 1, 2, 3, 4, 5, 6] 每个大于4的位置都会重置\n","            \"\"\"\n","            _input_ids = input_ids[:, 1:]  # 把sos去掉\n","            bsz, seq_len = _input_ids.shape[:2]\n","            special_tag_mask = _input_ids.ge(self.special_tag_start_id)  # bsz x max_len\n","            if special_tag_mask.sum()>0:\n","                num_masks = special_tag_mask.cumsum(dim=1)  # 表示最长的\n","                num_masks_value = num_masks.max()\n","                arange_indices = torch.arange(seq_len).to(_input_ids).expand_as(_input_ids)  # bsz x max_len\n","\n","                special_tag_indice = arange_indices.masked_select(special_tag_mask)  # a vector只包含所有的special的indice\n","                indices = torch.arange(num_masks_value).to(_input_ids)[None].repeat(bsz, 1)  # bsz x mask_len\n","                mask = indices.lt(special_tag_mask.sum(dim=-1, keepdim=True))\n","                special_tag_indice = indices.masked_scatter(mask, special_tag_indice)\n","\n","                indices = torch.cat([special_tag_indice.new_zeros(bsz, 1), special_tag_indice[:, :-1] + 1], dim=1)\n","                _, inverted_indices = special_tag_mask.flip(dims=[1]).cumsum(dim=-1).flip(dims=[1]).unique(\n","                    return_inverse=True)\n","                values = inverted_indices[:, 0]  # bsz\n","                inverted_indices = values[:, None] - inverted_indices\n","                inverted_indices = inverted_indices.masked_fill(inverted_indices.ge(indices.size(1)), indices.size(1)-1)\n","\n","                positions = indices.gather(index=inverted_indices, dim=1)\n","                positions = arange_indices - positions + 1\n","            else:\n","                positions = torch.arange(seq_len+1, dtype=torch.long, device=self.weight.device)[None]\n","\n","        if use_cache:\n","            positions = positions[:, -1:]\n","        else:\n","            positions = torch.cat([input_ids.new_zeros(bsz, 1), positions], dim=1)\n","\n","        return super().forward(positions + self.offset)\n","\n","\n","def LayerNorm(normalized_shape, eps=1e-5, elementwise_affine=True):\n","    if torch.cuda.is_available():\n","        try:\n","            from apex.normalization import FusedLayerNorm\n","\n","            return FusedLayerNorm(normalized_shape, eps, elementwise_affine)\n","        except ImportError:\n","            pass\n","    return torch.nn.LayerNorm(normalized_shape, eps, elementwise_affine)\n","\n","\n","def fill_with_neg_inf(t):\n","    \"\"\"FP16-compatible function that fills a input_ids with -inf.\"\"\"\n","    return t.float().fill_(float(\"-inf\")).type_as(t)\n","\n","\n","# Public API\n","def _get_shape(t):\n","    return getattr(t, \"shape\", None)\n","\n","\n","class BartModel(PretrainedBartModel):\n","    def __init__(self, config: BartConfig):\n","        super().__init__(config)\n","\n","        padding_idx, vocab_size = config.pad_token_id, config.vocab_size\n","        self.shared = nn.Embedding(vocab_size, config.d_model, padding_idx)\n","\n","        self.encoder = BartEncoder(config, self.shared)\n","        self.decoder = BartDecoder(config, self.shared)\n","\n","        self.init_weights()\n","\n","    \n","    def forward(\n","            self,\n","            input_ids,\n","            attention_mask=None,\n","            decoder_input_ids=None,\n","            decoder_attention_mask=None,\n","            encoder_outputs: Optional[Tuple] = None,\n","            past_key_values=None,\n","            use_cache=None,\n","            output_attentions=None,\n","            output_hidden_states=None,\n","            return_dict=None,\n","            **kwargs,\n","    ):\n","        if \"decoder_past_key_values\" in kwargs:\n","            warnings.warn(\n","                \"The `decoder_past_key_values` argument is deprecated and will be removed in a future version, use `past_key_values` instead.\",\n","                FutureWarning,\n","            )\n","            past_key_values = kwargs.pop(\"decoder_past_key_values\")\n","\n","        if decoder_input_ids is None:\n","            use_cache = False\n","\n","        output_attentions = output_attentions if output_attentions is not None else self.config.output_attentions\n","        output_hidden_states = (\n","            output_hidden_states if output_hidden_states is not None else self.config.output_hidden_states\n","        )\n","        use_cache = use_cache if use_cache is not None else self.config.use_cache\n","        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n","\n","        # make masks if user doesn't supply\n","        if not use_cache:\n","            decoder_input_ids, decoder_padding_mask, causal_mask = _prepare_bart_decoder_inputs(\n","                self.config,\n","                input_ids,\n","                decoder_input_ids=decoder_input_ids,\n","                decoder_padding_mask=decoder_attention_mask,\n","                causal_mask_dtype=self.shared.weight.dtype,\n","            )\n","        else:\n","            decoder_padding_mask, causal_mask = None, None\n","\n","        assert decoder_input_ids is not None\n","\n","        if encoder_outputs is None:\n","            encoder_outputs = self.encoder(\n","                input_ids=input_ids,\n","                attention_mask=attention_mask,\n","                output_attentions=output_attentions,\n","                output_hidden_states=output_hidden_states,\n","                return_dict=return_dict,\n","            )\n","        # If the user passed a tuple for encoder_outputs, we wrap it in a BaseModelOuput when return_dict=False\n","        elif return_dict and not isinstance(encoder_outputs, BaseModelOutput):\n","            encoder_outputs = BaseModelOutput(\n","                last_hidden_state=encoder_outputs[0],\n","                hidden_states=encoder_outputs[1] if len(encoder_outputs) > 1 else None,\n","                attentions=encoder_outputs[2] if len(encoder_outputs) > 2 else None,\n","            )\n","\n","        # decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\n","        decoder_outputs = self.decoder(\n","            decoder_input_ids,\n","            encoder_outputs[0],\n","            attention_mask,\n","            decoder_padding_mask,\n","            decoder_causal_mask=causal_mask,\n","            past_key_values=past_key_values,\n","            use_cache=use_cache,\n","            output_attentions=output_attentions,\n","            output_hidden_states=output_hidden_states,\n","            return_dict=return_dict,\n","        )\n","\n","        if not return_dict:\n","            return decoder_outputs + encoder_outputs\n","\n","        return Seq2SeqModelOutput(\n","            last_hidden_state=decoder_outputs.last_hidden_state,\n","            past_key_values=decoder_outputs.past_key_values,\n","            decoder_hidden_states=decoder_outputs.hidden_states,\n","            decoder_attentions=decoder_outputs.attentions,\n","            encoder_last_hidden_state=encoder_outputs.last_hidden_state,\n","            encoder_hidden_states=encoder_outputs.hidden_states,\n","            encoder_attentions=encoder_outputs.attentions,\n","        )\n","\n","    def get_input_embeddings(self):\n","        return self.shared\n","\n","    def set_input_embeddings(self, value):\n","        self.shared = value\n","        self.encoder.embed_tokens = self.shared\n","        self.decoder.embed_tokens = self.shared\n","\n","    def get_output_embeddings(self):\n","        return _make_linear_from_emb(self.shared)  # make it on the fly\n","\n","\n","\n","class BartForConditionalGeneration(PretrainedBartModel):\n","    base_model_prefix = \"model\"\n","    authorized_missing_keys = [r\"final_logits_bias\", r\"encoder\\.version\", r\"decoder\\.version\"]\n","\n","    def __init__(self, config: BartConfig):\n","        super().__init__(config)\n","        base_model = BartModel(config)\n","        self.model = base_model\n","        self.register_buffer(\"final_logits_bias\", torch.zeros((1, self.model.shared.num_embeddings)))\n","\n","    def resize_token_embeddings(self, new_num_tokens: int) -> nn.Embedding:\n","        old_num_tokens = self.model.shared.num_embeddings\n","        new_embeddings = super().resize_token_embeddings(new_num_tokens)\n","        self.model.shared = new_embeddings\n","        self._resize_final_logits_bias(new_num_tokens, old_num_tokens)\n","        return new_embeddings\n","\n","    def _resize_final_logits_bias(self, new_num_tokens: int, old_num_tokens: int) -> None:\n","        if new_num_tokens <= old_num_tokens:\n","            new_bias = self.final_logits_bias[:, :new_num_tokens]\n","        else:\n","            extra_bias = torch.zeros((1, new_num_tokens - old_num_tokens), device=self.final_logits_bias.device)\n","            new_bias = torch.cat([self.final_logits_bias, extra_bias], dim=1)\n","        self.register_buffer(\"final_logits_bias\", new_bias)\n","\n","    \n","    def forward(\n","            self,\n","            input_ids,\n","            attention_mask=None,\n","            decoder_input_ids=None,\n","            decoder_attention_mask=None,\n","            encoder_outputs=None,\n","            past_key_values=None,\n","            labels=None,\n","            use_cache=None,\n","            output_attentions=None,\n","            output_hidden_states=None,\n","            return_dict=None,\n","            **unused,\n","    ):\n","        r\"\"\"\n","        labels (:obj:`torch.LongTensor` of shape :obj:`(batch_size, sequence_length)`, `optional`):\n","            Labels for computing the masked language modeling loss.\n","            Indices should either be in ``[0, ..., config.vocab_size]`` or -100 (see ``input_ids`` docstring).\n","            Tokens with indices set to ``-100`` are ignored (masked), the loss is only computed for the tokens\n","            with labels in ``[0, ..., config.vocab_size]``.\n","        Returns:\n","        Conditional generation example::\n","            >>> # Mask filling only works for bart-large\n","            >>> from transformers import BartTokenizer, BartForConditionalGeneration\n","            >>> tokenizer = BartTokenizer.from_pretrained('facebook/bart-large')\n","            >>> TXT = \"My friends are <mask> but they eat too many carbs.\"\n","            >>> model = BartForConditionalGeneration.from_pretrained('facebook/bart-large')\n","            >>> input_ids = tokenizer([TXT], return_tensors='pt')['input_ids']\n","            >>> logits = model(input_ids).logits\n","            >>> masked_index = (input_ids[0] == tokenizer.mask_token_id).nonzero().item()\n","            >>> probs = logits[0, masked_index].softmax(dim=0)\n","            >>> values, predictions = probs.topk(5)\n","            >>> tokenizer.decode(predictions).split()\n","            >>> # ['good', 'great', 'all', 'really', 'very']\n","        \"\"\"\n","        if \"lm_labels\" in unused:\n","            warnings.warn(\n","                \"The `lm_labels` argument is deprecated and will be removed in a future version, use `labels` instead.\",\n","                FutureWarning,\n","            )\n","            labels = unused.pop(\"lm_labels\")\n","        if \"decoder_cached_states\" in unused:\n","            warnings.warn(\n","                \"The `decoder_cached_states` argument is deprecated and will be removed in a future version, use `past_key_values` instead.\",\n","                FutureWarning,\n","            )\n","            past_key_values = unused.pop(\"decoder_cached_states\")\n","        if \"decoder_past_key_values\" in unused:\n","            warnings.warn(\n","                \"The `decoder_past_key_values` argument is deprecated and will be removed in a future version, use `past_key_values` instead.\",\n","                FutureWarning,\n","            )\n","            past_key_values = unused.pop(\"decoder_past_key_values\")\n","        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n","\n","        if labels is not None:\n","            use_cache = False\n","            if decoder_input_ids is None:\n","                decoder_input_ids = shift_tokens_right(labels, self.config.pad_token_id)\n","\n","        outputs = self.model(\n","            input_ids,\n","            attention_mask=attention_mask,\n","            decoder_input_ids=decoder_input_ids,\n","            encoder_outputs=encoder_outputs,\n","            decoder_attention_mask=decoder_attention_mask,\n","            past_key_values=past_key_values,\n","            use_cache=use_cache,\n","            output_attentions=output_attentions,\n","            output_hidden_states=output_hidden_states,\n","            return_dict=return_dict,\n","        )\n","        lm_logits = F.linear(outputs[0], self.model.shared.weight, bias=self.final_logits_bias)\n","\n","        masked_lm_loss = None\n","        if labels is not None:\n","            loss_fct = CrossEntropyLoss()\n","            # TODO(SS): do we need to ignore pad tokens in labels?\n","            masked_lm_loss = loss_fct(lm_logits.view(-1, self.config.vocab_size), labels.view(-1))\n","\n","        if not return_dict:\n","            output = (lm_logits,) + outputs[1:]\n","            return ((masked_lm_loss,) + output) if masked_lm_loss is not None else output\n","\n","        return Seq2SeqLMOutput(\n","            loss=masked_lm_loss,\n","            logits=lm_logits,\n","            past_key_values=outputs.past_key_values,\n","            decoder_hidden_states=outputs.decoder_hidden_states,\n","            decoder_attentions=outputs.decoder_attentions,\n","            encoder_last_hidden_state=outputs.encoder_last_hidden_state,\n","            encoder_hidden_states=outputs.encoder_hidden_states,\n","            encoder_attentions=outputs.encoder_attentions,\n","        )\n","\n","    def prepare_inputs_for_generation(\n","            self, decoder_input_ids, past, attention_mask, use_cache, encoder_outputs, **kwargs\n","    ):\n","        return {\n","            \"input_ids\": None,  # encoder_outputs is defined. input_ids not needed\n","            \"encoder_outputs\": encoder_outputs,\n","            \"past_key_values\": past,\n","            \"decoder_input_ids\": decoder_input_ids,\n","            \"attention_mask\": attention_mask,\n","            \"use_cache\": use_cache,  # change this to avoid caching (presumably for debugging)\n","        }\n","\n","    def adjust_logits_during_generation(self, logits, cur_len, max_length):\n","        if cur_len == 1 and self.config.force_bos_token_to_be_generated:\n","            self._force_token_ids_generation(logits, self.config.bos_token_id)\n","        elif cur_len == max_length - 1 and self.config.eos_token_id is not None:\n","            self._force_token_ids_generation(logits, self.config.eos_token_id)\n","        return logits\n","\n","    def _force_token_ids_generation(self, scores, token_id) -> None:\n","        \"\"\"force one of token_ids to be generated by setting prob of all other tokens to 0 (logprob=-float(\"inf\"))\"\"\"\n","        scores[:, [x for x in range(self.config.vocab_size) if x != token_id]] = -float(\"inf\")\n","\n","    @staticmethod\n","    def _reorder_cache(past, beam_idx):\n","        reordered_past = []\n","        for layer_past in past:\n","            # get the correct batch idx from decoder layer's batch dim for cross and self-attn\n","            layer_past_new = {\n","                attn_key: _reorder_buffer(attn_cache, beam_idx) for attn_key, attn_cache in layer_past.items()\n","            }\n","            reordered_past.append(layer_past_new)\n","        return reordered_past\n","\n","    def get_encoder(self):\n","        return self.model.encoder\n","\n","    def get_output_embeddings(self):\n","        return _make_linear_from_emb(self.model.shared)  # make it on the fly\n","\n","\n","\n","class BartForSequenceClassification(PretrainedBartModel):\n","    def __init__(self, config: BartConfig, **kwargs):\n","        super().__init__(config, **kwargs)\n","        self.model = BartModel(config)\n","        self.classification_head = BartClassificationHead(\n","            config.d_model,\n","            config.d_model,\n","            config.num_labels,\n","            config.classifier_dropout,\n","        )\n","        self.model._init_weights(self.classification_head.dense)\n","        self.model._init_weights(self.classification_head.out_proj)\n","\n","    \n","    def forward(\n","            self,\n","            input_ids,\n","            attention_mask=None,\n","            decoder_input_ids=None,\n","            decoder_attention_mask=None,\n","            encoder_outputs=None,\n","            labels=None,\n","            use_cache=None,\n","            output_attentions=None,\n","            output_hidden_states=None,\n","            return_dict=None,\n","    ):\n","        r\"\"\"\n","        labels (:obj:`torch.LongTensor` of shape :obj:`(batch_size,)`, `optional`):\n","            Labels for computing the sequence classification/regression loss.\n","            Indices should be in :obj:`[0, ..., config.num_labels - 1]`.\n","            If :obj:`config.num_labels > 1` a classification loss is computed (Cross-Entropy).\n","        \"\"\"\n","        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n","        if labels is not None:\n","            use_cache = False\n","\n","        outputs = self.model(\n","            input_ids,\n","            attention_mask=attention_mask,\n","            decoder_input_ids=decoder_input_ids,\n","            decoder_attention_mask=decoder_attention_mask,\n","            encoder_outputs=encoder_outputs,\n","            use_cache=use_cache,\n","            output_attentions=output_attentions,\n","            output_hidden_states=output_hidden_states,\n","            return_dict=return_dict,\n","        )\n","        x = outputs[0]  # last hidden state\n","        eos_mask = input_ids.eq(self.config.eos_token_id)\n","        if len(torch.unique(eos_mask.sum(1))) > 1:\n","            raise ValueError(\"All examples must have the same number of <eos> tokens.\")\n","        sentence_representation = x[eos_mask, :].view(x.size(0), -1, x.size(-1))[:, -1, :]\n","        logits = self.classification_head(sentence_representation)\n","\n","        loss = None\n","        if labels is not None:\n","            loss_fct = CrossEntropyLoss()\n","            loss = loss_fct(logits.view(-1, self.config.num_labels), labels.view(-1))\n","\n","        if not return_dict:\n","            output = (logits,) + outputs[1:]\n","            return ((loss,) + output) if loss is not None else output\n","\n","        return Seq2SeqSequenceClassifierOutput(\n","            loss=loss,\n","            logits=logits,\n","            past_key_values=outputs.past_key_values,\n","            decoder_hidden_states=outputs.decoder_hidden_states,\n","            decoder_attentions=outputs.decoder_attentions,\n","            encoder_last_hidden_state=outputs.encoder_last_hidden_state,\n","            encoder_hidden_states=outputs.encoder_hidden_states,\n","            encoder_attentions=outputs.encoder_attentions,\n","        )\n","\n","\n","\n","class BartForQuestionAnswering(PretrainedBartModel):\n","    def __init__(self, config):\n","        super().__init__(config)\n","\n","        config.num_labels = 2\n","        self.num_labels = config.num_labels\n","\n","        self.model = BartModel(config)\n","        self.qa_outputs = nn.Linear(config.hidden_size, config.num_labels)\n","\n","        self.model._init_weights(self.qa_outputs)\n","\n","    \n","    def forward(\n","            self,\n","            input_ids,\n","            attention_mask=None,\n","            decoder_input_ids=None,\n","            decoder_attention_mask=None,\n","            encoder_outputs=None,\n","            start_positions=None,\n","            end_positions=None,\n","            use_cache=None,\n","            output_attentions=None,\n","            output_hidden_states=None,\n","            return_dict=None,\n","    ):\n","        r\"\"\"\n","        start_positions (:obj:`torch.LongTensor` of shape :obj:`(batch_size,)`, `optional`):\n","            Labels for position (index) of the start of the labelled span for computing the token classification loss.\n","            Positions are clamped to the length of the sequence (`sequence_length`).\n","            Position outside of the sequence are not taken into account for computing the loss.\n","        end_positions (:obj:`torch.LongTensor` of shape :obj:`(batch_size,)`, `optional`):\n","            Labels for position (index) of the end of the labelled span for computing the token classification loss.\n","            Positions are clamped to the length of the sequence (`sequence_length`).\n","            Position outside of the sequence are not taken into account for computing the loss.\n","        \"\"\"\n","        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n","        if start_positions is not None and end_positions is not None:\n","            use_cache = False\n","\n","        outputs = self.model(\n","            input_ids,\n","            attention_mask=attention_mask,\n","            decoder_input_ids=decoder_input_ids,\n","            decoder_attention_mask=decoder_attention_mask,\n","            encoder_outputs=encoder_outputs,\n","            use_cache=use_cache,\n","            output_attentions=output_attentions,\n","            output_hidden_states=output_hidden_states,\n","            return_dict=return_dict,\n","        )\n","\n","        sequence_output = outputs[0]\n","\n","        logits = self.qa_outputs(sequence_output)\n","        start_logits, end_logits = logits.split(1, dim=-1)\n","        start_logits = start_logits.squeeze(-1)\n","        end_logits = end_logits.squeeze(-1)\n","\n","        total_loss = None\n","        if start_positions is not None and end_positions is not None:\n","            # If we are on multi-GPU, split add a dimension\n","            if len(start_positions.size()) > 1:\n","                start_positions = start_positions.squeeze(-1)\n","            if len(end_positions.size()) > 1:\n","                end_positions = end_positions.squeeze(-1)\n","            # sometimes the start/end positions are outside our model inputs, we ignore these terms\n","            ignored_index = start_logits.size(1)\n","            start_positions.clamp_(0, ignored_index)\n","            end_positions.clamp_(0, ignored_index)\n","\n","            loss_fct = CrossEntropyLoss(ignore_index=ignored_index)\n","            start_loss = loss_fct(start_logits, start_positions)\n","            end_loss = loss_fct(end_logits, end_positions)\n","            total_loss = (start_loss + end_loss) / 2\n","\n","        if not return_dict:\n","            output = (\n","                         start_logits,\n","                         end_logits,\n","                     ) + outputs[1:]\n","            return ((total_loss,) + output) if total_loss is not None else output\n","\n","        return Seq2SeqQuestionAnsweringModelOutput(\n","            loss=total_loss,\n","            start_logits=start_logits,\n","            end_logits=end_logits,\n","            past_key_values=outputs.past_key_values,\n","            decoder_hidden_states=outputs.decoder_hidden_states,\n","            decoder_attentions=outputs.decoder_attentions,\n","            encoder_last_hidden_state=outputs.encoder_last_hidden_state,\n","            encoder_hidden_states=outputs.encoder_hidden_states,\n","            encoder_attentions=outputs.encoder_attentions,\n","        )\n","\n","\n","class SinusoidalPositionalEmbedding(nn.Embedding):\n","    \"\"\"This module produces sinusoidal positional embeddings of any length.\"\"\"\n","\n","    def __init__(self, num_positions, embedding_dim, padding_idx=None):\n","        super().__init__(num_positions, embedding_dim)\n","        if embedding_dim % 2 != 0:\n","            raise NotImplementedError(f\"odd embedding_dim {embedding_dim} not supported\")\n","        self.weight = self._init_weight(self.weight)\n","\n","    @staticmethod\n","    def _init_weight(out: nn.Parameter):\n","        \"\"\"Identical to the XLM create_sinusoidal_embeddings except features are not interleaved.\n","        The cos features are in the 2nd half of the vector. [dim // 2:]\n","        \"\"\"\n","        n_pos, dim = out.shape\n","        position_enc = np.array(\n","            [[pos / np.power(10000, 2 * (j // 2) / dim) for j in range(dim)] for pos in range(n_pos)]\n","        )\n","        out[:, 0: dim // 2] = torch.FloatTensor(np.sin(position_enc[:, 0::2]))  # This line breaks for odd n_pos\n","        out[:, dim // 2:] = torch.FloatTensor(np.cos(position_enc[:, 1::2]))\n","        out.detach_()\n","        out.requires_grad = False\n","        return out\n","\n","    @torch.no_grad()\n","    def forward(self, input_ids, use_cache=False):\n","        \"\"\"Input is expected to be of size [bsz x seqlen].\"\"\"\n","        bsz, seq_len = input_ids.shape[:2]\n","        if use_cache:\n","            positions = input_ids.data.new(1, 1).fill_(seq_len - 1)  # called before slicing\n","        else:\n","            # starts at 0, ends at 1-seq_len\n","            positions = torch.arange(seq_len, dtype=torch.long, device=self.weight.device)\n","        return super().forward(positions)"],"metadata":{"id":"ZijvJnk-XLE5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","from transformers import BartTokenizer\n","from fastNLP import seq_len_to_mask\n","from fastNLP.modules import Seq2SeqEncoder, Seq2SeqDecoder, State\n","import torch.nn.functional as F\n","from fastNLP.models import Seq2SeqModel\n","from torch import nn\n","import math\n","\n","\n","class FBartEncoder(Seq2SeqEncoder):\n","    def __init__(self, encoder):\n","        super().__init__()\n","        assert isinstance(encoder, BartEncoder)\n","        self.bart_encoder = encoder\n","\n","    def forward(self, src_tokens, src_seq_len):\n","        mask = seq_len_to_mask(src_seq_len, max_len=src_tokens.size(1))\n","        dict = self.bart_encoder(input_ids=src_tokens, attention_mask=mask, return_dict=True,\n","                                 output_hidden_states=True)\n","        encoder_outputs = dict.last_hidden_state\n","        hidden_states = dict.hidden_states\n","        return encoder_outputs, mask, hidden_states\n","\n","\n","class FBartDecoder(Seq2SeqDecoder):\n","    def __init__(self, decoder, pad_token_id, label_ids, use_encoder_mlp=True):\n","        super().__init__()\n","        assert isinstance(decoder, BartDecoder)\n","        self.decoder = decoder\n","        causal_mask = torch.zeros(512, 512).fill_(float('-inf'))\n","        causal_mask = causal_mask.triu(diagonal=1)\n","        self.register_buffer('causal_masks', causal_mask.float())\n","        self.pad_token_id = pad_token_id\n","        self.label_start_id = label_ids[0]\n","        self.label_end_id = label_ids[-1]+1\n","        # 0th position is <s>, 1st position is </s>\n","        mapping = torch.LongTensor([0, 2]+sorted(label_ids, reverse=False))\n","        self.register_buffer('mapping', mapping)\n","        self.src_start_index = len(mapping)  # 加上一个\n","        hidden_size = decoder.embed_tokens.weight.size(1)\n","        if use_encoder_mlp:\n","            self.encoder_mlp = nn.Sequential(nn.Linear(hidden_size, hidden_size),\n","                                             nn.Dropout(0.3),\n","                                             nn.ReLU(),\n","                                             nn.Linear(hidden_size, hidden_size))\n","\n","    def forward(self, tokens, state):\n","        # bsz, max_len = tokens.size()\n","        encoder_outputs = state.encoder_output\n","        encoder_pad_mask = state.encoder_mask\n","\n","        first = state.first\n","\n","        # eos is 1\n","        cumsum = tokens.eq(1).flip(dims=[1]).cumsum(dim=-1)\n","        tgt_pad_mask = cumsum.flip(dims=[1]).ne(cumsum[:, -1:])\n","\n","        # mapping to the BART token index\n","        mapping_token_mask = tokens.lt(self.src_start_index)  #\n","        mapped_tokens = tokens.masked_fill(tokens.ge(self.src_start_index), 0)\n","        tag_mapped_tokens = self.mapping[mapped_tokens]\n","\n","        src_tokens_index = tokens - self.src_start_index # bsz x num_src_token\n","        src_tokens_index = src_tokens_index.masked_fill(src_tokens_index.lt(0), 0)\n","        src_tokens = state.src_tokens\n","        if first is not None:\n","            src_tokens = src_tokens.gather(index=first, dim=1)\n","        word_mapped_tokens = src_tokens.gather(index=src_tokens_index, dim=1)\n","\n","        tokens = torch.where(mapping_token_mask, tag_mapped_tokens, word_mapped_tokens)\n","        tokens = tokens.masked_fill(tgt_pad_mask, self.pad_token_id)\n","\n","        if self.training:\n","            tokens = tokens[:, :-1]\n","            decoder_pad_mask = tokens.eq(self.pad_token_id)\n","            dict = self.decoder(input_ids=tokens,\n","                                encoder_hidden_states=encoder_outputs,\n","                                encoder_padding_mask=encoder_pad_mask,\n","                                decoder_padding_mask=decoder_pad_mask,\n","                                decoder_causal_mask=self.causal_masks[:tokens.size(1), :tokens.size(1)],\n","                                return_dict=True)\n","        else:\n","            past_key_values = state.past_key_values\n","            dict = self.decoder(input_ids=tokens,\n","                                encoder_hidden_states=encoder_outputs,\n","                                encoder_padding_mask=encoder_pad_mask,\n","                                decoder_padding_mask=None,\n","                                decoder_causal_mask=None,\n","                                past_key_values=past_key_values,\n","                                use_cache=True,\n","                                return_dict=True)\n","        hidden_state = dict.last_hidden_state  # bsz x max_len x hidden_size\n","        if not self.training:\n","            state.past_key_values = dict.past_key_values\n","\n","        logits = hidden_state.new_full((hidden_state.size(0), hidden_state.size(1), self.src_start_index+src_tokens.size(-1)),\n","                                       fill_value=-1e24)\n","\n","        # first get the\n","        eos_scores = F.linear(hidden_state, self.decoder.embed_tokens.weight[2:3])  # bsz x max_len x 1\n","        tag_scores = F.linear(hidden_state, self.decoder.embed_tokens.weight[self.label_start_id:self.label_end_id])  # bsz x max_len x num_class\n","\n","        # bsz x max_word_len x hidden_size\n","        src_outputs = state.encoder_output\n","\n","        if hasattr(self, 'encoder_mlp'):\n","            src_outputs = self.encoder_mlp(src_outputs)\n","\n","        if first is not None:\n","            mask = first.eq(0)  # bsz x 1 x max_word_len, 为1的地方是padding\n","            src_outputs = src_outputs.gather(index=first.unsqueeze(2).repeat(1, 1, src_outputs.size(-1)), dim=1)\n","        else:\n","            mask = state.encoder_mask.eq(0)\n","\n","        mask = mask.unsqueeze(1).__or__(src_tokens.eq(2).cumsum(dim=1).ge(1).unsqueeze(1))\n","        word_scores = torch.einsum('blh,bnh->bln', hidden_state, src_outputs)  # bsz x max_len x max_word_len\n","        word_scores = word_scores.masked_fill(mask, -1e32)\n","\n","        logits[:, :, 1:2] = eos_scores\n","        logits[:, :, 2:self.src_start_index] = tag_scores\n","        logits[:, :, self.src_start_index:] = word_scores\n","\n","        return logits\n","\n","    def decode(self, tokens, state):\n","        return self(tokens, state)[:, -1]\n","\n","\n","class CaGFBartDecoder(FBartDecoder):\n","    # Copy and generate,\n","    def __init__(self, decoder, pad_token_id, label_ids, use_encoder_mlp=False):\n","        super().__init__(decoder, pad_token_id, label_ids, use_encoder_mlp=use_encoder_mlp)\n","\n","    def forward(self, tokens, state):\n","        encoder_outputs = state.encoder_output\n","        encoder_pad_mask = state.encoder_mask\n","\n","        first = state.first\n","\n","        cumsum = tokens.eq(1).flip(dims=[1]).cumsum(dim=-1)\n","        tgt_pad_mask = cumsum.flip(dims=[1]).ne(cumsum[:, -1:])\n","\n","        mapping_token_mask = tokens.lt(self.src_start_index)\n","        mapped_tokens = tokens.masked_fill(tokens.ge(self.src_start_index), 0)\n","        tag_mapped_tokens = self.mapping[mapped_tokens]\n","\n","        src_tokens_index = tokens - self.src_start_index # bsz x num_src_token\n","        src_tokens_index = src_tokens_index.masked_fill(src_tokens_index.lt(0), 0)\n","        src_tokens = state.src_tokens\n","        if first is not None:\n","            src_tokens = src_tokens.gather(index=first, dim=1)\n","        word_mapped_tokens = src_tokens.gather(index=src_tokens_index, dim=1)\n","\n","        tokens = torch.where(mapping_token_mask, tag_mapped_tokens, word_mapped_tokens)  # bsz x max_len\n","        tokens = tokens.masked_fill(tgt_pad_mask, self.pad_token_id)\n","\n","        if self.training:\n","            tokens = tokens[:, :-1]\n","            decoder_pad_mask = tokens.eq(self.pad_token_id)  # decoder需要让pad位置为1\n","            dict = self.decoder(input_ids=tokens,\n","                                encoder_hidden_states=encoder_outputs,\n","                                encoder_padding_mask=encoder_pad_mask,\n","                                decoder_padding_mask=decoder_pad_mask,\n","                                decoder_causal_mask=self.causal_masks[:tokens.size(1), :tokens.size(1)],\n","                                return_dict=True)\n","        else:\n","            past_key_values = state.past_key_values\n","            dict = self.decoder(input_ids=tokens,\n","                                encoder_hidden_states=encoder_outputs,\n","                                encoder_padding_mask=encoder_pad_mask,\n","                                decoder_padding_mask=None,\n","                                decoder_causal_mask=None,\n","                                past_key_values=past_key_values,\n","                                use_cache=True,\n","                                return_dict=True)\n","        hidden_state = dict.last_hidden_state  # bsz x max_len x hidden_size\n","        if not self.training:\n","            state.past_key_values = dict.past_key_values\n","\n","        logits = hidden_state.new_full((hidden_state.size(0), hidden_state.size(1), self.src_start_index+src_tokens.size(-1)),\n","                                       fill_value=-1e24)\n","\n","        eos_scores = F.linear(hidden_state, self.decoder.embed_tokens.weight[2:3])  # bsz x max_len x 1\n","        tag_scores = F.linear(hidden_state, self.decoder.embed_tokens.weight[self.label_start_id:self.label_end_id])  # bsz x max_len x num_class\n","\n","\n","        # bsz x max_bpe_len x hidden_size\n","        src_outputs = state.encoder_output\n","        if hasattr(self, 'encoder_mlp'):\n","            src_outputs = self.encoder_mlp(src_outputs)\n","\n","        if first is not None:\n","            mask = first.eq(0)  # bsz x 1 x max_word_len, 为1的地方是padding\n","            # bsz x max_word_len x hidden_size\n","            src_outputs = src_outputs.gather(index=first.unsqueeze(2).repeat(1, 1, src_outputs.size(-1)), dim=1)\n","        else:\n","            mask = state.encoder_mask.eq(0)\n","            # src_outputs = self.decoder.embed_tokens(src_tokens)\n","        mask = mask.unsqueeze(1)\n","        input_embed = self.decoder.embed_tokens(src_tokens)  # bsz x max_word_len x hidden_size\n","        word_scores = torch.einsum('blh,bnh->bln', hidden_state, src_outputs)  # bsz x max_len x max_word_len\n","        gen_scores = torch.einsum('blh,bnh->bln', hidden_state, input_embed)  # bsz x max_len x max_word_len\n","        word_scores = (gen_scores + word_scores)/2\n","        mask = mask.__or__(src_tokens.eq(2).cumsum(dim=1).ge(1).unsqueeze(1))\n","        word_scores = word_scores.masked_fill(mask, -1e32)\n","\n","        logits[:, :, 1:2] = eos_scores\n","        logits[:, :, 2:self.src_start_index] = tag_scores\n","        logits[:, :, self.src_start_index:] = word_scores\n","\n","        return logits\n","\n","\n","class BartSeq2SeqModel(Seq2SeqModel):\n","    @classmethod\n","    def build_model(cls, bart_model, tokenizer, label_ids, decoder_type=None, copy_gate=False,\n","                    use_encoder_mlp=False, use_recur_pos=False, tag_first=False):\n","        model = BartModel.from_pretrained(bart_model)\n","        num_tokens, _ = model.encoder.embed_tokens.weight.shape\n","        model.resize_token_embeddings(len(tokenizer.unique_no_split_tokens)+num_tokens)\n","        encoder = model.encoder\n","        decoder = model.decoder\n","\n","        if use_recur_pos:\n","            decoder.set_position_embedding(label_ids[0], tag_first)\n","\n","        _tokenizer = BartTokenizer.from_pretrained(bart_model)\n","        for token in tokenizer.unique_no_split_tokens:\n","            if token[:2] == '<<':\n","                index = tokenizer.convert_tokens_to_ids(tokenizer.tokenize(token))\n","                if len(index)>1:\n","                    raise RuntimeError(f\"{token} wrong split\")\n","                else:\n","                    index = index[0]\n","                assert index>=num_tokens, (index, num_tokens, token)\n","                indexes = _tokenizer.convert_tokens_to_ids(_tokenizer.tokenize(token[2:-2]))\n","                embed = model.encoder.embed_tokens.weight.data[indexes[0]]\n","                for i in indexes[1:]:\n","                    embed += model.decoder.embed_tokens.weight.data[i]\n","                embed /= len(indexes)\n","                model.decoder.embed_tokens.weight.data[index] = embed\n","\n","        encoder = FBartEncoder(encoder)\n","        label_ids = sorted(label_ids)\n","        if decoder_type is None:\n","            assert copy_gate is False\n","            decoder = FBartDecoder(decoder, pad_token_id=tokenizer.pad_token_id, label_ids=label_ids)\n","        elif decoder_type =='avg_score':\n","            decoder = CaGFBartDecoder(decoder, pad_token_id=tokenizer.pad_token_id, label_ids=label_ids,\n","                                              use_encoder_mlp=use_encoder_mlp)\n","        else:\n","            raise RuntimeError(\"Unsupported feature.\")\n","\n","        return cls(encoder=encoder, decoder=decoder)\n","\n","    def prepare_state(self, src_tokens, src_seq_len=None, first=None, tgt_seq_len=None):\n","        encoder_outputs, encoder_mask, hidden_states = self.encoder(src_tokens, src_seq_len)\n","        src_embed_outputs = hidden_states[0]\n","        state = BartState(encoder_outputs, encoder_mask, src_tokens, first, src_embed_outputs)\n","        # setattr(state, 'tgt_seq_len', tgt_seq_len)\n","        return state\n","\n","    def forward(self, src_tokens, tgt_tokens, src_seq_len, tgt_seq_len, first):\n","        \"\"\"\n","        :param torch.LongTensor src_tokens: source的token\n","        :param torch.LongTensor tgt_tokens: target的token\n","        :param torch.LongTensor first: 显示每个, bsz x max_word_len\n","        :param torch.LongTensor src_seq_len: src的长度\n","        :param torch.LongTensor tgt_seq_len: target的长度，默认用不上\n","        :return: {'pred': torch.Tensor}, 其中pred的shape为bsz x max_len x vocab_size\n","        \"\"\"\n","        state = self.prepare_state(src_tokens, src_seq_len, first, tgt_seq_len)\n","        decoder_output = self.decoder(tgt_tokens, state)\n","        if isinstance(decoder_output, torch.Tensor):\n","            return {'pred': decoder_output}\n","        elif isinstance(decoder_output, (tuple, list)):\n","            return {'pred': decoder_output[0]}\n","        else:\n","            raise TypeError(f\"Unsupported return type from Decoder:{type(self.decoder)}\")\n","\n","\n","\n","class BartState(State):\n","    def __init__(self, encoder_output, encoder_mask, src_tokens, first, src_embed_outputs):\n","        super().__init__(encoder_output, encoder_mask)\n","        self.past_key_values = None\n","        self.src_tokens = src_tokens\n","        self.first = first\n","        self.src_embed_outputs = src_embed_outputs\n","\n","    def reorder_state(self, indices: torch.LongTensor):\n","        super().reorder_state(indices)\n","        self.src_tokens = self._reorder_state(self.src_tokens, indices)\n","        if self.first is not None:\n","            self.first = self._reorder_state(self.first, indices)\n","        self.src_embed_outputs = self._reorder_state(self.src_embed_outputs, indices)\n","        if self.past_key_values is not None:\n","            new = []\n","            for layer in self.past_key_values:\n","                new_layer = {}\n","                for key1 in list(layer.keys()):\n","                    new_layer_ = {}\n","                    for key2 in list(layer[key1].keys()):\n","                        if layer[key1][key2] is not None:\n","                            layer[key1][key2] = self._reorder_state(layer[key1][key2], indices)\n","                            # print(key1, key2, layer[key1][key2].shape)\n","                        new_layer_[key2] = layer[key1][key2]\n","                    new_layer[key1] = new_layer_\n","                new.append(new_layer)\n","            self.past_key_values = new"],"metadata":{"id":"gM9Rbqb5DZzZ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Model"],"metadata":{"id":"dVLiv9MiD_70"}},{"cell_type":"code","source":["\n","import torch\n","from torch import nn\n","from fastNLP.models.seq2seq_model import Seq2SeqModel\n","from fastNLP.modules.decoder.seq2seq_decoder import Seq2SeqDecoder, State\n","import torch.nn.functional as F\n","from fastNLP.core.utils import _get_model_device\n","from functools import partial\n","\n","\n","class SequenceGeneratorModel(nn.Module):\n","    \"\"\"\n","    用于封装Seq2SeqModel使其可以做生成任务\n","    \"\"\"\n","\n","    def __init__(self, seq2seq_model: Seq2SeqModel, bos_token_id, eos_token_id=None, max_length=30, max_len_a=0.0,\n","                 num_beams=1, do_sample=True,\n","                 repetition_penalty=1, length_penalty=1.0, pad_token_id=0,\n","                 restricter=None):\n","        \"\"\"\n","        :param Seq2SeqModel seq2seq_model: 序列到序列模型. 会使用seq2seq_model的decoder进行生成\n","        :param int,None bos_token_id: 句子开头的token id\n","        :param int,None eos_token_id: 句子结束的token id\n","        :param int max_length: 生成句子的最大长度, 每句话的decode长度为max_length + max_len_a*src_len\n","        :param float max_len_a: 每句话的decode长度为max_length + max_len_a*src_len。 如果不为0，需要保证State中包含encoder_mask\n","        :param int num_beams: beam search的大小\n","        :param bool do_sample: 是否通过采样的方式生成\n","        :param float temperature: 只有在do_sample为True才有意义\n","        :param int top_k: 只从top_k中采样\n","        :param float top_p: 只从top_p的token中采样，nucles sample\n","        :param float repetition_penalty: 多大程度上惩罚重复的token\n","        :param float length_penalty: 对长度的惩罚，小于1鼓励长句，大于1鼓励短剧\n","        :param int pad_token_id: 当某句话生成结束之后，之后生成的内容用pad_token_id补充\n","        \"\"\"\n","        super().__init__()\n","        self.seq2seq_model = seq2seq_model\n","        self.restricter = restricter\n","        self.generator = SequenceGenerator(seq2seq_model.decoder, max_length=max_length, max_len_a=max_len_a,\n","                                           num_beams=num_beams,\n","                                           do_sample=do_sample,\n","                                           bos_token_id=bos_token_id,\n","                                           eos_token_id=eos_token_id,\n","                                           repetition_penalty=repetition_penalty, length_penalty=length_penalty,\n","                                           pad_token_id=pad_token_id,\n","                                           restricter=restricter)\n","\n","    def forward(self, src_tokens, tgt_tokens, src_seq_len=None, tgt_seq_len=None, first=None):\n","        \"\"\"\n","        透传调用seq2seq_model的forward\n","        :param torch.LongTensor src_tokens: bsz x max_len\n","        :param torch.LongTensor tgt_tokens: bsz x max_len'\n","        :param torch.LongTensor src_seq_len: bsz\n","        :param torch.LongTensor tgt_seq_len: bsz\n","        :return:\n","        \"\"\"\n","        return self.seq2seq_model(src_tokens, tgt_tokens, src_seq_len, tgt_seq_len, first)\n","\n","    def predict(self, src_tokens, src_seq_len=None, first=None):\n","        \"\"\"\n","        给定source的内容，输出generate的内容\n","        :param torch.LongTensor src_tokens: bsz x max_len\n","        :param torch.LongTensor src_seq_len: bsz\n","        :return:\n","        \"\"\"\n","        state = self.seq2seq_model.prepare_state(src_tokens, src_seq_len, first)\n","        result = self.generator.generate(state)\n","        return {'pred': result}\n","\n","\n","r\"\"\"\n","\"\"\"\n","\n","__all__ = [\n","    'SequenceGenerator'\n","]\n","\n","\n","\n","class SequenceGenerator:\n","    \"\"\"\n","    给定一个Seq2SeqDecoder，decode出句子\n","    \"\"\"\n","    def __init__(self, decoder: Seq2SeqDecoder, max_length=20, max_len_a=0.0, num_beams=1,\n","                 do_sample=False, bos_token_id=None, eos_token_id=None,\n","                 repetition_penalty=1, length_penalty=1.0, pad_token_id=0, restricter=None):\n","        \"\"\"\n","        :param Seq2SeqDecoder decoder: Decoder对象\n","        :param int max_length: 生成句子的最大长度, 每句话的decode长度为max_length + max_len_a*src_len\n","        :param float max_len_a: 每句话的decode长度为max_length + max_len_a*src_len。 如果不为0，需要保证State中包含encoder_mask\n","        :param int num_beams: beam search的大小\n","        :param bool do_sample: 是否通过采样的方式生成\n","        :param float temperature: 只有在do_sample为True才有意义\n","        :param int top_k: 只从top_k中采样\n","        :param float top_p: 只从top_p的token中采样，nucles sample\n","        :param int,None bos_token_id: 句子开头的token id\n","        :param int,None eos_token_id: 句子结束的token id\n","        :param float repetition_penalty: 多大程度上惩罚重复的token\n","        :param float length_penalty: 对长度的惩罚，小于1鼓励长句，大于1鼓励短剧\n","        :param int pad_token_id: 当某句话生成结束之后，之后生成的内容用pad_token_id补充\n","        \"\"\"\n","        self.generate_func = partial(greedy_generate, decoder=decoder, max_length=max_length, max_len_a=max_len_a,\n","                                     num_beams=num_beams,\n","                                     bos_token_id=bos_token_id, eos_token_id=eos_token_id,\n","                                     repetition_penalty=repetition_penalty,\n","                                     length_penalty=length_penalty, pad_token_id=pad_token_id,\n","                                     restricter=restricter)\n","        self.do_sample = do_sample\n","        self.max_length = max_length\n","        self.num_beams = num_beams\n","        self.bos_token_id = bos_token_id\n","        self.eos_token_id = eos_token_id\n","        self.repetition_penalty = repetition_penalty\n","        self.length_penalty = length_penalty\n","        self.decoder = decoder\n","        self.pad_token_id = pad_token_id\n","        self.restricter = restricter\n","        self.max_len_a = max_len_a\n","\n","    def set_new_generator(self, max_length=-1, max_len_a=-1, num_beams=-1,\n","                          repetition_penalty=-1, length_penalty=-1, restricter=-1):\n","        if max_length == -1:\n","            max_length = self.max_length\n","        if max_len_a == -1:\n","            max_len_a = self.max_len_a\n","        if num_beams == -1:\n","            num_beams = self.num_beams\n","        if repetition_penalty == -1:\n","            repetition_penalty = self.repetition_penalty\n","        if length_penalty == -1:\n","            length_penalty = self.length_penalty\n","        if restricter == -1:\n","            restricter = self.restricter\n","        self.generate_func = partial(greedy_generate, decoder=self.decoder, max_length=max_length, max_len_a=max_len_a,\n","                                     num_beams=num_beams,\n","                                     bos_token_id=self.bos_token_id, eos_token_id=self.eos_token_id,\n","                                     repetition_penalty=repetition_penalty,\n","                                     length_penalty=length_penalty, pad_token_id=self.pad_token_id,\n","                                     restricter=restricter)\n","\n","    @torch.no_grad()\n","    def generate(self, state, tokens=None):\n","        \"\"\"\n","        :param State state: encoder结果的State, 是与Decoder配套是用的\n","        :param torch.LongTensor,None tokens: batch_size x length, 开始的token\n","        :return: bsz x max_length' 生成的token序列。如果eos_token_id不为None, 每个sequence的结尾一定是eos_token_id\n","        \"\"\"\n","\n","        return self.generate_func(tokens=tokens, state=state)\n","\n","@torch.no_grad()\n","def greedy_generate(decoder, tokens=None, state=None, max_length=20, max_len_a=0.0, num_beams=1,\n","                    bos_token_id=None, eos_token_id=None, pad_token_id=0,\n","                    repetition_penalty=1, length_penalty=1.0, restricter=None):\n","    \"\"\"\n","    贪婪地搜索句子\n","    :param Decoder decoder: Decoder对象\n","    :param torch.LongTensor tokens: batch_size x len, decode的输入值，如果为None，则自动从bos_token_id开始生成\n","    :param State state: 应该包含encoder的一些输出。\n","    :param int max_length: 生成句子的最大长度, 每句话的decode长度为max_length + max_len_a*src_len\n","    :param float max_len_a: 每句话的decode长度为max_length + max_len_a*src_len。 如果不为0，需要保证State中包含encoder_mask\n","    :param int num_beams: 使用多大的beam进行解码。\n","    :param int bos_token_id: 如果tokens传入为None，则使用bos_token_id开始往后解码。\n","    :param int eos_token_id: 结束的token，如果为None，则一定会解码到max_length这么长。\n","    :param int pad_token_id: pad的token id\n","    :param float repetition_penalty: 对重复出现的token多大的惩罚。\n","    :param float length_penalty: 对每个token（除了eos）按照长度进行一定的惩罚。\n","    :return:\n","    \"\"\"\n","    if num_beams == 1:\n","        token_ids = _no_beam_search_generate(decoder, tokens=tokens, state=state, max_length=max_length, max_len_a=max_len_a,\n","                                             bos_token_id=bos_token_id, eos_token_id=eos_token_id,\n","                                             repetition_penalty=repetition_penalty, length_penalty=length_penalty,\n","                                             pad_token_id=pad_token_id, restricter=restricter)\n","    else:\n","        token_ids = _beam_search_generate(decoder, tokens=tokens, state=state, max_length=max_length, max_len_a=max_len_a,\n","                                          num_beams=num_beams,\n","                                          bos_token_id=bos_token_id, eos_token_id=eos_token_id, do_sample=False,\n","                                          repetition_penalty=repetition_penalty, length_penalty=length_penalty,\n","                                          pad_token_id=pad_token_id, restricter=restricter)\n","\n","    return token_ids\n","\n","\n","def _no_beam_search_generate(decoder: Seq2SeqDecoder, state, tokens=None, max_length=20, max_len_a=0.0, bos_token_id=None,\n","                             eos_token_id=None,\n","                             repetition_penalty=1.0, length_penalty=1.0, pad_token_id=0,\n","                             restricter=None):\n","    device = _get_model_device(decoder)\n","    if tokens is None:\n","        if bos_token_id is None:\n","            raise RuntimeError(\"You have to specify either `tokens` or `bos_token_id`.\")\n","        batch_size = state.num_samples\n","        if batch_size is None:\n","            raise RuntimeError(\"Cannot infer the number of samples from `state`.\")\n","        tokens = torch.full([batch_size, 1], fill_value=bos_token_id, dtype=torch.long).to(device)\n","    batch_size = tokens.size(0)\n","    if state.num_samples:\n","        assert state.num_samples == batch_size, \"The number of samples in `tokens` and `state` should match.\"\n","\n","    if eos_token_id is None:\n","        _eos_token_id = -1\n","    else:\n","        _eos_token_id = eos_token_id\n","\n","    scores = decoder.decode(tokens=tokens, state=state)  # 主要是为了update state\n","    # 这里需要考虑如果在第一个位置就结束的情况\n","    # if _eos_token_id!=-1:\n","    #     scores[:, _eos_token_id] = -1e12\n","\n","    if restricter is not None:\n","        _, next_tokens = restricter(state, tokens, scores, num_beams=1)\n","    else:\n","        next_tokens = scores.argmax(dim=-1, keepdim=True)\n","    token_ids = torch.cat([tokens, next_tokens], dim=1)\n","    cur_len = token_ids.size(1)\n","    dones = token_ids.new_zeros(batch_size).eq(1).__or__(next_tokens.squeeze(1).eq(eos_token_id))\n","    # tokens = tokens[:, -1:]\n","\n","    if max_len_a!=0:\n","        # (bsz x num_beams, )\n","        if state.encoder_mask is not None:\n","            max_lengths = (state.encoder_mask.sum(dim=1).float()*max_len_a).long() + max_length\n","        else:\n","            max_lengths = tokens.new_full((tokens.size(0), ), fill_value=max_length, dtype=torch.long)\n","        real_max_length = max_lengths.max().item()\n","    else:\n","        real_max_length = max_length\n","        if state.encoder_mask is not None:\n","            max_lengths = state.encoder_mask.new_ones(state.encoder_mask.size(0)).long()*max_length\n","        else:\n","            max_lengths = tokens.new_full((tokens.size(0),), fill_value=max_length, dtype=torch.long)\n","\n","    while cur_len < real_max_length:\n","        scores = decoder.decode(tokens=token_ids, state=state)  # batch_size x vocab_size\n","\n","        if repetition_penalty != 1.0:\n","            token_scores = scores.gather(dim=1, index=token_ids)\n","            lt_zero_mask = token_scores.lt(0).float()\n","            ge_zero_mask = lt_zero_mask.eq(0).float()\n","            token_scores = lt_zero_mask * repetition_penalty * token_scores + ge_zero_mask / repetition_penalty * token_scores\n","            scores.scatter_(dim=1, index=token_ids, src=token_scores)\n","\n","        if eos_token_id is not None and length_penalty != 1.0:\n","            token_scores = scores / cur_len ** length_penalty  # batch_size x vocab_size\n","            eos_mask = scores.new_ones(scores.size(1))\n","            eos_mask[eos_token_id] = 0\n","            eos_mask = eos_mask.unsqueeze(0).eq(1)\n","            scores = scores.masked_scatter(eos_mask, token_scores)  # 也即除了eos，其他词的分数经过了放大/缩小\n","\n","        if restricter is not None:\n","            _, next_tokens = restricter(state, token_ids, scores, 1)\n","        else:\n","            next_tokens = scores.argmax(dim=-1, keepdim=True)\n","        next_tokens = next_tokens.squeeze(-1)\n","\n","        # 如果已经达到对应的sequence长度了，就直接填为eos了\n","        if _eos_token_id!=-1:\n","            next_tokens = next_tokens.masked_fill(max_lengths.eq(cur_len+1), _eos_token_id)\n","        next_tokens = next_tokens.masked_fill(dones, pad_token_id)  # 对已经搜索完成的sample做padding\n","        tokens = next_tokens.unsqueeze(1)\n","\n","        token_ids = torch.cat([token_ids, tokens], dim=-1)  # batch_size x max_len\n","\n","        end_mask = next_tokens.eq(_eos_token_id)\n","        dones = dones.__or__(end_mask)\n","        cur_len += 1\n","\n","        if dones.min() == 1:\n","            break\n","\n","    # if eos_token_id is not None:\n","    #     tokens.scatter(index=max_lengths[:, None], dim=1, value=eos_token_id)  # 将最大长度位置设置为eos\n","    # if cur_len == max_length:\n","    #     token_ids[:, -1].masked_fill_(~dones, eos_token_id)  # 若到最长长度仍未到EOS，则强制将最后一个词替换成eos\n","    return token_ids\n","\n","\n","def _beam_search_generate(decoder: Seq2SeqDecoder, tokens=None, state=None, max_length=20, max_len_a=0.0, num_beams=4,\n","                          bos_token_id=None, eos_token_id=None, do_sample=True,\n","                          repetition_penalty=1.0, length_penalty=None, pad_token_id=0,\n","                          restricter=None) -> torch.LongTensor:\n","    assert do_sample is False\n","    # 进行beam search\n","    device = _get_model_device(decoder)\n","    if tokens is None:\n","        if bos_token_id is None:\n","            raise RuntimeError(\"You have to specify either `tokens` or `bos_token_id`.\")\n","        batch_size = state.num_samples\n","        if batch_size is None:\n","            raise RuntimeError(\"Cannot infer the number of samples from `state`.\")\n","        tokens = torch.full([batch_size, 1], fill_value=bos_token_id, dtype=torch.long).to(device)\n","    batch_size = tokens.size(0)\n","    if state.num_samples:\n","        assert state.num_samples == batch_size, \"The number of samples in `tokens` and `state` should match.\"\n","\n","    if eos_token_id is None:\n","        _eos_token_id = -1\n","    else:\n","        _eos_token_id = eos_token_id\n","\n","    scores = decoder.decode(tokens=tokens, state=state)  # 这里要传入的是整个句子的长度\n","    # 这里需要考虑如果在第一个位置就结束的情况\n","    # if _eos_token_id!=-1:\n","    #     scores[:, _eos_token_id] = -1e12\n","    vocab_size = scores.size(1)\n","    assert vocab_size >= num_beams, \"num_beams should be smaller than the number of vocabulary size.\"\n","\n","    scores = F.log_softmax(scores, dim=-1)  # (batch_size, vocab_size)\n","    # 得到(batch_size, num_beams), (batch_size, num_beams)\n","    # TODO 把限制写到这个位置, 加1是因为需要考虑输出就是eos的情况\n","    if restricter is not None:\n","        _next_scores, _next_tokens = restricter(state, tokens, scores, num_beams+1)\n","    else:\n","        # 是bsz x (num_beams+1)大小的东西\n","        _next_scores, _next_tokens = torch.topk(scores, num_beams+1, dim=1, largest=True, sorted=True)\n","\n","    # 根据index来做顺序的调转\n","    indices = torch.arange(batch_size, dtype=torch.long).to(device)\n","    indices = indices.repeat_interleave(num_beams)\n","    state.reorder_state(indices)\n","    tokens = tokens.index_select(dim=0, index=indices)  # batch_size * num_beams x length\n","\n","    # if hasattr(state, 'tgt_seq_len'):  # TODO 应该需要删除\n","    #     max_lengths = state.tgt_seq_len\n","    #     real_max_length = max_lengths.max().item()\n","    if max_len_a!=0:\n","        # (bsz x num_beams, )\n","        if state.encoder_mask is not None:\n","            max_lengths = (state.encoder_mask.sum(dim=1).float()*max_len_a).long() + max_length\n","        else:\n","            max_lengths = tokens.new_full((batch_size*num_beams, ), fill_value=max_length, dtype=torch.long)\n","        real_max_length = max_lengths.max().item()\n","    else:\n","        real_max_length = max_length\n","        if state.encoder_mask is not None:\n","            max_lengths = state.encoder_mask.new_ones(state.encoder_mask.size(0)).long()*max_length\n","        else:\n","            max_lengths = tokens.new_full((batch_size*num_beams,), fill_value=max_length, dtype=torch.long)\n","    hypos = [\n","        BeamHypotheses(num_beams, real_max_length, length_penalty, early_stopping=False) for _ in range(batch_size)\n","    ]\n","\n","    not_eos_mask = _next_tokens.ne(_eos_token_id)  # 为1的地方不是eos\n","    keep_mask = not_eos_mask.cumsum(dim=1).le(num_beams)  # 为1的地方需要保留\n","    keep_mask = not_eos_mask.__and__(keep_mask)  # 为1的地方是需要进行下一步search的\n","\n","    next_tokens = _next_tokens.masked_select(keep_mask).view(batch_size, num_beams)  # 这是真的接下来要继续的\n","    next_scores = _next_scores.masked_select(keep_mask).view(batch_size, num_beams)\n","\n","    rows, cols = not_eos_mask.eq(0)[:, :num_beams].nonzero(as_tuple=True)\n","\n","    if len(rows)>0:  # 说明有的开头就结束了\n","        for row, col in zip(rows.tolist(), cols.tolist()):\n","            _token = torch.cat([tokens[row*num_beams], _next_tokens[row, col:col+1]], dim=0)\n","            hypos[row].add(_token.clone(), _next_scores[row, col].item())\n","\n","    # 记录生成好的token (batch_size', cur_len)\n","    token_ids = torch.cat([tokens, next_tokens.view(-1, 1)], dim=-1)\n","    dones = [False] * batch_size\n","\n","    beam_scores = next_scores.view(-1)  # batch_size * num_beams\n","\n","    #  用来记录已经生成好的token的长度\n","    cur_len = token_ids.size(1)\n","\n","    # 0, num_beams, 2*num_beams, ...\n","    batch_inds_with_numbeams_interval = (torch.arange(batch_size) * num_beams).view(-1, 1).to(token_ids)\n","\n","    while cur_len < real_max_length:\n","        scores = decoder.decode(token_ids, state)  # (bsz x num_beams, vocab_size)\n","        if repetition_penalty != 1.0:\n","            token_scores = scores.gather(dim=1, index=token_ids)\n","            lt_zero_mask = token_scores.lt(0).float()\n","            ge_zero_mask = lt_zero_mask.eq(0).float()\n","            token_scores = lt_zero_mask * repetition_penalty * token_scores + ge_zero_mask / repetition_penalty * token_scores\n","            scores.scatter_(dim=1, index=token_ids, src=token_scores)\n","\n","        if _eos_token_id!=-1:\n","            max_len_eos_mask = max_lengths.eq(cur_len+1)\n","            eos_scores = scores[:, _eos_token_id]\n","            # 如果已经达到最大长度，就把eos的分数加大\n","            scores[:, _eos_token_id] = torch.where(max_len_eos_mask, eos_scores+1e32, eos_scores)\n","\n","        scores = F.log_softmax(scores, dim=-1)  # (batch_size * num_beams, vocab_size)\n","        _scores = scores + beam_scores[:, None]  # (batch_size * num_beams, vocab_size)\n","        _scores = _scores.view(batch_size, -1)  # (batch_size, num_beams*vocab_size)\n","        # TODO 把限制加到这个位置\n","        if restricter is not None:\n","            next_scores, ids = restricter(state, token_ids, _scores, 2 * num_beams)\n","        else:\n","            next_scores, ids = torch.topk(_scores, 2 * num_beams, dim=1, largest=True, sorted=True)  # (bsz, 2*num_beams)\n","        from_which_beam = ids // vocab_size  # (batch_size, 2*num_beams)\n","        next_tokens = ids % vocab_size  # (batch_size, 2*num_beams)\n","\n","        #  接下来需要组装下一个batch的结果。\n","        #  需要选定哪些留下来\n","        # next_scores, sorted_inds = next_scores.sort(dim=-1, descending=True)\n","        # next_tokens = next_tokens.gather(dim=1, index=sorted_inds)\n","        # from_which_beam = from_which_beam.gather(dim=1, index=sorted_inds)\n","\n","        not_eos_mask = next_tokens.ne(_eos_token_id)  # 为1的地方不是eos\n","        keep_mask = not_eos_mask.cumsum(dim=1).le(num_beams)  # 为1的地方需要保留\n","        keep_mask = not_eos_mask.__and__(keep_mask)  # 为1的地方是需要进行下一步search的\n","\n","        _next_tokens = next_tokens.masked_select(keep_mask).view(-1, 1)\n","        _from_which_beam = from_which_beam.masked_select(keep_mask).view(batch_size, num_beams)  # 上面的token是来自哪个beam\n","        _next_scores = next_scores.masked_select(keep_mask).view(batch_size, num_beams)\n","        beam_scores = _next_scores.view(-1)\n","\n","        flag = True\n","        if cur_len+1 == real_max_length:\n","            eos_batch_idx = torch.arange(batch_size).to(next_tokens).repeat_interleave(repeats=num_beams, dim=0)\n","            eos_beam_ind = torch.arange(num_beams).to(token_ids).repeat(batch_size)  # 表示的是indice\n","            eos_beam_idx = from_which_beam[:, :num_beams].reshape(-1)  # 表示的是从哪个beam获取得到的\n","        else:\n","            # 将每个batch中在num_beam内的序列添加到结束中, 为1的地方需要结束了\n","            effective_eos_mask = next_tokens[:, :num_beams].eq(_eos_token_id)  # batch_size x num_beams\n","            if effective_eos_mask.sum().gt(0):\n","                eos_batch_idx, eos_beam_ind = effective_eos_mask.nonzero(as_tuple=True)\n","                # 是由于from_which_beam是 (batch_size, 2*num_beams)的，所以需要2*num_beams\n","                eos_beam_idx = eos_batch_idx * num_beams * 2 + eos_beam_ind\n","                eos_beam_idx = from_which_beam.view(-1)[eos_beam_idx]  # 获取真实的从哪个beam获取的eos\n","            else:\n","                flag = False\n","\n","        if flag:\n","            _token_ids = torch.cat([token_ids, _next_tokens], dim=-1)\n","            for batch_idx, beam_ind, beam_idx in zip(eos_batch_idx.tolist(), eos_beam_ind.tolist(),\n","                                                     eos_beam_idx.tolist()):\n","                if not dones[batch_idx]:\n","                    score = next_scores[batch_idx, beam_ind].item()\n","                    # 之后需要在结尾新增一个eos\n","                    if _eos_token_id!=-1:\n","                        hypos[batch_idx].add(_token_ids[batch_idx * num_beams + beam_idx, :cur_len].clone(), score)\n","                    else:\n","                        hypos[batch_idx].add(_token_ids[batch_idx * num_beams + beam_idx].clone(), score)\n","\n","        # 更改state状态, 重组token_ids\n","        reorder_inds = (batch_inds_with_numbeams_interval + _from_which_beam).view(-1)  # flatten成一维\n","        state.reorder_state(reorder_inds)\n","        # 重新组织token_ids的状态\n","        token_ids = torch.cat([token_ids.index_select(index=reorder_inds, dim=0), _next_tokens], dim=-1)\n","\n","        for batch_idx in range(batch_size):\n","            dones[batch_idx] = dones[batch_idx] or hypos[batch_idx].is_done(next_scores[batch_idx, 0].item()) or \\\n","                               max_lengths[batch_idx*num_beams]==cur_len+1\n","\n","        cur_len += 1\n","\n","        if all(dones):\n","            break\n","\n","    # select the best hypotheses\n","    tgt_len = token_ids.new_zeros(batch_size)\n","    best = []\n","\n","    for i, hypotheses in enumerate(hypos):\n","        best_hyp = max(hypotheses.hyp, key=lambda x: x[0])[1]\n","        # 把上面替换为非eos的词替换回eos\n","        if _eos_token_id!=-1:\n","            best_hyp = torch.cat([best_hyp, best_hyp.new_ones(1)*_eos_token_id])\n","        tgt_len[i] = len(best_hyp)\n","        best.append(best_hyp)\n","\n","    # generate target batch\n","    decoded = token_ids.new_zeros(batch_size, tgt_len.max().item()).fill_(pad_token_id)\n","    for i, hypo in enumerate(best):\n","        decoded[i, :tgt_len[i]] = hypo\n","\n","    return decoded\n","\n","\n","class BeamHypotheses(object):\n","    def __init__(self, num_beams, max_length, length_penalty, early_stopping):\n","        \"\"\"\n","        Initialize n-best list of hypotheses.\n","        \"\"\"\n","        self.max_length = max_length - 1  # ignoring bos_token\n","        self.length_penalty = length_penalty\n","        self.early_stopping = early_stopping\n","        self.num_beams = num_beams\n","        self.hyp = []\n","        self.worst_score = 1e9\n","\n","    def __len__(self):\n","        \"\"\"\n","        Number of hypotheses in the list.\n","        \"\"\"\n","        return len(self.hyp)\n","\n","    def add(self, hyp, sum_logprobs):\n","        \"\"\"\n","        Add a new hypothesis to the list.\n","        \"\"\"\n","        score = sum_logprobs / len(hyp) ** self.length_penalty\n","        if len(self) < self.num_beams or score > self.worst_score:\n","            self.hyp.append((score, hyp))\n","            if len(self) > self.num_beams:\n","                sorted_scores = sorted([(s, idx) for idx, (s, _) in enumerate(self.hyp)])\n","                del self.hyp[sorted_scores[0][1]]\n","                self.worst_score = sorted_scores[1][0]\n","            else:\n","                self.worst_score = min(score, self.worst_score)\n","\n","    def is_done(self, best_sum_logprobs):\n","        \"\"\"\n","        If there are enough hypotheses and that none of the hypotheses being generated\n","        can become better than the worst one in the heap, then we are done with this sentence.\n","        \"\"\"\n","        if len(self) < self.num_beams:\n","            return False\n","        elif self.early_stopping:\n","            return True\n","        else:\n","            return self.worst_score >= best_sum_logprobs / self.max_length ** self.length_penalty"],"metadata":{"id":"3OujcjF8D3qv"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#LOSS and METRIC"],"metadata":{"id":"PE8Y8i_gt9rg"}},{"cell_type":"code","source":["from fastNLP import LossBase\n","import torch.nn.functional as F\n","from fastNLP import seq_len_to_mask\n","\n","\n","class Seq2SeqLoss(LossBase):\n","    def __init__(self):\n","        super().__init__()\n","\n","    def get_loss(self, tgt_tokens, tgt_seq_len, pred):\n","        \"\"\"\n","        :param tgt_tokens: bsz x max_len, [sos, tokens, eos]\n","        :param pred: bsz x max_len-1 x vocab_size\n","        :return:\n","        \"\"\"\n","        tgt_seq_len = tgt_seq_len - 1\n","        mask = seq_len_to_mask(tgt_seq_len, max_len=tgt_tokens.size(1) - 1).eq(0)\n","        tgt_tokens = tgt_tokens[:, 1:].masked_fill(mask, -100)\n","        loss = F.cross_entropy(target=tgt_tokens, input=pred.transpose(1, 2))\n","        return loss"],"metadata":{"id":"Jpp_mQ5wuAyl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from fastNLP import MetricBase\n","from fastNLP.core.metrics import _compute_f_pre_rec\n","from collections import Counter\n","\n","\n","class Seq2SeqSpanMetric(MetricBase):\n","    def __init__(self, eos_token_id, num_labels, opinion_first=True):\n","        super(Seq2SeqSpanMetric, self).__init__()\n","        self.eos_token_id = eos_token_id\n","        self.num_labels = num_labels\n","        self.word_start_index = num_labels + 2  # +2, shift for sos and eos\n","\n","        self.quad_fp = 0\n","        self.quad_tp = 0\n","        self.quad_fn = 0\n","        self.em = 0\n","        self.invalid = 0\n","        self.total = 0\n","        assert opinion_first is False, \"Current metric only supports aspect first\"\n","\n","        self.opinin_first = opinion_first\n","\n","    def evaluate(self, target_span, pred, tgt_tokens):\n","        self.total += pred.size(0)\n","        pred_eos_index = pred.flip(dims=[1]).eq(self.eos_token_id).cumsum(dim=1).long()\n","        target_eos_index = tgt_tokens.flip(dims=[1]).eq(self.eos_token_id).cumsum(dim=1).long()\n","\n","        pred = pred[:, 1:]  # delete </s>\n","        tgt_tokens = tgt_tokens[:, 1:]\n","        pred_seq_len = pred_eos_index.flip(dims=[1]).eq(pred_eos_index[:, -1:]).sum(dim=1)  # bsz\n","        pred_seq_len = (pred_seq_len - 2).tolist()\n","        target_seq_len = target_eos_index.flip(dims=[1]).eq(target_eos_index[:, -1:]).sum(dim=1)  # bsz\n","        target_seq_len = (target_seq_len - 2).tolist()\n","        pred_spans = []\n","        for i, (ts, ps) in enumerate(zip(target_span, pred.tolist())):\n","            em = 0\n","            ps = ps[:pred_seq_len[i]]\n","            if pred_seq_len[i] == target_seq_len[i]:\n","                em = int(\n","                    tgt_tokens[i, :target_seq_len[i]].eq(pred[i, :target_seq_len[i]]).sum().item() == target_seq_len[i])\n","            self.em += em\n","            invalid = 0\n","            pairs = []\n","            cur_pair = []\n","            if len(ps):\n","                count = 0\n","                for index, j in enumerate(ps):\n","                    if j < self.word_start_index:\n","                        cur_pair.append(j)\n","                        if count<2:\n","                            count+=1\n","                        else:\n","                            if len(cur_pair) != 7 or cur_pair[0] > cur_pair[1] or cur_pair[4] > cur_pair[5]:\n","                                invalid = 1\n","                            else:\n","                                pairs.append(tuple(cur_pair))\n","                            cur_pair = []\n","                            count=0\n","                    else:\n","                        cur_pair.append(j)\n","            pred_spans.append(pairs.copy())\n","            self.invalid += invalid\n","\n","            ts = set([tuple(t) for t in ts])\n","            ps = set(pairs)\n","            for p in list(ps):\n","                if p in ts:\n","                    ts.remove(p)\n","                    self.quad_tp += 1\n","                else:\n","                    self.quad_fp += 1\n","\n","            self.quad_fn += len(ts)\n","\n","    def get_metric(self, reset=True):\n","        res = {}\n","        f, pre, rec = _compute_f_pre_rec(1, self.quad_tp, self.quad_fn, self.quad_fp)\n","\n","        res['quad_f'] = round(f, 4)*100\n","        res['quad_rec'] = round(rec, 4)*100\n","        res['quad_pre'] = round(pre, 4)*100\n","\n","        res['em'] = round(self.em / self.total, 4)\n","        res['invalid'] = round(self.invalid / self.total, 4)\n","        if reset:\n","            self.quad_fp = 0\n","            self.quad_tp = 0\n","            self.quad_fn = 0\n","            self.em = 0\n","            self.invalid = 0\n","            self.total = 0\n","        return res\n","\n","\n","def _compute_tp_fn_fp(ps, ts):\n","    ps = ps.copy()\n","    tp = 0\n","    fp = 0\n","    fn = 0\n","    if isinstance(ts, set):\n","        ts = {key: 1 for key in list(ts)}\n","    if isinstance(ps, set):\n","        ps = {key: 1 for key in list(ps)}\n","    for key in ts.keys():\n","        t_num = ts[key]\n","        if key not in ps:\n","            p_num = 0\n","        else:\n","            p_num = ps[key]\n","        tp += min(p_num, t_num)\n","        fp += max(p_num - t_num, 0)\n","        fn += max(t_num - p_num, 0)\n","        if key in ps:\n","            ps.pop(key)\n","    fp += sum(ps.values())\n","    return tp, fn, fp"],"metadata":{"id":"aUQYJUKfuBn3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#UTILS"],"metadata":{"id":"Zd3VqYYYuLc3"}},{"cell_type":"code","source":["import numpy as np\n","\n","\n","def get_max_len_max_len_a(data_bundle, max_len=10):\n","    \"\"\"\n","    :param data_bundle:\n","    :param max_len:\n","    :return:\n","    \"\"\"\n","    max_len_a = -1\n","    for name, ds in data_bundle.iter_datasets():\n","        if name=='train':continue\n","        src_seq_len = np.array(ds.get_field('src_seq_len').content)\n","        tgt_seq_len = np.array(ds.get_field('tgt_seq_len').content)\n","        _len_a = round(max(np.maximum(tgt_seq_len - max_len+2, 0)/src_seq_len), 1)\n","\n","        if _len_a>max_len_a:\n","            max_len_a = _len_a\n","\n","    return max_len, max_len_a\n","\n","\n","def get_num_parameters(model):\n","    num_param = 0\n","    for name, param in model.named_parameters():\n","        num_param += np.prod(param.size())\n","    print(f\"The number of parameters is {num_param}\")"],"metadata":{"id":"GvIcO41euLVM"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Train"],"metadata":{"id":"eLT2o2uRM_1v"}},{"cell_type":"code","source":["import sys\n","sys.path.append('../')\n","import os\n","if 'p' in os.environ:\n","    os.environ['CUDA_VISIBLE_DEVICES'] = os.environ['p']\n","    # os.environ['CUDA_VISIBLE_DEVICES'] = '7'\n","\n","import warnings\n","warnings.filterwarnings('ignore')\n","from fastNLP import Trainer,Tester\n","from fastNLP import BucketSampler, GradientClipCallback, cache_results, WarmupCallback\n","from fastNLP import FitlogCallback\n","from fastNLP.core.sampler import SortedSampler\n","import fitlog\n","from torch import optim\n","\n","# fitlog.debug()\n","lr = 5e-5\n","n_epochs = 50\n","batch_size = 3\n","num_beams = 4\n","dataset_name = 'pengb/16res'\n","opinion_first = False\n","length_penalty = 1.0\n","\n","decoder_type = 'avg_score'\n","bart_name = 'facebook/bart-base'\n","use_encoder_mlp = 1"],"metadata":{"id":"jGJdZwREM_Ff"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["demo = False\n","if demo:\n","    cache_fn = f\"caches/data_{bart_name}_{dataset_name}_{opinion_first}_demo.pt\"\n","else:\n","    cache_fn = f\"caches/data_{bart_name}_{dataset_name}_{opinion_first}.pt\""],"metadata":{"id":"s7DvIWAbQOCX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["@cache_results(cache_fn, _refresh=False)\n","def get_data():\n","    pipe = BartBPEABSAPipe(tokenizer=bart_name, opinion_first=opinion_first)\n","    data_bundle = pipe.process_from_file(f'/content/drive/MyDrive/Sentiment Analysis/data/Restaurant-ACOS/json', demo=demo)\n","    return data_bundle, pipe.tokenizer, pipe.mapping2id, pipe.mapping2targetid"],"metadata":{"id":"VRfiNhwJQN89"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data_bundle, tokenizer, mapping2id,mapping2targetid = get_data()\n","max_len = 10\n","max_len_a = {\n","    'penga/14lap': 0.9,\n","    'penga/14res': 1,\n","    'penga/15res': 1.2,\n","    'penga/16res': 0.9,\n","    'pengb/14lap': 1.1,\n","    'pengb/14res': 1.2,\n","    'pengb/15res': 0.9,\n","    'pengb/16res': 1.2\n","}[dataset_name]\n","\n","print(\"The number of tokens in tokenizer \", len(tokenizer.decoder))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":148,"referenced_widgets":["517db5d632b346cb87baf258608b1dc1","46be6628a7be4acda1829971061bbed4","bb2ee036ca014aa1825753419864f0cc","74089c52f4f644c99847a25b845718b7","2c88083802fd493b8fa1e3e4f0d04288","f654aef16249475f949fdd91e91f11a3","d0962910946649648d2e3511feddc6c6","799ca9eb7b994ab2bffed25f0ce885fa","570133c9c3574cbdaa3f79198e1a3f5f","ccd23235ef4240179fd86f39d6b20b2d","984305b0bb1446c58504527e70bb34fc","af3b6911a9cb415d987a5225dd013fa9","5cf4c138d8194e11ac16cb35455b2657","f9b838182ffa4a1a80948f5d36956201","d16ef2ab6b20459694290be4d48bb62b","479a2a3f6d0443eaba667d6f74218e46","1028abd27b5f47b7b97def956de38250","aee38c9ed738413392b53cfccfd989ac","13c7113f69fc474a8391650a00f4fd82","3225a8f23f7e484981b8d7031fe4cb91","c710281fedb54a538a255229a3529c05","ee69ecfcabfa4f49a767496f8e648449","fe5f2eb524174460b348439027985a4e","a1b72b82201649dbb898501b2bd8b096","b645786308bc484cb001d9eb3558f59c","7c45b14f906c4b46bc4020757fba5d8a","c83fe92a948d4136ab5f1ada0a786e66","049a7945e44d4f03ba0b19718aa97e68","f468091b81f94d59a83551084d7f6375","6615d1ec7a5f4e17b2a144268fcd96a3","8d878347504b4df5a8a5032f4a4f1ac4","24cdbd1a46464d35a219b447a524b46b","65b4e31e4ab94e89b7ff54ec7a96b8dd","df82a18287ed453c97c53044212bec69","6012bdc538d54d568730b7fdee1be209","42308a89abeb4719b8504139cfe8fc95","fb46570775f54c24a11dd4757b693df7","c9305207429f4a9eb2b8d3b6f57fa92f","ede23750796b43f988d5de88985d931a","6bced419a6f149d89bd9da234f6df382","727258ac79da42848eaa83dfc113f97e","5771410fffaf427fb2bcac52d72e6625","bf4a824ec0fd434cb31dbea5d94bb671","edfcd670596b4f0da321783304d00491","956df583d75042cf809e0a6edb57a733","775d3546995847768f7b6a1f62d71b44","1cc83d7481aa4925ab55b76c420c4176","33bac986d8d846c8b1868dc16b1101e4","f02c20680d3642279a1cdf9b0b0a4001","181e415664d44dc4a1fa36f3f8d67d5b","49d35756f2bf420e9e9ef35c3f0a4f3d","5c97baf71b674557a7ec2f76481b20b7","b4c32e952aad4d3d94c2f222387fbd23","9378114855a042c5a9605dc4f2269676","a219ffa7bb844038a23dcf5da85b3166","84887bf942d04543a4ade9615f5bcd0d","7361ecabff63463b843ca00cc768977e","deb768add23e4ed9b0ad2957e03c635d","190fe3a474bd4e6da9fb1a77dfb5f79d","2c1da913cb584a8eae04cc780c5e781c","0171ddb93cab4cedab6ca8b53ad7a6eb","8a44b39e118447bd86a1a912b56355ea","1394c1560de14c14a88a96563b9f0756","bc29ffa700dc4fb88590431461781c90","85671aea0aaf40bf8784f4e3f4c2ee35","4fd76899dc8441c785a189ee8a6d5fdc"]},"id":"eQGhrUXuR1Vz","executionInfo":{"status":"ok","timestamp":1651160879249,"user_tz":-420,"elapsed":24748,"user":{"displayName":"Duy Hoang","userId":"17457647490907439684"}},"outputId":"5eb6f30a-c59a-4389-8696-b91770b315b9"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/1.55k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"517db5d632b346cb87baf258608b1dc1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/899k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"af3b6911a9cb415d987a5225dd013fa9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/456k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fe5f2eb524174460b348439027985a4e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Pre. tgt. for `dev`:   0%|          | 0/171 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"df82a18287ed453c97c53044212bec69"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Pre. tgt. for `test`:   0%|          | 0/583 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"956df583d75042cf809e0a6edb57a733"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Pre. tgt. for `train`:   0%|          | 0/1530 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"84887bf942d04543a4ade9615f5bcd0d"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Save cache to caches/data_facebook/bart-base_pengb/16res_False.pt.\n","The number of tokens in tokenizer  50265\n"]}]},{"cell_type":"code","source":["idtarget2map=inv_map = {v: k for k, v in mapping2targetid.items()}"],"metadata":{"id":"vTtAJOdPxDhL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["bos_token_id = 0  #\n","eos_token_id = 1  #\n","label_ids = list(mapping2id.values())\n","vocab_size = len(tokenizer)\n"],"metadata":{"id":"IHaEL9aQ6eM4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","model = BartSeq2SeqModel.build_model(bart_name, tokenizer, label_ids=label_ids, decoder_type=decoder_type,\n","                                     copy_gate=False, use_encoder_mlp=use_encoder_mlp, use_recur_pos=False)\n","print(vocab_size, model.decoder.decoder.embed_tokens.weight.data.size(0))\n","model = SequenceGeneratorModel(model, bos_token_id=bos_token_id,\n","                               eos_token_id=eos_token_id,\n","                               max_length=max_len, max_len_a=max_len_a,num_beams=num_beams, do_sample=False,\n","                               repetition_penalty=1, length_penalty=length_penalty, pad_token_id=eos_token_id,\n","                               restricter=None)"],"metadata":{"id":"C4oB7u5hbfj7","colab":{"base_uri":"https://localhost:8080/","height":66,"referenced_widgets":["63732b415c304865bb4cd9bb00a8a815","cfbced143e4a471dbee5606e304d5cd6","e330ed307a6148ed8d97223a2988da7d","4c8b63a73d344c90b761a0dd09a18e54","9021a79805ae4dac8acb5b0ce2f2d5cb","e882644e26894f2bbbb6bd7043abe82d","40102d04f3854bb3a4831f013ed9a215","4cc28abe359f40aab0daff48228a385c","cfe403960a754390938bfdd38e8ef536","805d03e1b79042c6a07a83e1c53618be","b44fdfa8aeb044059b719a94b054ae7a"]},"executionInfo":{"status":"ok","timestamp":1650907682856,"user_tz":-420,"elapsed":26985,"user":{"displayName":"Mãi Học","userId":"14689829624788875777"}},"outputId":"5c2294df-6c71-427c-c18a-eacdfef541aa"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/558M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"63732b415c304865bb4cd9bb00a8a815"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["50280 50285\n"]}]},{"cell_type":"code","source":["model = torch.load(\"/content/drive/MyDrive/Sentiment Analysis/data/Restaurant-ACOS/model/current\")"],"metadata":{"id":"FJz0cJszWZP1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","import torch\n","if torch.cuda.is_available():\n","    # device = list([i for i in range(torch.cuda.device_count())])\n","    device = 'cuda'\n","else:\n","    device = 'cpu'\n","\n","parameters = []\n","params = {'lr':lr, 'weight_decay':1e-2}\n","params['params'] = [param for name, param in model.named_parameters() if not ('bart_encoder' in name or 'bart_decoder' in name)]\n","parameters.append(params)\n","\n","params = {'lr':lr, 'weight_decay':1e-2}\n","params['params'] = []\n","for name, param in model.named_parameters():\n","    if ('bart_encoder' in name or 'bart_decoder' in name) and not ('layernorm' in name or 'layer_norm' in name):\n","        params['params'].append(param)\n","parameters.append(params)\n","\n","params = {'lr':lr, 'weight_decay':0}\n","params['params'] = []\n","for name, param in model.named_parameters():\n","    if ('bart_encoder' in name or 'bart_decoder' in name) and ('layernorm' in name or 'layer_norm' in name):\n","        params['params'].append(param)\n","parameters.append(params)\n","\n","optimizer = optim.AdamW(parameters)"],"metadata":{"id":"7iC0zaq2bYVv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","callbacks = []\n","callbacks.append(GradientClipCallback(clip_value=5, clip_type='value'))\n","callbacks.append(WarmupCallback(warmup=0.01, schedule='linear'))\n","callbacks.append(FitlogCallback(data_bundle.get_dataset('test')))\n","\n","sampler = None\n","# sampler = ConstTokenNumSampler('src_seq_len', max_token=1000)\n","sampler = BucketSampler(seq_len_field_name='src_seq_len')\n","metric = Seq2SeqSpanMetric(eos_token_id, num_labels=len(label_ids), opinion_first=opinion_first)\n"],"metadata":{"id":"hEmyntdObt0i"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["fitlog.set_log_dir('/content/caches')\n","\n","model_path = \"/content/drive/MyDrive/Sentiment Analysis/data/Restaurant-ACOS/model\"\n","\n","\n","trainer = Trainer(train_data=data_bundle.get_dataset('train'), model=model, optimizer=optimizer,\n","                  loss=Seq2SeqLoss(),\n","                  batch_size=batch_size, sampler=sampler, drop_last=False, update_every=1,\n","                  num_workers=2, n_epochs=n_epochs, print_every=1,\n","                  dev_data=data_bundle.get_dataset('dev'), metrics=metric, metric_key='quad_f',\n","                  validate_every=-1, save_path=model_path, use_tqdm=True, device=device,\n","                  callbacks=callbacks, check_code_level=0, test_use_tqdm=False,\n","                  test_sampler=SortedSampler('src_seq_len'), dev_batch_size=batch_size)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TIlie3ekbzBK","executionInfo":{"status":"ok","timestamp":1650907475336,"user_tz":-420,"elapsed":11783,"user":{"displayName":"Cao Duy Hoang","userId":"17498028471290040726"}},"outputId":"63678d9f-8593-4fd6-fcdf-07d0ed6d7ad4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["input fields after batch(if batch size is 2):\n","\ttgt_tokens: (1)type:torch.Tensor (2)dtype:torch.int64, (3)shape:torch.Size([2, 9]) \n","\tsrc_tokens: (1)type:torch.Tensor (2)dtype:torch.int64, (3)shape:torch.Size([2, 36]) \n","\tsrc_seq_len: (1)type:torch.Tensor (2)dtype:torch.int64, (3)shape:torch.Size([2]) \n","\ttgt_seq_len: (1)type:torch.Tensor (2)dtype:torch.int64, (3)shape:torch.Size([2]) \n","target fields after batch(if batch size is 2):\n","\ttgt_tokens: (1)type:torch.Tensor (2)dtype:torch.int64, (3)shape:torch.Size([2, 9]) \n","\ttarget_span: (1)type:numpy.ndarray (2)dtype:int64, (3)shape:(2, 1, 7) \n","\ttgt_seq_len: (1)type:torch.Tensor (2)dtype:torch.int64, (3)shape:torch.Size([2]) \n","\n"]}]},{"cell_type":"code","source":["trainer.train(load_best_model=True)\n"],"metadata":{"id":"8M33ue43b09m","colab":{"base_uri":"https://localhost:8080/","height":66,"referenced_widgets":["d8a0a2e2132f43f2ba2f0663bd8b8897","d0d8e088c9f549dfab384564c81cb63f","bfe5125fbc9d47389ede8e31a57971de","a286689b54cb4c7a8b6bf37bafa25674","5ae6fd90b19d4391945ccdaf0b1f913d","ac34afddd37745bfa78080eca39467c0","0fc95e00aa4749058b46864a655e5ef6","fcf601c37a7243b299828b5c50744613","f3fa5a97665a4587a8ed2977f6c8c64e","c8cf22311ec14e60bfca507cc07f241a","db1a3576a87743b4b75f4fab0181fe58"]},"outputId":"099a4d7c-8b71-40a2-9482-1a12655ca792"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["training epochs started 2022-04-25-17-24-36-699081\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/25500 [00:00<?, ?it/s, loss:{0:<6.5f}]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d8a0a2e2132f43f2ba2f0663bd8b8897"}},"metadata":{}}]},{"cell_type":"markdown","source":["#Testing"],"metadata":{"id":"apnS0DwNQA58"}},{"cell_type":"code","source":["torch.save(model,\"/content/drive/MyDrive/Sentiment Analysis/data/Restaurant-ACOS/model/current_res\")"],"metadata":{"id":"Bo8vfnd7p6vq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tester = Tester(data_bundle.get_dataset('test'), model, metrics=metric,batch_size=batch_size)\n","eval_results = tester.test()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":69,"referenced_widgets":["66dcf9080aa34c7b9d5bcaad83932c2b","ea41370d025747e39c75807e6bc10c3c","4394783393bd4102b0f4f68b6e3da2a8","3f1a78dcf3534612a37cf7cc3ba90006","445ac39f572b4ed485933715d1ce3d15","3384668a83b1468698f22e2c1617cedd","f1dd49ed53d94b3986998bf8105e52ab","44207528c88c46b3a9e8be0b8b70647f","5bf3370b83634a088a1b94c6db2c2b0c","2115448e2a2240f680f64a2b06dce33f","fdb3fcf3055c4ea2af10965d65921839"]},"id":"GNg64gFoOl8c","executionInfo":{"status":"ok","timestamp":1651161061095,"user_tz":-420,"elapsed":159477,"user":{"displayName":"Duy Hoang","userId":"17457647490907439684"}},"outputId":"99b5e243-61f0-4628-ddfe-4d6d98b6c725"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/195 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"66dcf9080aa34c7b9d5bcaad83932c2b"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Evaluate data in 159.59 seconds!\n","[tester] \n","Seq2SeqSpanMetric: quad_f=53.790000000000006, quad_rec=51.09, quad_pre=56.8, em=0.4408, invalid=0.0189\n"]}]},{"cell_type":"code","source":["print(len(data_bundle.get_dataset('test')))\n","print(len(data_bundle.get_dataset('dev')))\n","print(len(data_bundle.get_dataset('train')))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1iiNWGhMQqY_","executionInfo":{"status":"ok","timestamp":1650867841676,"user_tz":-420,"elapsed":358,"user":{"displayName":"Duy Hoang Cao","userId":"16271725378927136297"}},"outputId":"7f188cea-7b70-4e5b-8610-6617f06bf207"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["583\n","171\n","1530\n"]}]},{"cell_type":"code","source":["916+261+2484"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fp2jToHrxpul","executionInfo":{"status":"ok","timestamp":1650304053197,"user_tz":-420,"elapsed":484,"user":{"displayName":"Duy Hoang Cao","userId":"16271725378927136297"}},"outputId":"b5c15ebc-37d7-447f-c69f-ffb4ef96effa"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["3661"]},"metadata":{},"execution_count":51}]},{"cell_type":"code","source":["ret = 0\n","for i in range(0,len(data_bundle.get_dataset('train'))):\n","    ret += len(data_bundle.get_dataset('train')[\"opinions\"][i])\n","ret"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CtKGwE_xx7WQ","executionInfo":{"status":"ok","timestamp":1650304047654,"user_tz":-420,"elapsed":1032,"user":{"displayName":"Duy Hoang Cao","userId":"16271725378927136297"}},"outputId":"d5f087e5-d1c9-49fa-a6cb-a9459a3b89b6"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["2484"]},"metadata":{},"execution_count":50}]},{"cell_type":"code","source":["pipe = BartBPEABSAPipe(tokenizer=bart_name, opinion_first=opinion_first)"],"metadata":{"id":"u0m8qQTv0FWw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test_bundle = pipe.process_from_file(\"/content/drive/MyDrive/Sentiment Analysis/data/Restaurant-ACOS/json/Implicit Explicit\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17,"referenced_widgets":["9f2b26b4757e454ab40f93877cad81a0","372630e0685d44d8979f93d4905376fa","0f1f35b9f86440d19cefe8b3ae97f744","480563d324cf4ad99d071640c4a5c521","470ef326b180487f900ebb459cc57549","635d3b539c26402a9d59454eb29d45a4","4b2509933a2d4d4b90698c7990d51bd1","2fe2fd7602cc4c5fbd1d1eaa018c6f29","c36f0d683d3442c6933f4bfc2a7284fe","b3c3a36404624f4baa999635ca725f09","b3b59b6fb2334f89acf2ef85df97bb97","af3814ddde6941a193ee24444b637386","3030759fc8cd4810a85078eac9412794","f69ef85d0b614f5d99ae879fe94cf2a5","ead94b8f524a476ab7c23fb09f3e940b","d398b87346cb41e79ff6a5d9a315494a","e8a498ee1d5f4658892ef5b3859d3667","566c77fb1e9643cc9c0bee13843bc258","00d2e5e985c144348ee7133e5f56a534","9f43132d736245ff944ffe4e17d58f27","cbc7a9f3e765420ea77283d1f0048629","a500490161e642b19351998265e096e4","143e0b3df5be419797f33d454357929d","0c63b536f74b4164a53b6b013ae38c1d","37e6d1fe8f0446cab9c43ae58cb9806e","5c4419e1e12645d2ba6af1609f3c3fe1","e7852749a1a44eef9d30c63bc18cd602","b177da5c70284aec9efdf4ad415cffaa","f884e047559d49ef9d333667eb3beca6","497d931c2028441a80e009390466af6f","d2192524a0684eba8b3cf3a07065792e","719d05a3892c491193132f1834a9549c","c10e9809bc0242279e3b55b4303d69f6"]},"id":"iLgsk_kg1SdQ","executionInfo":{"status":"ok","timestamp":1651161067482,"user_tz":-420,"elapsed":4144,"user":{"displayName":"Duy Hoang","userId":"17457647490907439684"}},"outputId":"d29fd19d-4024-4e4c-ce79-df1284bb9843"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["Pre. tgt. for `dev`:   0%|          | 0/112 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9f2b26b4757e454ab40f93877cad81a0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Pre. tgt. for `test`:   0%|          | 0/90 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"af3814ddde6941a193ee24444b637386"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Pre. tgt. for `train`:   0%|          | 0/366 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"143e0b3df5be419797f33d454357929d"}},"metadata":{}}]},{"cell_type":"markdown","source":["##IAIO"],"metadata":{"id":"htqgAHuC50-3"}},{"cell_type":"code","source":["model.to(\"cuda\")"],"metadata":{"id":"exhsrICAT5hs","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1651161067484,"user_tz":-420,"elapsed":25,"user":{"displayName":"Duy Hoang","userId":"17457647490907439684"}},"outputId":"95356c9c-877b-4af8-eedc-6bc529ba2848"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["SequenceGeneratorModel(\n","  (seq2seq_model): BartSeq2SeqModel(\n","    (encoder): FBartEncoder(\n","      (bart_encoder): BartEncoder(\n","        (embed_tokens): Embedding(50285, 768)\n","        (embed_positions): LearnedPositionalEmbedding(1026, 768, padding_idx=1)\n","        (layers): ModuleList(\n","          (0): EncoderLayer(\n","            (self_attn): Attention(\n","              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","            )\n","            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          )\n","          (1): EncoderLayer(\n","            (self_attn): Attention(\n","              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","            )\n","            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          )\n","          (2): EncoderLayer(\n","            (self_attn): Attention(\n","              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","            )\n","            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          )\n","          (3): EncoderLayer(\n","            (self_attn): Attention(\n","              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","            )\n","            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          )\n","          (4): EncoderLayer(\n","            (self_attn): Attention(\n","              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","            )\n","            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          )\n","          (5): EncoderLayer(\n","            (self_attn): Attention(\n","              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","            )\n","            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          )\n","        )\n","        (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","      )\n","    )\n","    (decoder): CaGFBartDecoder(\n","      (decoder): BartDecoder(\n","        (embed_tokens): Embedding(50285, 768)\n","        (embed_positions): LearnedPositionalEmbedding(1026, 768, padding_idx=1)\n","        (layers): ModuleList(\n","          (0): DecoderLayer(\n","            (self_attn): Attention(\n","              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","            )\n","            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (encoder_attn): Attention(\n","              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","            )\n","            (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          )\n","          (1): DecoderLayer(\n","            (self_attn): Attention(\n","              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","            )\n","            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (encoder_attn): Attention(\n","              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","            )\n","            (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          )\n","          (2): DecoderLayer(\n","            (self_attn): Attention(\n","              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","            )\n","            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (encoder_attn): Attention(\n","              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","            )\n","            (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          )\n","          (3): DecoderLayer(\n","            (self_attn): Attention(\n","              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","            )\n","            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (encoder_attn): Attention(\n","              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","            )\n","            (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          )\n","          (4): DecoderLayer(\n","            (self_attn): Attention(\n","              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","            )\n","            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (encoder_attn): Attention(\n","              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","            )\n","            (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          )\n","          (5): DecoderLayer(\n","            (self_attn): Attention(\n","              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","            )\n","            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (encoder_attn): Attention(\n","              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","            )\n","            (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          )\n","        )\n","        (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","      )\n","      (encoder_mlp): Sequential(\n","        (0): Linear(in_features=768, out_features=768, bias=True)\n","        (1): Dropout(p=0.3, inplace=False)\n","        (2): ReLU()\n","        (3): Linear(in_features=768, out_features=768, bias=True)\n","      )\n","    )\n","  )\n",")"]},"metadata":{},"execution_count":27}]},{"cell_type":"code","source":["tester = Tester(test_bundle.get_dataset('test'), model, metrics=metric,batch_size=batch_size)\n","eval_results = tester.test()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":69,"referenced_widgets":["02f6b2acf68643ccb74b6ac41cbd9d93","20ade3e614c744ae8a05fd3d7dfef40d","8f2f626491814f9e8f273ca372414cc3","6295cc36bf8747db92e8ed07f6199a9c","e99e70ada72f404eb47ee685bce5e59e","9f84055b9cf04177a6f9e9e4bf3f6b7f","853b0abc2df54e9688b075d133b60346","5cd4cd00ab6d4775b5e260117fae33aa","bc31184e180c4d09a9564d350cfab35e","8d55b4dc1857412ea21e4dc0c24945ee","eb5681b4a9824dbca6f7dae508b72adf"]},"id":"zvpcgAO-12Is","executionInfo":{"status":"ok","timestamp":1650908815973,"user_tz":-420,"elapsed":10217,"user":{"displayName":"Mãi Học","userId":"14689829624788875777"}},"outputId":"04a949cb-abc0-4e44-e308-ef99f64f6edc"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/30 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"02f6b2acf68643ccb74b6ac41cbd9d93"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Evaluate data in 10.01 seconds!\n","[tester] \n","Seq2SeqSpanMetric: quad_f=42.86, quad_rec=42.86, quad_pre=42.86, em=0.4222, invalid=0.0222\n"]}]},{"cell_type":"markdown","source":["##EAEO"],"metadata":{"id":"wUIufUfy53L4"}},{"cell_type":"code","source":["tester = Tester(test_bundle.get_dataset('train'), model, metrics=metric,batch_size=batch_size)\n","eval_results = tester.test()"],"metadata":{"id":"fvBlQYuH19rw","executionInfo":{"status":"ok","timestamp":1651161178041,"user_tz":-420,"elapsed":110579,"user":{"displayName":"Duy Hoang","userId":"17457647490907439684"}},"colab":{"base_uri":"https://localhost:8080/","height":69,"referenced_widgets":["38b976bb7a274cc386cb06eeab958fa5","ab81478d1f994a0aae8a87641d6de590","c377051749244fd2b7ef63b932430e0e","e4903f5b18b9477c88b39b2c8accb144","2089b8af4165443fa1572dbf2810349f","40aa11815b61440d878392cf2cc6d386","f8e791ed80f64b0eb3432e2d3f73cfaf","ed380696fe474220bfd530b7c802626d","df8ee2f2ca0e4add88859923c543336c","e23f1be560f54418be15b5b83edbde82","71f6e328edab4b92a3178c22cc57021c"]},"outputId":"b6902fa7-560c-437f-a725-eb3a7d8121e7"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/122 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"38b976bb7a274cc386cb06eeab958fa5"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Evaluate data in 110.64 seconds!\n","[tester] \n","Seq2SeqSpanMetric: quad_f=58.46, quad_rec=58.56, quad_pre=58.36, em=0.4563, invalid=0.0191\n"]}]},{"cell_type":"markdown","source":["##EAIO"],"metadata":{"id":"8R292Wnd55pz"}},{"cell_type":"code","source":["tester = Tester(test_bundle.get_dataset('dev'), model, metrics=metric,batch_size=batch_size)\n","eval_results = tester.test()"],"metadata":{"id":"-AlquKtq1-NR","executionInfo":{"status":"ok","timestamp":1650908797762,"user_tz":-420,"elapsed":14440,"user":{"displayName":"Mãi Học","userId":"14689829624788875777"}},"colab":{"base_uri":"https://localhost:8080/","height":69,"referenced_widgets":["0aa3fe347f1648a890d644c6feee9908","ccd0d58dc9664886b5d3910f1306dce4","30b3aaab7bc64a629bed0e4ddd8b34c7","577b56ab56804f9bb99d49c837f4f780","ffcbb63ea7d54f9491771b8db7528e7e","80de24a5416f4e568ac3ed535c60b20c","81ec4f64615e4f25b5335d4157a221f4","18dd841c6b0c403c857f38bbcdcf2598","7df691aea184491c8229b66d6ed22b1d","29e403119db947a6b6369136a91ef1d8","400f7e5a67d94ce296c5c567ca6fd551"]},"outputId":"985b3cf3-7cb5-474b-fe5d-f89e07341a16"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/26 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0aa3fe347f1648a890d644c6feee9908"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Evaluate data in 13.99 seconds!\n","[tester] \n","Seq2SeqSpanMetric: quad_f=20.0, quad_rec=19.63, quad_pre=20.39, em=0.2237, invalid=0.0263\n"]}]},{"cell_type":"markdown","source":["##IAEO"],"metadata":{"id":"YVsH5aS86GrU"}},{"cell_type":"code","source":["tester = Tester(test_bundle.get_dataset('dev'), model, metrics=metric,batch_size=batch_size)\n","eval_results = tester.test()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":69,"referenced_widgets":["64ca6d1523594483ac783983dd45aa77","91096cbbd89e41f1b17de00458ca8a3d","bf48ba65376246989c14f2edb9b82fdc","3472979d1f9e4c5eac14acfc285b0472","ed19715562114330bbfba730aea866af","02ad9ebd37744dd894ab945c835023a5","30b60763884d435eae8cec494b31ca8e","e8b3d5695a4443b2bb59ecb7def03287","c2f9674bd1ce4b9ab01dbda7f6641576","fae2d50762194cb8984788410e817468","fb5c9fe10bcb4842b8f876d00fe15912"]},"id":"bnZl-7Vp6F1I","executionInfo":{"status":"ok","timestamp":1650909209084,"user_tz":-420,"elapsed":10953,"user":{"displayName":"Mãi Học","userId":"14689829624788875777"}},"outputId":"d010ca57-3cf5-4364-a470-165b53185a17"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/38 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"64ca6d1523594483ac783983dd45aa77"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Evaluate data in 10.68 seconds!\n","[tester] \n","Seq2SeqSpanMetric: quad_f=43.87, quad_rec=48.36, quad_pre=40.14, em=0.3839, invalid=0.0179\n"]}]},{"cell_type":"markdown","source":["#Test use"],"metadata":{"id":"w132u__HLK5E"}},{"cell_type":"code","source":["import numpy as np\n","def tokenize_sentence(sentences,tokenizer,device = \"cpu\"):\n","    output_mold = []\n","    len_lst = []\n","    for i in range (0,len(sentences)):\n","        added_sentence = \"<<null>> \"+sentences[i]\n","        raw_words = added_sentence.split(\" \")\n","        word_bpes = [[tokenizer.bos_token_id]]\n","        for word in raw_words:\n","            bpes = tokenizer.tokenize(word, add_prefix_space=True)\n","            bpes = tokenizer.convert_tokens_to_ids(bpes)\n","            word_bpes.append(bpes)\n","        word_bpes.append([tokenizer.eos_token_id])\n","        output = list(chain(*word_bpes))\n","        output_mold.append(output)\n","    max_len = max(len(x) for x in output_mold)\n","    mold_np = np.ones([len(sentences),max_len])\n","    for i in range (0,len(sentences)):\n","        raw_words = output_mold[i]\n","        len_lst.append(len(raw_words))\n","        mold_np[i,:len_lst[-1]]=raw_words\n","    seg_token = torch.LongTensor(mold_np).to(device)\n","    seg_token_len = torch.LongTensor(len_lst).to(device)\n","    return seg_token , seg_token_len\n","\n","sentences = [\"We waited for an hour to be seated\",\"it was is great\"]\n","seg_token, seg_token_len = tokenize_sentence(sentences,tokenizer,\"cuda\")\n","model.train(mode=False)\n","model.to(\"cuda\")   \n","res = model.predict(seg_token, seg_token_len)[\"pred\"]"],"metadata":{"id":"m61ToHByLKP0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["res"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pkfGpf57x733","executionInfo":{"status":"ok","timestamp":1650522049638,"user_tz":-420,"elapsed":8,"user":{"displayName":"Duy Hoang","userId":"17457647490907439684"}},"outputId":"0c392de7-cff2-444b-ba74-ee1bf14ab451"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[ 0, 17, 17,  3,  8, 17, 17, 14,  1],\n","        [ 0, 19, 19,  4,  9, 21, 21, 13,  1]], device='cuda:0')"]},"metadata":{},"execution_count":35}]},{"cell_type":"code","source":["def translateResult(sentences,results,idtarget2map,tokenizer):\n","    converted_sentences=[]\n","    for i in sentences:\n","        lst = []\n","        for word in i.split(\" \"):\n","            bpes = tokenizer.tokenize(word, add_prefix_space=True)\n","            lst.extend(bpes)\n","        converted_sentences.append(\" \".join(lst))\n","    output_mold = []\n","    len_lst = []\n","    cap = len(idtarget2map)+2\n","    def translateResultChunk(block,sentence):\n","        output = []\n","        prev = None\n","        lst = sentence.split(\" \")\n","        for i in block:\n","            if i<cap:\n","                output.append(idtarget2map[i-2])\n","                continue\n","            if prev is not None:\n","                chunk = lst[prev:i-cap]\n","                text = \"\"\n","                for i in chunk:\n","                    if i[0]==\"Ġ\":\n","                        text =text +\" \"+i[1:]\n","                    else:\n","                        text =text +i\n","                output.append(text.strip())\n","                prev = None\n","            else:\n","                prev = i-cap-1\n","        return output\n","    for i in range(0,len(converted_sentences)):\n","        blocks=[]\n","        count=0\n","        cur_pair = []\n","        for o in results[i]:\n","            k = int(o)\n","            if k==0 or k==1:\n","                continue\n","            \n","            if k<cap:\n","                cur_pair.append(k)\n","\n","                if count<2:\n","                    count+=1\n","                else:\n","                    if not(len(cur_pair) != 7 or cur_pair[0] > cur_pair[1] or cur_pair[4] > cur_pair[5]):\n","                        blocks.append(translateResultChunk(cur_pair,\"NULL \"+converted_sentences[i]).copy())\n","                    cur_pair = []\n","                    count=0\n","            else:\n","                cur_pair.append(k)\n","        output_mold.append(blocks.copy())\n","    return output_mold"],"metadata":{"id":"6-heP7xgNSQ_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["translateResult(sentences,res,idtarget2map,tokenizer)"],"metadata":{"id":"UbHuOz8kUMwK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1650522204952,"user_tz":-420,"elapsed":7,"user":{"displayName":"Duy Hoang","userId":"17457647490907439684"}},"outputId":"c078da41-29ed-4283-fc15-c1ff0f0d0c89"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[[['NULL', 'SERVICE', 'GENERAL', 'NULL', 'NEG']],\n"," [['NULL', 'RESTAURANT', 'GENERAL', 'great', 'POS']]]"]},"metadata":{},"execution_count":41}]}]}